[32m[0315 20:30:05 @logger.py:67][0m Log file set to /mnt/rl_playground/tool/train_gym.py/../../log/gym_0315-203005.log
[32m[0315 20:30:05 @train_gym.py:36][0m Session starts, using gpu: 0
[32m[0315 20:30:05 @dqn_agent.py:47][0m Constructing a q-learning agent to play Breakout-v0
[32m[0315 20:30:06 @environments.py:46][0m Init game environments Breakout-v0
[32m[0315 20:30:06 @environments.py:88][0m Game set image size: 80, random walk step: 30
[32m[0315 20:30:06 @network.py:124][0m building the target network, name: target_network
[32m[0315 20:30:06 @network.py:52][0m Building network of type: dqn, using basebone: nips
[32m[0315 20:30:06 @cnn.py:21][0m building the basebone network, using nips format
[32m[0315 20:30:06 @network.py:126][0m building the pred network, name: predict_network
[32m[0315 20:30:06 @network.py:52][0m Building network of type: dqn, using basebone: nips
[32m[0315 20:30:06 @cnn.py:21][0m building the basebone network, using nips format
[32m[0315 20:30:06 @experience.py:23][0m building the experience shop
[32m[0315 20:30:06 @summary_handler.py:30][0m summary write initialized, writing to /mnt/rl_playground/tool/../agent/../checkpoint
[32m[0315 20:30:08 @dqn_agent.py:203][0m episode: 45, total game step: 1000, epsilon: 1.0
[32m[0315 20:30:10 @dqn_agent.py:203][0m episode: 87, total game step: 2000, epsilon: 1.0
[32m[0315 20:30:11 @summary_handler.py:101][0m At episode: 2369, Reward: 0.13 (over 100 episodes)
[32m[0315 20:30:11 @summary_handler.py:102][0m Length: 23.69
[32m[0315 20:30:12 @dqn_agent.py:203][0m episode: 126, total game step: 3000, epsilon: 1.0
[32m[0315 20:30:14 @dqn_agent.py:203][0m episode: 177, total game step: 4000, epsilon: 1.0
[32m[0315 20:30:15 @summary_handler.py:101][0m At episode: 4519, Reward: 0.09 (over 100 episodes)
[32m[0315 20:30:15 @summary_handler.py:102][0m Length: 21.5
[32m[0315 20:30:16 @dqn_agent.py:203][0m episode: 222, total game step: 5000, epsilon: 1.0
[32m[0315 20:30:18 @dqn_agent.py:203][0m episode: 264, total game step: 6000, epsilon: 1.0
[32m[0315 20:30:20 @summary_handler.py:101][0m At episode: 6805, Reward: 0.13 (over 100 episodes)
[32m[0315 20:30:20 @summary_handler.py:102][0m Length: 22.86
[32m[0315 20:30:20 @dqn_agent.py:203][0m episode: 306, total game step: 7000, epsilon: 1.0
[32m[0315 20:30:22 @dqn_agent.py:203][0m episode: 337, total game step: 8000, epsilon: 1.0
[32m[0315 20:30:24 @dqn_agent.py:203][0m episode: 377, total game step: 9000, epsilon: 1.0
[32m[0315 20:30:24 @summary_handler.py:101][0m At episode: 9383, Reward: 0.22 (over 100 episodes)
[32m[0315 20:30:24 @summary_handler.py:102][0m Length: 25.78
[32m[0315 20:30:26 @dqn_agent.py:203][0m episode: 424, total game step: 10000, epsilon: 1.0
[32m[0315 20:30:28 @dqn_agent.py:203][0m episode: 470, total game step: 11000, epsilon: 1.0
[32m[0315 20:30:29 @summary_handler.py:101][0m At episode: 11548, Reward: 0.14 (over 100 episodes)
[32m[0315 20:30:29 @summary_handler.py:102][0m Length: 21.65
[32m[0315 20:30:30 @dqn_agent.py:203][0m episode: 513, total game step: 12000, epsilon: 1.0
[32m[0315 20:30:32 @dqn_agent.py:203][0m episode: 554, total game step: 13000, epsilon: 1.0
[32m[0315 20:30:34 @dqn_agent.py:203][0m episode: 597, total game step: 14000, epsilon: 1.0
[32m[0315 20:30:34 @summary_handler.py:101][0m At episode: 14060, Reward: 0.18 (over 100 episodes)
[32m[0315 20:30:34 @summary_handler.py:102][0m Length: 25.12
[32m[0315 20:30:35 @dqn_agent.py:203][0m episode: 631, total game step: 15000, epsilon: 1.0
[32m[0315 20:30:37 @dqn_agent.py:203][0m episode: 684, total game step: 16000, epsilon: 1.0
[32m[0315 20:30:38 @summary_handler.py:101][0m At episode: 16486, Reward: 0.19 (over 100 episodes)
[32m[0315 20:30:38 @summary_handler.py:102][0m Length: 24.26
[32m[0315 20:30:39 @dqn_agent.py:203][0m episode: 728, total game step: 17000, epsilon: 1.0
[32m[0315 20:30:41 @dqn_agent.py:203][0m episode: 764, total game step: 18000, epsilon: 1.0
[32m[0315 20:30:43 @summary_handler.py:101][0m At episode: 18766, Reward: 0.15 (over 100 episodes)
[32m[0315 20:30:43 @summary_handler.py:102][0m Length: 22.8
[32m[0315 20:30:43 @dqn_agent.py:203][0m episode: 807, total game step: 19000, epsilon: 1.0
[32m[0315 20:30:45 @dqn_agent.py:203][0m episode: 861, total game step: 20000, epsilon: 1.0
[32m[0315 20:30:47 @summary_handler.py:101][0m At episode: 20878, Reward: 0.1 (over 100 episodes)
[32m[0315 20:30:47 @summary_handler.py:102][0m Length: 21.12
[32m[0315 20:30:47 @dqn_agent.py:203][0m episode: 904, total game step: 21000, epsilon: 1.0
[32m[0315 20:30:49 @dqn_agent.py:203][0m episode: 942, total game step: 22000, epsilon: 1.0
[32m[0315 20:30:51 @dqn_agent.py:203][0m episode: 977, total game step: 23000, epsilon: 1.0
[32m[0315 20:30:52 @summary_handler.py:101][0m At episode: 23516, Reward: 0.22 (over 100 episodes)
[32m[0315 20:30:52 @summary_handler.py:102][0m Length: 26.38
[32m[0315 20:30:53 @dqn_agent.py:203][0m episode: 1020, total game step: 24000, epsilon: 1.0
[32m[0315 20:30:55 @dqn_agent.py:203][0m episode: 1058, total game step: 25000, epsilon: 1.0
[32m[0315 20:30:57 @summary_handler.py:101][0m At episode: 25993, Reward: 0.2 (over 100 episodes)
[32m[0315 20:30:57 @summary_handler.py:102][0m Length: 24.77
[32m[0315 20:30:57 @dqn_agent.py:203][0m episode: 1100, total game step: 26000, epsilon: 1.0
[32m[0315 20:30:59 @dqn_agent.py:203][0m episode: 1153, total game step: 27000, epsilon: 1.0
[32m[0315 20:31:01 @dqn_agent.py:203][0m episode: 1199, total game step: 28000, epsilon: 1.0
[32m[0315 20:31:02 @summary_handler.py:101][0m At episode: 28015, Reward: 0.05 (over 100 episodes)
[32m[0315 20:31:02 @summary_handler.py:102][0m Length: 20.22
[32m[0315 20:31:04 @dqn_agent.py:203][0m episode: 1237, total game step: 29000, epsilon: 1.0
[32m[0315 20:31:06 @dqn_agent.py:203][0m episode: 1291, total game step: 30000, epsilon: 1.0
[32m[0315 20:31:06 @summary_handler.py:101][0m At episode: 30187, Reward: 0.07 (over 100 episodes)
[32m[0315 20:31:06 @summary_handler.py:102][0m Length: 21.72
[32m[0315 20:31:08 @dqn_agent.py:203][0m episode: 1324, total game step: 31000, epsilon: 1.0
[32m[0315 20:31:10 @dqn_agent.py:203][0m episode: 1368, total game step: 32000, epsilon: 1.0
[32m[0315 20:31:11 @summary_handler.py:101][0m At episode: 32617, Reward: 0.2 (over 100 episodes)
[32m[0315 20:31:11 @summary_handler.py:102][0m Length: 24.3
[32m[0315 20:31:12 @dqn_agent.py:203][0m episode: 1419, total game step: 33000, epsilon: 1.0
[32m[0315 20:31:14 @dqn_agent.py:203][0m episode: 1456, total game step: 34000, epsilon: 1.0
[32m[0315 20:31:16 @dqn_agent.py:203][0m episode: 1495, total game step: 35000, epsilon: 1.0
[32m[0315 20:31:16 @summary_handler.py:101][0m At episode: 35116, Reward: 0.17 (over 100 episodes)
[32m[0315 20:31:16 @summary_handler.py:102][0m Length: 24.99
[32m[0315 20:31:18 @dqn_agent.py:203][0m episode: 1535, total game step: 36000, epsilon: 1.0
[32m[0315 20:31:20 @dqn_agent.py:203][0m episode: 1575, total game step: 37000, epsilon: 1.0
[32m[0315 20:31:21 @summary_handler.py:101][0m At episode: 37703, Reward: 0.17 (over 100 episodes)
[32m[0315 20:31:21 @summary_handler.py:102][0m Length: 25.87
[32m[0315 20:31:22 @dqn_agent.py:203][0m episode: 1612, total game step: 38000, epsilon: 1.0
[32m[0315 20:31:24 @dqn_agent.py:203][0m episode: 1649, total game step: 39000, epsilon: 1.0
[32m[0315 20:31:26 @dqn_agent.py:203][0m episode: 1696, total game step: 40000, epsilon: 1.0
[32m[0315 20:31:26 @summary_handler.py:101][0m At episode: 40106, Reward: 0.16 (over 100 episodes)
[32m[0315 20:31:26 @summary_handler.py:102][0m Length: 24.03
[32m[0315 20:31:28 @dqn_agent.py:203][0m episode: 1737, total game step: 41000, epsilon: 1.0
[32m[0315 20:31:30 @dqn_agent.py:203][0m episode: 1783, total game step: 42000, epsilon: 1.0
[32m[0315 20:31:31 @summary_handler.py:101][0m At episode: 42425, Reward: 0.12 (over 100 episodes)
[32m[0315 20:31:31 @summary_handler.py:102][0m Length: 23.19
[32m[0315 20:31:32 @dqn_agent.py:203][0m episode: 1830, total game step: 43000, epsilon: 1.0
[32m[0315 20:31:34 @dqn_agent.py:203][0m episode: 1876, total game step: 44000, epsilon: 1.0
[32m[0315 20:31:35 @summary_handler.py:101][0m At episode: 44508, Reward: 0.09 (over 100 episodes)
[32m[0315 20:31:35 @summary_handler.py:102][0m Length: 20.83
[32m[0315 20:31:36 @dqn_agent.py:203][0m episode: 1920, total game step: 45000, epsilon: 1.0
[32m[0315 20:31:38 @dqn_agent.py:203][0m episode: 1978, total game step: 46000, epsilon: 1.0
[32m[0315 20:31:39 @summary_handler.py:101][0m At episode: 46452, Reward: 0.11 (over 100 episodes)
[32m[0315 20:31:39 @summary_handler.py:102][0m Length: 19.44
[32m[0315 20:31:40 @dqn_agent.py:203][0m episode: 2024, total game step: 47000, epsilon: 1.0
[32m[0315 20:31:42 @dqn_agent.py:203][0m episode: 2071, total game step: 48000, epsilon: 1.0
[32m[0315 20:31:44 @summary_handler.py:101][0m At episode: 48724, Reward: 0.1 (over 100 episodes)
[32m[0315 20:31:44 @summary_handler.py:102][0m Length: 22.72
[32m[0315 20:31:44 @dqn_agent.py:203][0m episode: 2111, total game step: 49000, epsilon: 1.0
[32m[0315 20:31:46 @dqn_agent.py:203][0m episode: 2153, total game step: 50000, epsilon: 1.0
[32m[0315 20:31:46 @dqn_agent.py:216][0m At time step 0, the target_network is updated
[32m[0315 20:31:47 @network.py:203][0m step: 0, current TD loss: 0.0428347215056
[32m[0315 20:31:47 @dqn_agent.py:216][0m At time step 0, the target_network is updated
[32m[0315 20:31:48 @network.py:203][0m step: 100, current TD loss: 0.0021674525924
[32m[0315 20:31:49 @network.py:203][0m step: 200, current TD loss: 0.000181800365681
[32m[0315 20:31:50 @network.py:203][0m step: 300, current TD loss: 0.0171701908112
[32m[0315 20:31:51 @network.py:203][0m step: 400, current TD loss: 0.0026922437828
[32m[0315 20:31:52 @network.py:203][0m step: 500, current TD loss: 0.015455965884
[32m[0315 20:31:53 @network.py:203][0m step: 600, current TD loss: 6.05286040809e-05
[32m[0315 20:31:54 @network.py:203][0m step: 700, current TD loss: 0.0322418361902
[32m[0315 20:31:55 @network.py:203][0m step: 800, current TD loss: 0.0323574878275
[32m[0315 20:31:57 @network.py:203][0m step: 900, current TD loss: 0.00126623990946
[32m[0315 20:31:58 @dqn_agent.py:203][0m episode: 2194, total game step: 51000, epsilon: 0.99901099
[32m[0315 20:31:58 @network.py:203][0m step: 1000, current TD loss: 0.00133147207089
[32m[0315 20:31:59 @summary_handler.py:101][0m At episode: 51098, Reward: 0.17 (over 100 episodes)
[32m[0315 20:31:59 @summary_handler.py:102][0m Length: 23.74
[32m[0315 20:31:59 @network.py:203][0m step: 1100, current TD loss: 0.000768472265918
[32m[0315 20:32:00 @network.py:203][0m step: 1200, current TD loss: 0.000713341811206
[32m[0315 20:32:01 @network.py:203][0m step: 1300, current TD loss: 0.00121676980052
[32m[0315 20:32:02 @network.py:203][0m step: 1400, current TD loss: 9.17164725251e-05
[32m[0315 20:32:03 @network.py:203][0m step: 1500, current TD loss: 0.00161009386647
[32m[0315 20:32:04 @network.py:203][0m step: 1600, current TD loss: 0.000660201709252
[32m[0315 20:32:05 @network.py:203][0m step: 1700, current TD loss: 0.000243073329329
[32m[0315 20:32:06 @network.py:203][0m step: 1800, current TD loss: 8.91902818694e-05
[32m[0315 20:32:08 @network.py:203][0m step: 1900, current TD loss: 0.000696515548043
[32m[0315 20:32:09 @dqn_agent.py:203][0m episode: 2241, total game step: 52000, epsilon: 0.99802099
[32m[0315 20:32:09 @network.py:203][0m step: 2000, current TD loss: 0.00149331870489
[32m[0315 20:32:10 @network.py:203][0m step: 2100, current TD loss: 0.00118687748909
[32m[0315 20:32:11 @network.py:203][0m step: 2200, current TD loss: 0.000131107546622
[32m[0315 20:32:12 @network.py:203][0m step: 2300, current TD loss: 0.000691224762704
[32m[0315 20:32:13 @network.py:203][0m step: 2400, current TD loss: 0.0183065757155
[32m[0315 20:32:14 @network.py:203][0m step: 2500, current TD loss: 0.0160523224622
[32m[0315 20:32:14 @dqn_agent.py:216][0m At time step 2500, the target_network is updated
[32m[0315 20:32:15 @network.py:203][0m step: 2600, current TD loss: 0.00164330180269
[32m[0315 20:32:16 @network.py:203][0m step: 2700, current TD loss: 0.000851874763612
[32m[0315 20:32:18 @network.py:203][0m step: 2800, current TD loss: 0.0164999496192
[32m[0315 20:32:19 @network.py:203][0m step: 2900, current TD loss: 0.000881898100488
[32m[0315 20:32:20 @dqn_agent.py:203][0m episode: 2286, total game step: 53000, epsilon: 0.99703099
[32m[0315 20:32:20 @network.py:203][0m step: 3000, current TD loss: 0.00109808216803
[32m[0315 20:32:21 @network.py:203][0m step: 3100, current TD loss: 0.000880177365616
[32m[0315 20:32:22 @network.py:203][0m step: 3200, current TD loss: 0.000818168278784
[32m[0315 20:32:23 @summary_handler.py:101][0m At episode: 53276, Reward: 0.07 (over 100 episodes)
[32m[0315 20:32:23 @summary_handler.py:102][0m Length: 21.78
[32m[0315 20:32:23 @network.py:203][0m step: 3300, current TD loss: 0.000908904359676
[32m[0315 20:32:24 @network.py:203][0m step: 3400, current TD loss: 0.0016213899944
[32m[0315 20:32:25 @network.py:203][0m step: 3500, current TD loss: 0.00234467466362
[32m[0315 20:32:26 @network.py:203][0m step: 3600, current TD loss: 0.00152795575559
[32m[0315 20:32:28 @network.py:203][0m step: 3700, current TD loss: 0.00355029781349
[32m[0315 20:32:29 @network.py:203][0m step: 3800, current TD loss: 0.00199406361207
[32m[0315 20:32:30 @network.py:203][0m step: 3900, current TD loss: 0.003965690732
[32m[0315 20:32:31 @dqn_agent.py:203][0m episode: 2327, total game step: 54000, epsilon: 0.99604099
[32m[0315 20:32:31 @network.py:203][0m step: 4000, current TD loss: 0.00160614773631
[32m[0315 20:32:32 @network.py:203][0m step: 4100, current TD loss: 2.76641367236e-05
[32m[0315 20:32:33 @network.py:203][0m step: 4200, current TD loss: 0.0154275577515
[32m[0315 20:32:34 @network.py:203][0m step: 4300, current TD loss: 0.00307195680216
[32m[0315 20:32:35 @network.py:203][0m step: 4400, current TD loss: 0.00198208773509
[32m[0315 20:32:36 @network.py:203][0m step: 4500, current TD loss: 0.000831769488286
[32m[0315 20:32:38 @network.py:203][0m step: 4600, current TD loss: 0.015282756649
[32m[0315 20:32:39 @network.py:203][0m step: 4700, current TD loss: 0.0161965675652
[32m[0315 20:32:40 @network.py:203][0m step: 4800, current TD loss: 0.00160284154117
[32m[0315 20:32:41 @network.py:203][0m step: 4900, current TD loss: 0.000893941847607
[32m[0315 20:32:42 @dqn_agent.py:203][0m episode: 2370, total game step: 55000, epsilon: 0.99505099
[32m[0315 20:32:42 @network.py:203][0m step: 5000, current TD loss: 0.000762177980505
[32m[0315 20:32:42 @dqn_agent.py:216][0m At time step 5000, the target_network is updated
[32m[0315 20:32:43 @network.py:203][0m step: 5100, current TD loss: 0.00152976938989
[32m[0315 20:32:44 @network.py:203][0m step: 5200, current TD loss: 0.00075198878767
[32m[0315 20:32:45 @network.py:203][0m step: 5300, current TD loss: 8.22535075713e-05
[32m[0315 20:32:47 @network.py:203][0m step: 5400, current TD loss: 2.59093230852e-05
[32m[0315 20:32:48 @network.py:203][0m step: 5500, current TD loss: 0.015754930675
[32m[0315 20:32:48 @summary_handler.py:101][0m At episode: 55571, Reward: 0.19 (over 100 episodes)
[32m[0315 20:32:48 @summary_handler.py:102][0m Length: 22.95
[32m[0315 20:32:49 @network.py:203][0m step: 5600, current TD loss: 0.000676355382893
[32m[0315 20:32:50 @network.py:203][0m step: 5700, current TD loss: 0.0317232273519
[32m[0315 20:32:51 @network.py:203][0m step: 5800, current TD loss: 0.00151995639317
[32m[0315 20:32:52 @network.py:203][0m step: 5900, current TD loss: 0.0172371994704
[32m[0315 20:32:53 @dqn_agent.py:203][0m episode: 2421, total game step: 56000, epsilon: 0.99406099
[32m[0315 20:32:53 @network.py:203][0m step: 6000, current TD loss: 0.00133619224653
[32m[0315 20:32:54 @network.py:203][0m step: 6100, current TD loss: 0.0165822636336
[32m[0315 20:32:55 @network.py:203][0m step: 6200, current TD loss: 0.000816786894575
[32m[0315 20:32:56 @network.py:203][0m step: 6300, current TD loss: 0.00224753376096
[32m[0315 20:32:58 @network.py:203][0m step: 6400, current TD loss: 2.56683924817e-05
[32m[0315 20:32:59 @network.py:203][0m step: 6500, current TD loss: 0.000743184471503
[32m[0315 20:33:00 @network.py:203][0m step: 6600, current TD loss: 0.0325296409428
[32m[0315 20:33:01 @network.py:203][0m step: 6700, current TD loss: 0.000662727863528
[32m[0315 20:33:02 @network.py:203][0m step: 6800, current TD loss: 0.0194286834449
[32m[0315 20:33:03 @network.py:203][0m step: 6900, current TD loss: 0.00204471778125
[32m[0315 20:33:04 @dqn_agent.py:203][0m episode: 2469, total game step: 57000, epsilon: 0.99307099
[32m[0315 20:33:04 @network.py:203][0m step: 7000, current TD loss: 3.52955466951e-05
[32m[0315 20:33:05 @network.py:203][0m step: 7100, current TD loss: 7.50995823182e-05
[32m[0315 20:33:07 @network.py:203][0m step: 7200, current TD loss: 0.000690309563652
[32m[0315 20:33:08 @network.py:203][0m step: 7300, current TD loss: 0.00204395595938
[32m[0315 20:33:09 @network.py:203][0m step: 7400, current TD loss: 0.00214826175943
[32m[0315 20:33:10 @network.py:203][0m step: 7500, current TD loss: 0.00253618578427
[32m[0315 20:33:10 @dqn_agent.py:216][0m At time step 7500, the target_network is updated
[32m[0315 20:33:11 @summary_handler.py:101][0m At episode: 57584, Reward: 0.1 (over 100 episodes)
[32m[0315 20:33:11 @summary_handler.py:102][0m Length: 20.13
[32m[0315 20:33:11 @network.py:203][0m step: 7600, current TD loss: 0.00222720578313
[32m[0315 20:33:12 @network.py:203][0m step: 7700, current TD loss: 0.0164407342672
[32m[0315 20:33:13 @network.py:203][0m step: 7800, current TD loss: 0.0174559485167
[32m[0315 20:33:15 @network.py:203][0m step: 7900, current TD loss: 0.0164345037192
[32m[0315 20:33:16 @dqn_agent.py:203][0m episode: 2521, total game step: 58000, epsilon: 0.99208099
[32m[0315 20:33:16 @network.py:203][0m step: 8000, current TD loss: 0.00248321844265
[32m[0315 20:33:17 @network.py:203][0m step: 8100, current TD loss: 0.017112441361
[32m[0315 20:33:18 @network.py:203][0m step: 8200, current TD loss: 0.00156897038687
[32m[0315 20:33:19 @network.py:203][0m step: 8300, current TD loss: 0.00147874653339
[32m[0315 20:33:20 @network.py:203][0m step: 8400, current TD loss: 0.000690520915668
[32m[0315 20:33:21 @network.py:203][0m step: 8500, current TD loss: 0.00321970134974
[32m[0315 20:33:22 @network.py:203][0m step: 8600, current TD loss: 0.000790370919276
[32m[0315 20:33:24 @network.py:203][0m step: 8700, current TD loss: 0.000821192807052
[32m[0315 20:33:25 @network.py:203][0m step: 8800, current TD loss: 0.000954833638389
[32m[0315 20:33:26 @network.py:203][0m step: 8900, current TD loss: 0.000676216208376
[32m[0315 20:33:27 @dqn_agent.py:203][0m episode: 2567, total game step: 59000, epsilon: 0.99109099
[32m[0315 20:33:27 @network.py:203][0m step: 9000, current TD loss: 0.000744946242776
[32m[0315 20:33:28 @network.py:203][0m step: 9100, current TD loss: 0.00166800420266
[32m[0315 20:33:29 @network.py:203][0m step: 9200, current TD loss: 0.000861785025336
[32m[0315 20:33:30 @network.py:203][0m step: 9300, current TD loss: 0.00276966672391
[32m[0315 20:33:31 @network.py:203][0m step: 9400, current TD loss: 0.00161682581529
[32m[0315 20:33:32 @network.py:203][0m step: 9500, current TD loss: 0.00142857735045
[32m[0315 20:33:33 @network.py:203][0m step: 9600, current TD loss: 0.000686591258273
[32m[0315 20:33:35 @network.py:203][0m step: 9700, current TD loss: 0.00219721207395
[32m[0315 20:33:35 @summary_handler.py:101][0m At episode: 59701, Reward: 0.09 (over 100 episodes)
[32m[0315 20:33:35 @summary_handler.py:102][0m Length: 21.17
[32m[0315 20:33:36 @network.py:203][0m step: 9800, current TD loss: 0.00152141111903
[32m[0315 20:33:37 @network.py:203][0m step: 9900, current TD loss: 0.00139724637847
[32m[0315 20:33:38 @dqn_agent.py:203][0m episode: 2613, total game step: 60000, epsilon: 0.99010099
[32m[0315 20:33:38 @network.py:203][0m step: 10000, current TD loss: 0.000957047217526
[32m[0315 20:33:38 @dqn_agent.py:216][0m At time step 10000, the target_network is updated
[32m[0315 20:33:39 @network.py:203][0m step: 10100, current TD loss: 0.000966172432527
[32m[0315 20:33:40 @network.py:203][0m step: 10200, current TD loss: 5.72257631575e-05
[32m[0315 20:33:41 @network.py:203][0m step: 10300, current TD loss: 0.000981912249699
[32m[0315 20:33:42 @network.py:203][0m step: 10400, current TD loss: 0.00256693735719
[32m[0315 20:33:43 @network.py:203][0m step: 10500, current TD loss: 0.0159708186984
[32m[0315 20:33:44 @network.py:203][0m step: 10600, current TD loss: 0.0159452650696
[32m[0315 20:33:46 @network.py:203][0m step: 10700, current TD loss: 0.0155268097296
[32m[0315 20:33:47 @network.py:203][0m step: 10800, current TD loss: 0.000917284924071
[32m[0315 20:33:48 @network.py:203][0m step: 10900, current TD loss: 4.90691672894e-05
[32m[0315 20:33:49 @dqn_agent.py:203][0m episode: 2655, total game step: 61000, epsilon: 0.98911099
[32m[0315 20:33:49 @network.py:203][0m step: 11000, current TD loss: 0.0025929287076
[32m[0315 20:33:50 @network.py:203][0m step: 11100, current TD loss: 6.35143951513e-05
[32m[0315 20:33:52 @network.py:203][0m step: 11200, current TD loss: 0.000163740100106
[32m[0315 20:33:53 @network.py:203][0m step: 11300, current TD loss: 0.00264533935115
[32m[0315 20:33:54 @network.py:203][0m step: 11400, current TD loss: 0.00248611951247
[32m[0315 20:33:55 @network.py:203][0m step: 11500, current TD loss: 0.00179994909558
[32m[0315 20:33:56 @network.py:203][0m step: 11600, current TD loss: 0.000954813964199
[32m[0315 20:33:57 @network.py:203][0m step: 11700, current TD loss: 0.000811463047285
[32m[0315 20:33:59 @network.py:203][0m step: 11800, current TD loss: 2.79967862298e-05
[32m[0315 20:34:00 @network.py:203][0m step: 11900, current TD loss: 0.00164191820659
[32m[0315 20:34:00 @summary_handler.py:101][0m At episode: 61947, Reward: 0.11 (over 100 episodes)
[32m[0315 20:34:00 @summary_handler.py:102][0m Length: 22.46
[32m[0315 20:34:01 @dqn_agent.py:203][0m episode: 2704, total game step: 62000, epsilon: 0.98812099
[32m[0315 20:34:01 @network.py:203][0m step: 12000, current TD loss: 7.0415524533e-05
[32m[0315 20:34:02 @network.py:203][0m step: 12100, current TD loss: 0.000107216241304
[32m[0315 20:34:03 @network.py:203][0m step: 12200, current TD loss: 0.000888668815605
[32m[0315 20:34:05 @network.py:203][0m step: 12300, current TD loss: 0.0175356417894
[32m[0315 20:34:06 @network.py:203][0m step: 12400, current TD loss: 0.0173905752599
[32m[0315 20:34:07 @network.py:203][0m step: 12500, current TD loss: 0.0163361914456
[32m[0315 20:34:07 @dqn_agent.py:216][0m At time step 12500, the target_network is updated
[32m[0315 20:34:08 @network.py:203][0m step: 12600, current TD loss: 0.0155948540196
[32m[0315 20:34:09 @network.py:203][0m step: 12700, current TD loss: 0.00244880048558
[32m[0315 20:34:10 @network.py:203][0m step: 12800, current TD loss: 0.00082858290989
[32m[0315 20:34:11 @network.py:203][0m step: 12900, current TD loss: 0.000862123270053
[32m[0315 20:34:12 @dqn_agent.py:203][0m episode: 2743, total game step: 63000, epsilon: 0.98713099
[32m[0315 20:34:12 @network.py:203][0m step: 13000, current TD loss: 0.000110359760583
[32m[0315 20:34:14 @network.py:203][0m step: 13100, current TD loss: 3.10859613819e-05
[32m[0315 20:34:15 @network.py:203][0m step: 13200, current TD loss: 0.00235947524197
[32m[0315 20:34:16 @network.py:203][0m step: 13300, current TD loss: 0.0160688348114
[32m[0315 20:34:17 @network.py:203][0m step: 13400, current TD loss: 0.000970585562754
[32m[0315 20:34:18 @network.py:203][0m step: 13500, current TD loss: 0.000832977006212
[32m[0315 20:34:20 @network.py:203][0m step: 13600, current TD loss: 0.00258662062697
[32m[0315 20:34:21 @network.py:203][0m step: 13700, current TD loss: 0.000900785962585
[32m[0315 20:34:22 @network.py:203][0m step: 13800, current TD loss: 0.000908919784706
[32m[0315 20:34:23 @network.py:203][0m step: 13900, current TD loss: 0.00174879538827
[32m[0315 20:34:24 @dqn_agent.py:203][0m episode: 2784, total game step: 64000, epsilon: 0.98614099
[32m[0315 20:34:24 @network.py:203][0m step: 14000, current TD loss: 0.0169523078948
[32m[0315 20:34:25 @network.py:203][0m step: 14100, current TD loss: 0.0172050371766
[32m[0315 20:34:27 @network.py:203][0m step: 14200, current TD loss: 0.0025192219764
[32m[0315 20:34:28 @network.py:203][0m step: 14300, current TD loss: 8.26105024316e-05
[32m[0315 20:34:29 @network.py:203][0m step: 14400, current TD loss: 0.00395589694381
[32m[0315 20:34:30 @summary_handler.py:101][0m At episode: 64456, Reward: 0.22 (over 100 episodes)
[32m[0315 20:34:30 @summary_handler.py:102][0m Length: 25.09
[32m[0315 20:34:30 @network.py:203][0m step: 14500, current TD loss: 0.00243194960058
[32m[0315 20:34:31 @network.py:203][0m step: 14600, current TD loss: 0.00162680703215
[32m[0315 20:34:32 @network.py:203][0m step: 14700, current TD loss: 0.00391877721995
[32m[0315 20:34:33 @network.py:203][0m step: 14800, current TD loss: 0.0161917489022
[32m[0315 20:34:35 @network.py:203][0m step: 14900, current TD loss: 0.00168171559926
[32m[0315 20:34:36 @dqn_agent.py:203][0m episode: 2824, total game step: 65000, epsilon: 0.98515099
[32m[0315 20:34:36 @network.py:203][0m step: 15000, current TD loss: 3.45038606611e-05
[32m[0315 20:34:36 @dqn_agent.py:216][0m At time step 15000, the target_network is updated
[32m[0315 20:34:37 @network.py:203][0m step: 15100, current TD loss: 5.71781129111e-05
[32m[0315 20:34:38 @network.py:203][0m step: 15200, current TD loss: 7.17249931768e-05
[32m[0315 20:34:39 @network.py:203][0m step: 15300, current TD loss: 5.38267049706e-05
[32m[0315 20:34:40 @network.py:203][0m step: 15400, current TD loss: 0.000884504057467
[32m[0315 20:34:41 @network.py:203][0m step: 15500, current TD loss: 0.00252493983135
[32m[0315 20:34:42 @network.py:203][0m step: 15600, current TD loss: 0.0167063307017
[32m[0315 20:34:44 @network.py:203][0m step: 15700, current TD loss: 0.00528137013316
[32m[0315 20:34:45 @network.py:203][0m step: 15800, current TD loss: 0.000979578588158
[32m[0315 20:34:46 @network.py:203][0m step: 15900, current TD loss: 0.00266629923135
[32m[0315 20:34:47 @dqn_agent.py:203][0m episode: 2864, total game step: 66000, epsilon: 0.98416099
[32m[0315 20:34:47 @network.py:203][0m step: 16000, current TD loss: 0.00169825565536
[32m[0315 20:34:48 @network.py:203][0m step: 16100, current TD loss: 0.00293096038513
[32m[0315 20:34:49 @network.py:203][0m step: 16200, current TD loss: 0.0164122395217
[32m[0315 20:34:50 @network.py:203][0m step: 16300, current TD loss: 0.0167959053069
[32m[0315 20:34:51 @network.py:203][0m step: 16400, current TD loss: 0.000957182783168
[32m[0315 20:34:52 @network.py:203][0m step: 16500, current TD loss: 0.00266845826991
[32m[0315 20:34:54 @network.py:203][0m step: 16600, current TD loss: 0.00177838734817
[32m[0315 20:34:55 @network.py:203][0m step: 16700, current TD loss: 0.000952902832069
[32m[0315 20:34:56 @network.py:203][0m step: 16800, current TD loss: 0.0163303688169
[32m[0315 20:34:57 @network.py:203][0m step: 16900, current TD loss: 0.000929982459638
[32m[0315 20:34:57 @summary_handler.py:101][0m At episode: 66958, Reward: 0.18 (over 100 episodes)
[32m[0315 20:34:57 @summary_handler.py:102][0m Length: 25.02
[32m[0315 20:34:58 @dqn_agent.py:203][0m episode: 2903, total game step: 67000, epsilon: 0.98317099
[32m[0315 20:34:58 @network.py:203][0m step: 17000, current TD loss: 0.000892829266377
[32m[0315 20:34:59 @network.py:203][0m step: 17100, current TD loss: 0.00271074380726
[32m[0315 20:35:00 @network.py:203][0m step: 17200, current TD loss: 0.00164137035608
[32m[0315 20:35:01 @network.py:203][0m step: 17300, current TD loss: 0.000927414337639
[32m[0315 20:35:02 @network.py:203][0m step: 17400, current TD loss: 0.00196987856179
[32m[0315 20:35:04 @network.py:203][0m step: 17500, current TD loss: 0.00184826308396
[32m[0315 20:35:04 @dqn_agent.py:216][0m At time step 17500, the target_network is updated
[32m[0315 20:35:05 @network.py:203][0m step: 17600, current TD loss: 0.00172778859269
[32m[0315 20:35:06 @network.py:203][0m step: 17700, current TD loss: 0.00082786398707
[32m[0315 20:35:07 @network.py:203][0m step: 17800, current TD loss: 1.996030187e-05
[32m[0315 20:35:08 @network.py:203][0m step: 17900, current TD loss: 0.01783602871
[32m[0315 20:35:09 @dqn_agent.py:203][0m episode: 2946, total game step: 68000, epsilon: 0.98218099
[32m[0315 20:35:09 @network.py:203][0m step: 18000, current TD loss: 0.00259730080143
[32m[0315 20:35:10 @network.py:203][0m step: 18100, current TD loss: 0.000872217642609
[32m[0315 20:35:11 @network.py:203][0m step: 18200, current TD loss: 0.0170250944793
[32m[0315 20:35:13 @network.py:203][0m step: 18300, current TD loss: 0.00344713497907
[32m[0315 20:35:14 @network.py:203][0m step: 18400, current TD loss: 0.0018494380638
[32m[0315 20:35:15 @network.py:203][0m step: 18500, current TD loss: 0.0168327894062
[32m[0315 20:35:16 @network.py:203][0m step: 18600, current TD loss: 5.19344466738e-05
[32m[0315 20:35:17 @network.py:203][0m step: 18700, current TD loss: 0.0171234309673
[32m[0315 20:35:18 @network.py:203][0m step: 18800, current TD loss: 0.015788692981
[32m[0315 20:35:19 @network.py:203][0m step: 18900, current TD loss: 0.00086398771964
[32m[0315 20:35:21 @dqn_agent.py:203][0m episode: 2999, total game step: 69000, epsilon: 0.98119099
[32m[0315 20:35:21 @network.py:203][0m step: 19000, current TD loss: 0.0026166823227
[32m[0315 20:35:21 @summary_handler.py:101][0m At episode: 69005, Reward: 0.11 (over 100 episodes)
[32m[0315 20:35:21 @summary_handler.py:102][0m Length: 20.47
[32m[0315 20:35:22 @network.py:203][0m step: 19100, current TD loss: 0.00175112532452
[32m[0315 20:35:23 @network.py:203][0m step: 19200, current TD loss: 4.60040464532e-05
[32m[0315 20:35:24 @network.py:203][0m step: 19300, current TD loss: 0.016570949927
[32m[0315 20:35:25 @network.py:203][0m step: 19400, current TD loss: 0.00258685695007
[32m[0315 20:35:26 @network.py:203][0m step: 19500, current TD loss: 7.99435947556e-05
[32m[0315 20:35:27 @network.py:203][0m step: 19600, current TD loss: 0.000884719076566
[32m[0315 20:35:29 @network.py:203][0m step: 19700, current TD loss: 0.0025589147117
[32m[0315 20:35:30 @network.py:203][0m step: 19800, current TD loss: 0.000895843084436
[32m[0315 20:35:31 @network.py:203][0m step: 19900, current TD loss: 0.00535450689495
[32m[0315 20:35:32 @dqn_agent.py:203][0m episode: 3046, total game step: 70000, epsilon: 0.98020099
[32m[0315 20:35:32 @network.py:203][0m step: 20000, current TD loss: 6.87266801833e-05
[32m[0315 20:35:32 @dqn_agent.py:216][0m At time step 20000, the target_network is updated
[32m[0315 20:35:33 @network.py:203][0m step: 20100, current TD loss: 0.00260352878831
[32m[0315 20:35:34 @network.py:203][0m step: 20200, current TD loss: 0.00179875944741
[32m[0315 20:35:35 @network.py:203][0m step: 20300, current TD loss: 0.0167649183422
[32m[0315 20:35:37 @network.py:203][0m step: 20400, current TD loss: 0.0192387476563
[32m[0315 20:35:38 @network.py:203][0m step: 20500, current TD loss: 0.00336063979194
[32m[0315 20:35:39 @network.py:203][0m step: 20600, current TD loss: 0.0167711135
[32m[0315 20:35:40 @network.py:203][0m step: 20700, current TD loss: 0.00105111626908
[32m[0315 20:35:41 @network.py:203][0m step: 20800, current TD loss: 0.00358503195457
[32m[0315 20:35:42 @network.py:203][0m step: 20900, current TD loss: 0.000888754322659
[32m[0315 20:35:43 @dqn_agent.py:203][0m episode: 3090, total game step: 71000, epsilon: 0.97921099
[32m[0315 20:35:43 @network.py:203][0m step: 21000, current TD loss: 0.00256789964624
[32m[0315 20:35:45 @network.py:203][0m step: 21100, current TD loss: 5.33688289579e-05
[32m[0315 20:35:45 @summary_handler.py:101][0m At episode: 71173, Reward: 0.08 (over 100 episodes)
[32m[0315 20:35:45 @summary_handler.py:102][0m Length: 21.68
[32m[0315 20:35:46 @network.py:203][0m step: 21200, current TD loss: 6.10963033978e-05
[32m[0315 20:35:47 @network.py:203][0m step: 21300, current TD loss: 0.00252557103522
[32m[0315 20:35:48 @network.py:203][0m step: 21400, current TD loss: 0.000872683245689
[32m[0315 20:35:49 @network.py:203][0m step: 21500, current TD loss: 0.000881901825778
[32m[0315 20:35:50 @network.py:203][0m step: 21600, current TD loss: 4.37501366832e-05
[32m[0315 20:35:51 @network.py:203][0m step: 21700, current TD loss: 0.00172270846087
[32m[0315 20:35:52 @network.py:203][0m step: 21800, current TD loss: 0.0179704092443
[32m[0315 20:35:54 @network.py:203][0m step: 21900, current TD loss: 0.0157276857644
[32m[0315 20:35:55 @dqn_agent.py:203][0m episode: 3135, total game step: 72000, epsilon: 0.97822099
[32m[0315 20:35:55 @network.py:203][0m step: 22000, current TD loss: 0.00258997664787
[32m[0315 20:35:56 @network.py:203][0m step: 22100, current TD loss: 0.000807127566077
[32m[0315 20:35:57 @network.py:203][0m step: 22200, current TD loss: 0.0016878262395
[32m[0315 20:35:58 @network.py:203][0m step: 22300, current TD loss: 0.0016835636925
[32m[0315 20:35:59 @network.py:203][0m step: 22400, current TD loss: 0.0196535568684
[32m[0315 20:36:00 @network.py:203][0m step: 22500, current TD loss: 0.000896267476492
[32m[0315 20:36:00 @dqn_agent.py:216][0m At time step 22500, the target_network is updated
[32m[0315 20:36:01 @network.py:203][0m step: 22600, current TD loss: 0.0179052725434
[32m[0315 20:36:02 @network.py:203][0m step: 22700, current TD loss: 0.0173066407442
[32m[0315 20:36:03 @network.py:203][0m step: 22800, current TD loss: 0.00182879227214
[32m[0315 20:36:05 @network.py:203][0m step: 22900, current TD loss: 0.00180790165905
[32m[0315 20:36:06 @dqn_agent.py:203][0m episode: 3174, total game step: 73000, epsilon: 0.97723099
[32m[0315 20:36:06 @network.py:203][0m step: 23000, current TD loss: 0.00103288283572
[32m[0315 20:36:07 @network.py:203][0m step: 23100, current TD loss: 0.00387491192669
[32m[0315 20:36:08 @network.py:203][0m step: 23200, current TD loss: 0.000108225518488
[32m[0315 20:36:09 @network.py:203][0m step: 23300, current TD loss: 0.00105390476529
[32m[0315 20:36:10 @network.py:203][0m step: 23400, current TD loss: 7.21975156921e-05
[32m[0315 20:36:11 @summary_handler.py:101][0m At episode: 73470, Reward: 0.12 (over 100 episodes)
[32m[0315 20:36:11 @summary_handler.py:102][0m Length: 22.97
[32m[0315 20:36:11 @network.py:203][0m step: 23500, current TD loss: 0.016394386068
[32m[0315 20:36:12 @network.py:203][0m step: 23600, current TD loss: 0.0164150353521
[32m[0315 20:36:13 @network.py:203][0m step: 23700, current TD loss: 0.00188330118544
[32m[0315 20:36:15 @network.py:203][0m step: 23800, current TD loss: 0.003637712216
[32m[0315 20:36:16 @network.py:203][0m step: 23900, current TD loss: 0.00180302653462
[32m[0315 20:36:17 @dqn_agent.py:203][0m episode: 3222, total game step: 74000, epsilon: 0.97624099
[32m[0315 20:36:17 @network.py:203][0m step: 24000, current TD loss: 0.000909210881218
[32m[0315 20:36:18 @network.py:203][0m step: 24100, current TD loss: 0.000977083807811
[32m[0315 20:36:19 @network.py:203][0m step: 24200, current TD loss: 0.0010016313754
[32m[0315 20:36:20 @network.py:203][0m step: 24300, current TD loss: 0.00182439538185
[32m[0315 20:36:21 @network.py:203][0m step: 24400, current TD loss: 0.0172944981605
[32m[0315 20:36:22 @network.py:203][0m step: 24500, current TD loss: 0.00300935772248
[32m[0315 20:36:23 @network.py:203][0m step: 24600, current TD loss: 0.000928268244024
[32m[0315 20:36:24 @network.py:203][0m step: 24700, current TD loss: 0.00368958991021
[32m[0315 20:36:25 @network.py:203][0m step: 24800, current TD loss: 0.00108311709482
[32m[0315 20:36:27 @network.py:203][0m step: 24900, current TD loss: 0.00402659969404
[32m[0315 20:36:28 @dqn_agent.py:203][0m episode: 3256, total game step: 75000, epsilon: 0.97525099
[32m[0315 20:36:28 @network.py:203][0m step: 25000, current TD loss: 0.000908369955141
[32m[0315 20:36:28 @dqn_agent.py:216][0m At time step 25000, the target_network is updated
[32m[0315 20:36:29 @network.py:203][0m step: 25100, current TD loss: 8.42012377689e-05
[32m[0315 20:36:30 @network.py:203][0m step: 25200, current TD loss: 0.00280514638871
[32m[0315 20:36:31 @network.py:203][0m step: 25300, current TD loss: 0.000960703822784
[32m[0315 20:36:32 @network.py:203][0m step: 25400, current TD loss: 0.0179325994104
[32m[0315 20:36:33 @network.py:203][0m step: 25500, current TD loss: 0.00575833115727
[32m[0315 20:36:34 @network.py:203][0m step: 25600, current TD loss: 0.0164002552629
[32m[0315 20:36:35 @network.py:203][0m step: 25700, current TD loss: 0.000965462590102
[32m[0315 20:36:36 @network.py:203][0m step: 25800, current TD loss: 0.0190765410662
[32m[0315 20:36:37 @network.py:203][0m step: 25900, current TD loss: 0.00682489294559
[32m[0315 20:36:39 @dqn_agent.py:203][0m episode: 3290, total game step: 76000, epsilon: 0.97426099
[32m[0315 20:36:39 @network.py:203][0m step: 26000, current TD loss: 0.00105275155511
[32m[0315 20:36:40 @network.py:203][0m step: 26100, current TD loss: 0.0181210134178
[32m[0315 20:36:41 @network.py:203][0m step: 26200, current TD loss: 0.0165491644293
[32m[0315 20:36:42 @summary_handler.py:101][0m At episode: 76287, Reward: 0.25 (over 100 episodes)
[32m[0315 20:36:42 @summary_handler.py:102][0m Length: 28.17
[32m[0315 20:36:42 @network.py:203][0m step: 26300, current TD loss: 0.0310017298907
[32m[0315 20:36:43 @network.py:203][0m step: 26400, current TD loss: 0.00285017536953
[32m[0315 20:36:44 @network.py:203][0m step: 26500, current TD loss: 0.00189085572492
[32m[0315 20:36:45 @network.py:203][0m step: 26600, current TD loss: 0.0018548364751
[32m[0315 20:36:46 @network.py:203][0m step: 26700, current TD loss: 4.57475434814e-05
[32m[0315 20:36:47 @network.py:203][0m step: 26800, current TD loss: 0.00313076213934
[32m[0315 20:36:49 @network.py:203][0m step: 26900, current TD loss: 0.00111924891826
[32m[0315 20:36:50 @dqn_agent.py:203][0m episode: 3334, total game step: 77000, epsilon: 0.97327099
[32m[0315 20:36:50 @network.py:203][0m step: 27000, current TD loss: 0.0010730123613
[32m[0315 20:36:51 @network.py:203][0m step: 27100, current TD loss: 0.0020066476427
[32m[0315 20:36:52 @network.py:203][0m step: 27200, current TD loss: 4.68028811156e-05
[32m[0315 20:36:53 @network.py:203][0m step: 27300, current TD loss: 0.00113426859025
[32m[0315 20:36:54 @network.py:203][0m step: 27400, current TD loss: 0.00195330451243
[32m[0315 20:36:55 @network.py:203][0m step: 27500, current TD loss: 0.00298494659364
[32m[0315 20:36:55 @dqn_agent.py:216][0m At time step 27500, the target_network is updated
[32m[0315 20:36:56 @network.py:203][0m step: 27600, current TD loss: 0.00320824701339
[32m[0315 20:36:57 @network.py:203][0m step: 27700, current TD loss: 3.53053001163e-05
[32m[0315 20:36:59 @network.py:203][0m step: 27800, current TD loss: 0.00111467565876
[32m[0315 20:37:00 @network.py:203][0m step: 27900, current TD loss: 0.00207026395947
[32m[0315 20:37:01 @dqn_agent.py:203][0m episode: 3378, total game step: 78000, epsilon: 0.97228099
[32m[0315 20:37:01 @network.py:203][0m step: 28000, current TD loss: 0.0161422044039
[32m[0315 20:37:02 @network.py:203][0m step: 28100, current TD loss: 0.0164124965668
[32m[0315 20:37:03 @network.py:203][0m step: 28200, current TD loss: 0.000932522700168
[32m[0315 20:37:04 @network.py:203][0m step: 28300, current TD loss: 5.38610256626e-05
[32m[0315 20:37:05 @network.py:203][0m step: 28400, current TD loss: 0.0174854714423
[32m[0315 20:37:06 @summary_handler.py:101][0m At episode: 78466, Reward: 0.14 (over 100 episodes)
[32m[0315 20:37:06 @summary_handler.py:102][0m Length: 21.79
[32m[0315 20:37:06 @network.py:203][0m step: 28500, current TD loss: 0.00100980931893
[32m[0315 20:37:08 @network.py:203][0m step: 28600, current TD loss: 0.00195101683494
[32m[0315 20:37:09 @network.py:203][0m step: 28700, current TD loss: 0.0160116180778
[32m[0315 20:37:10 @network.py:203][0m step: 28800, current TD loss: 0.0330265760422
[32m[0315 20:37:11 @network.py:203][0m step: 28900, current TD loss: 0.00196265499108
[32m[0315 20:37:12 @dqn_agent.py:203][0m episode: 3429, total game step: 79000, epsilon: 0.97129099
[32m[0315 20:37:12 @network.py:203][0m step: 29000, current TD loss: 0.00185034738388
[32m[0315 20:37:13 @network.py:203][0m step: 29100, current TD loss: 0.00378832267597
[32m[0315 20:37:14 @network.py:203][0m step: 29200, current TD loss: 2.8749644116e-05
[32m[0315 20:37:15 @network.py:203][0m step: 29300, current TD loss: 0.000939550809562
[32m[0315 20:37:16 @network.py:203][0m step: 29400, current TD loss: 2.71391963906e-05
[32m[0315 20:37:18 @network.py:203][0m step: 29500, current TD loss: 8.16838000901e-05
[32m[0315 20:37:19 @network.py:203][0m step: 29600, current TD loss: 0.0171562619507
[32m[0315 20:37:20 @network.py:203][0m step: 29700, current TD loss: 0.00221761967987
[32m[0315 20:37:21 @network.py:203][0m step: 29800, current TD loss: 0.00289233634248
[32m[0315 20:37:22 @network.py:203][0m step: 29900, current TD loss: 0.00188874499872
[32m[0315 20:37:23 @dqn_agent.py:203][0m episode: 3470, total game step: 80000, epsilon: 0.97030099
[32m[0315 20:37:23 @network.py:203][0m step: 30000, current TD loss: 0.0325655527413
[32m[0315 20:37:23 @dqn_agent.py:216][0m At time step 30000, the target_network is updated
[32m[0315 20:37:24 @network.py:203][0m step: 30100, current TD loss: 0.000116656228784
[32m[0315 20:37:25 @network.py:203][0m step: 30200, current TD loss: 0.00301493168809
[32m[0315 20:37:26 @network.py:203][0m step: 30300, current TD loss: 0.00401227083057
[32m[0315 20:37:28 @network.py:203][0m step: 30400, current TD loss: 0.00322845811024
[32m[0315 20:37:29 @network.py:203][0m step: 30500, current TD loss: 0.00282027036883
[32m[0315 20:37:30 @summary_handler.py:101][0m At episode: 80573, Reward: 0.1 (over 100 episodes)
[32m[0315 20:37:30 @summary_handler.py:102][0m Length: 21.07
[32m[0315 20:37:30 @network.py:203][0m step: 30600, current TD loss: 2.2536754841e-05
[32m[0315 20:37:31 @network.py:203][0m step: 30700, current TD loss: 5.53271311219e-05
[32m[0315 20:37:32 @network.py:203][0m step: 30800, current TD loss: 0.00104574777652
[32m[0315 20:37:33 @network.py:203][0m step: 30900, current TD loss: 0.0335318297148
[32m[0315 20:37:34 @dqn_agent.py:203][0m episode: 3518, total game step: 81000, epsilon: 0.96931099
[32m[0315 20:37:34 @network.py:203][0m step: 31000, current TD loss: 0.0190290529281
[32m[0315 20:37:35 @network.py:203][0m step: 31100, current TD loss: 0.0171405486763
[32m[0315 20:37:36 @network.py:203][0m step: 31200, current TD loss: 0.00191576662473
[32m[0315 20:37:38 @network.py:203][0m step: 31300, current TD loss: 2.59495755017e-05
[32m[0315 20:37:39 @network.py:203][0m step: 31400, current TD loss: 0.00311371823773
[32m[0315 20:37:40 @network.py:203][0m step: 31500, current TD loss: 0.00327812903561
[32m[0315 20:37:41 @network.py:203][0m step: 31600, current TD loss: 0.00193456734996
[32m[0315 20:37:42 @network.py:203][0m step: 31700, current TD loss: 0.00206903833896
[32m[0315 20:37:43 @network.py:203][0m step: 31800, current TD loss: 2.26501979341e-05
[32m[0315 20:37:44 @network.py:203][0m step: 31900, current TD loss: 0.0201905630529
[32m[0315 20:37:45 @dqn_agent.py:203][0m episode: 3571, total game step: 82000, epsilon: 0.96832099
[32m[0315 20:37:45 @network.py:203][0m step: 32000, current TD loss: 0.0160815156996
[32m[0315 20:37:46 @network.py:203][0m step: 32100, current TD loss: 4.45104888058e-05
[32m[0315 20:37:48 @network.py:203][0m step: 32200, current TD loss: 0.0171801932156
[32m[0315 20:37:49 @network.py:203][0m step: 32300, current TD loss: 0.000126434446429
[32m[0315 20:37:50 @network.py:203][0m step: 32400, current TD loss: 0.00111145072151
[32m[0315 20:37:51 @network.py:203][0m step: 32500, current TD loss: 3.15847428283e-05
[32m[0315 20:37:51 @dqn_agent.py:216][0m At time step 32500, the target_network is updated
[32m[0315 20:37:52 @network.py:203][0m step: 32600, current TD loss: 0.0011274847202
[32m[0315 20:37:53 @network.py:203][0m step: 32700, current TD loss: 0.0020956187509
[32m[0315 20:37:53 @summary_handler.py:101][0m At episode: 82733, Reward: 0.13 (over 100 episodes)
[32m[0315 20:37:53 @summary_handler.py:102][0m Length: 21.6
[32m[0315 20:37:54 @network.py:203][0m step: 32800, current TD loss: 0.00357044977136
[32m[0315 20:37:55 @network.py:203][0m step: 32900, current TD loss: 0.00116749841254
[32m[0315 20:37:56 @dqn_agent.py:203][0m episode: 3612, total game step: 83000, epsilon: 0.96733099
[32m[0315 20:37:56 @network.py:203][0m step: 33000, current TD loss: 2.70803029707e-05
[32m[0315 20:37:58 @network.py:203][0m step: 33100, current TD loss: 4.13898051193e-05
[32m[0315 20:37:59 @network.py:203][0m step: 33200, current TD loss: 0.0186102557927
[32m[0315 20:38:00 @network.py:203][0m step: 33300, current TD loss: 0.0034757645335
[32m[0315 20:38:01 @network.py:203][0m step: 33400, current TD loss: 0.00105860247277
[32m[0315 20:38:02 @network.py:203][0m step: 33500, current TD loss: 0.00114899792243
[32m[0315 20:38:03 @network.py:203][0m step: 33600, current TD loss: 0.0022495565936
[32m[0315 20:38:04 @network.py:203][0m step: 33700, current TD loss: 0.00328273675404
[32m[0315 20:38:05 @network.py:203][0m step: 33800, current TD loss: 4.43909375463e-05
[32m[0315 20:38:07 @network.py:203][0m step: 33900, current TD loss: 0.00333595694974
[32m[0315 20:38:08 @dqn_agent.py:203][0m episode: 3659, total game step: 84000, epsilon: 0.96634099
[32m[0315 20:38:08 @network.py:203][0m step: 34000, current TD loss: 0.00103639427107
[32m[0315 20:38:09 @network.py:203][0m step: 34100, current TD loss: 0.00333223678172
[32m[0315 20:38:10 @network.py:203][0m step: 34200, current TD loss: 8.55616890476e-05
[32m[0315 20:38:11 @network.py:203][0m step: 34300, current TD loss: 0.000108360749437
[32m[0315 20:38:12 @network.py:203][0m step: 34400, current TD loss: 0.00111484539229
[32m[0315 20:38:14 @network.py:203][0m step: 34500, current TD loss: 0.0011353091104
[32m[0315 20:38:15 @network.py:203][0m step: 34600, current TD loss: 0.00527830002829
[32m[0315 20:38:16 @network.py:203][0m step: 34700, current TD loss: 0.0051133101806
[32m[0315 20:38:17 @network.py:203][0m step: 34800, current TD loss: 0.0023808227852
[32m[0315 20:38:18 @network.py:203][0m step: 34900, current TD loss: 0.00102114526089
[32m[0315 20:38:18 @summary_handler.py:101][0m At episode: 84930, Reward: 0.13 (over 100 episodes)
[32m[0315 20:38:18 @summary_handler.py:102][0m Length: 21.97
[32m[0315 20:38:19 @dqn_agent.py:203][0m episode: 3703, total game step: 85000, epsilon: 0.96535099
[32m[0315 20:38:19 @network.py:203][0m step: 35000, current TD loss: 0.00107476720586
[32m[0315 20:38:19 @dqn_agent.py:216][0m At time step 35000, the target_network is updated
[32m[0315 20:38:20 @network.py:203][0m step: 35100, current TD loss: 0.00220494531095
[32m[0315 20:38:22 @network.py:203][0m step: 35200, current TD loss: 0.00117037224118
[32m[0315 20:38:23 @network.py:203][0m step: 35300, current TD loss: 0.00204636412673
[32m[0315 20:38:24 @network.py:203][0m step: 35400, current TD loss: 0.00105043698568
[32m[0315 20:38:25 @network.py:203][0m step: 35500, current TD loss: 3.66918211512e-05
[32m[0315 20:38:26 @network.py:203][0m step: 35600, current TD loss: 0.00106313894503
[32m[0315 20:38:27 @network.py:203][0m step: 35700, current TD loss: 0.00102417101152
[32m[0315 20:38:28 @network.py:203][0m step: 35800, current TD loss: 0.00408110674471
[32m[0315 20:38:29 @network.py:203][0m step: 35900, current TD loss: 0.0166031923145
[32m[0315 20:38:31 @dqn_agent.py:203][0m episode: 3748, total game step: 86000, epsilon: 0.96436099
[32m[0315 20:38:31 @network.py:203][0m step: 36000, current TD loss: 0.00120199460071
[32m[0315 20:38:32 @network.py:203][0m step: 36100, current TD loss: 0.00214171083644
[32m[0315 20:38:33 @network.py:203][0m step: 36200, current TD loss: 0.00214427895844
[32m[0315 20:38:34 @network.py:203][0m step: 36300, current TD loss: 7.75848166086e-05
[32m[0315 20:38:35 @network.py:203][0m step: 36400, current TD loss: 4.10176435253e-05
[32m[0315 20:38:36 @network.py:203][0m step: 36500, current TD loss: 0.00101941335015
[32m[0315 20:38:37 @network.py:203][0m step: 36600, current TD loss: 0.00014240515884
[32m[0315 20:38:39 @network.py:203][0m step: 36700, current TD loss: 0.002172075212
[32m[0315 20:38:40 @network.py:203][0m step: 36800, current TD loss: 0.018403057009
[32m[0315 20:38:41 @network.py:203][0m step: 36900, current TD loss: 0.00315155624412
[32m[0315 20:38:42 @dqn_agent.py:203][0m episode: 3794, total game step: 87000, epsilon: 0.96337099
[32m[0315 20:38:42 @network.py:203][0m step: 37000, current TD loss: 0.00205928320065
[32m[0315 20:38:43 @summary_handler.py:101][0m At episode: 87096, Reward: 0.21 (over 100 episodes)
[32m[0315 20:38:43 @summary_handler.py:102][0m Length: 21.66
[32m[0315 20:38:43 @network.py:203][0m step: 37100, current TD loss: 0.00205581402406
[32m[0315 20:38:44 @network.py:203][0m step: 37200, current TD loss: 0.00358826620504
[32m[0315 20:38:45 @network.py:203][0m step: 37300, current TD loss: 0.000989564461634
[32m[0315 20:38:47 @network.py:203][0m step: 37400, current TD loss: 0.0337088517845
[32m[0315 20:38:48 @network.py:203][0m step: 37500, current TD loss: 0.0024345824495
[32m[0315 20:38:48 @dqn_agent.py:216][0m At time step 37500, the target_network is updated
[32m[0315 20:46:40 @network.py:203][0m step: 37600, current TD loss: 0.00207986170426
[32m[0315 20:46:41 @network.py:203][0m step: 37700, current TD loss: 5.066070662e-05
[32m[0315 20:46:43 @network.py:203][0m step: 37800, current TD loss: 5.47574309167e-05
[32m[0315 20:46:44 @network.py:203][0m step: 37900, current TD loss: 7.67303572502e-05
[32m[0315 20:46:45 @dqn_agent.py:203][0m episode: 3845, total game step: 88000, epsilon: 0.96238099
[32m[0315 20:46:45 @network.py:203][0m step: 38000, current TD loss: 5.16140753462e-05
[32m[0315 20:46:46 @network.py:203][0m step: 38100, current TD loss: 0.00116709456779
[32m[0315 20:46:47 @network.py:203][0m step: 38200, current TD loss: 0.00221980852075
[32m[0315 20:46:48 @network.py:203][0m step: 38300, current TD loss: 0.00107848166954
[32m[0315 20:46:49 @network.py:203][0m step: 38400, current TD loss: 0.0329370647669
[32m[0315 20:46:50 @network.py:203][0m step: 38500, current TD loss: 0.0170255564153
[32m[0315 20:46:52 @network.py:203][0m step: 38600, current TD loss: 0.00224493374117
[32m[0315 20:46:53 @network.py:203][0m step: 38700, current TD loss: 0.00454525882378
[32m[0315 20:46:54 @network.py:203][0m step: 38800, current TD loss: 0.00325896055438
[32m[0315 20:46:55 @network.py:203][0m step: 38900, current TD loss: 0.00108676427044
[32m[0315 20:46:56 @dqn_agent.py:203][0m episode: 3892, total game step: 89000, epsilon: 0.96139099
[32m[0315 20:46:56 @network.py:203][0m step: 39000, current TD loss: 0.0052777309902
[32m[0315 20:46:58 @network.py:203][0m step: 39100, current TD loss: 0.00110989576206
[32m[0315 20:46:58 @summary_handler.py:101][0m At episode: 89161, Reward: 0.07 (over 100 episodes)
[32m[0315 20:46:58 @summary_handler.py:102][0m Length: 20.65
[32m[0315 20:46:59 @network.py:203][0m step: 39200, current TD loss: 0.00226204982027
[32m[0315 20:47:00 @network.py:203][0m step: 39300, current TD loss: 0.0011077823583
[32m[0315 20:47:01 @network.py:203][0m step: 39400, current TD loss: 0.0023332615383
[32m[0315 20:47:02 @network.py:203][0m step: 39500, current TD loss: 0.00452958373353
[32m[0315 20:47:04 @network.py:203][0m step: 39600, current TD loss: 0.00111673574429
[32m[0315 20:47:05 @network.py:203][0m step: 39700, current TD loss: 0.00116023828741
[32m[0315 20:47:06 @network.py:203][0m step: 39800, current TD loss: 0.0022782497108
[32m[0315 20:47:07 @network.py:203][0m step: 39900, current TD loss: 5.57007369935e-05
[32m[0315 20:47:08 @dqn_agent.py:203][0m episode: 3948, total game step: 90000, epsilon: 0.96040099
[32m[0315 20:47:08 @network.py:203][0m step: 40000, current TD loss: 0.0181175321341
[32m[0315 20:47:08 @dqn_agent.py:216][0m At time step 40000, the target_network is updated
[32m[0315 20:47:09 @network.py:203][0m step: 40100, current TD loss: 0.0160967838019
[32m[0315 20:47:10 @network.py:203][0m step: 40200, current TD loss: 4.90705679113e-05
[32m[0315 20:47:12 @network.py:203][0m step: 40300, current TD loss: 6.14625096205e-05
[32m[0315 20:47:13 @network.py:203][0m step: 40400, current TD loss: 0.000145917132613
[32m[0315 20:47:14 @network.py:203][0m step: 40500, current TD loss: 0.00120902701747
[32m[0315 20:47:15 @network.py:203][0m step: 40600, current TD loss: 0.0034832758829
[32m[0315 20:47:16 @network.py:203][0m step: 40700, current TD loss: 3.97193580284e-05
[32m[0315 20:47:17 @network.py:203][0m step: 40800, current TD loss: 4.1572831833e-05
[32m[0315 20:47:18 @network.py:203][0m step: 40900, current TD loss: 0.00114974624012
[32m[0315 20:47:19 @dqn_agent.py:203][0m episode: 3999, total game step: 91000, epsilon: 0.95941099
[32m[0315 20:47:19 @network.py:203][0m step: 41000, current TD loss: 0.00239085010253
[32m[0315 20:47:20 @summary_handler.py:101][0m At episode: 91001, Reward: 0.05 (over 100 episodes)
[32m[0315 20:47:20 @summary_handler.py:102][0m Length: 18.4
[32m[0315 20:47:21 @network.py:203][0m step: 41100, current TD loss: 0.00116194132715
[32m[0315 20:47:22 @network.py:203][0m step: 41200, current TD loss: 0.00233012344688
[32m[0315 20:47:23 @network.py:203][0m step: 41300, current TD loss: 2.5916055165e-05
[32m[0315 20:47:24 @network.py:203][0m step: 41400, current TD loss: 0.00228067603894
[32m[0315 20:47:25 @network.py:203][0m step: 41500, current TD loss: 0.0182884633541
[32m[0315 20:47:26 @network.py:203][0m step: 41600, current TD loss: 0.00235918862745
[32m[0315 20:47:28 @network.py:203][0m step: 41700, current TD loss: 0.000203612129553
[32m[0315 20:47:29 @network.py:203][0m step: 41800, current TD loss: 0.00227928324603
[32m[0315 20:47:30 @network.py:203][0m step: 41900, current TD loss: 0.00121642730664
[32m[0315 20:47:31 @dqn_agent.py:203][0m episode: 4047, total game step: 92000, epsilon: 0.95842099
[32m[0315 20:47:31 @network.py:203][0m step: 42000, current TD loss: 5.52929777768e-05
[32m[0315 20:47:32 @network.py:203][0m step: 42100, current TD loss: 0.00374792749062
[32m[0315 20:47:33 @network.py:203][0m step: 42200, current TD loss: 0.00466469395906
[32m[0315 20:47:34 @network.py:203][0m step: 42300, current TD loss: 0.00133543403354
[32m[0315 20:47:35 @network.py:203][0m step: 42400, current TD loss: 3.61803613487e-05
[32m[0315 20:47:37 @network.py:203][0m step: 42500, current TD loss: 0.00123131973669
[32m[0315 20:47:37 @dqn_agent.py:216][0m At time step 42500, the target_network is updated
[32m[0315 20:47:38 @network.py:203][0m step: 42600, current TD loss: 0.00496896076947
[32m[0315 20:47:39 @network.py:203][0m step: 42700, current TD loss: 0.00350504321977
[32m[0315 20:47:40 @network.py:203][0m step: 42800, current TD loss: 0.00565726589411
[32m[0315 20:47:41 @network.py:203][0m step: 42900, current TD loss: 0.0174870733172
[32m[0315 20:47:42 @dqn_agent.py:203][0m episode: 4090, total game step: 93000, epsilon: 0.95743099
[32m[0315 20:47:42 @network.py:203][0m step: 43000, current TD loss: 4.92195467814e-05
[32m[0315 20:47:43 @network.py:203][0m step: 43100, current TD loss: 0.00232493667863
[32m[0315 20:47:44 @network.py:203][0m step: 43200, current TD loss: 0.00111989874858
[32m[0315 20:47:46 @network.py:203][0m step: 43300, current TD loss: 0.00119712390006
[32m[0315 20:47:46 @summary_handler.py:101][0m At episode: 93351, Reward: 0.17 (over 100 episodes)
[32m[0315 20:47:46 @summary_handler.py:102][0m Length: 23.5
[32m[0315 20:47:47 @network.py:203][0m step: 43400, current TD loss: 0.00313946721144
[32m[0315 20:47:48 @network.py:203][0m step: 43500, current TD loss: 1.00027191365e-05
[32m[0315 20:47:49 @network.py:203][0m step: 43600, current TD loss: 0.032524600625
[32m[0315 20:47:50 @network.py:203][0m step: 43700, current TD loss: 0.00232002232224
[32m[0315 20:47:51 @network.py:203][0m step: 43800, current TD loss: 0.0011251247488
[32m[0315 20:47:52 @network.py:203][0m step: 43900, current TD loss: 0.00457442598417
[32m[0315 20:47:53 @dqn_agent.py:203][0m episode: 4129, total game step: 94000, epsilon: 0.95644099
[32m[0315 20:47:53 @network.py:203][0m step: 44000, current TD loss: 0.00233510229737
[32m[0315 20:47:55 @network.py:203][0m step: 44100, current TD loss: 0.00234134495258
[32m[0315 20:47:56 @network.py:203][0m step: 44200, current TD loss: 0.00306755676866
[32m[0315 20:47:57 @network.py:203][0m step: 44300, current TD loss: 8.86516208993e-05
[32m[0315 20:47:58 @network.py:203][0m step: 44400, current TD loss: 0.00119276437908
[32m[0315 20:47:59 @network.py:203][0m step: 44500, current TD loss: 0.00116939959116
[32m[0315 20:48:00 @network.py:203][0m step: 44600, current TD loss: 0.000124840487842
[32m[0315 20:48:01 @network.py:203][0m step: 44700, current TD loss: 0.00115690683015
[32m[0315 20:48:02 @network.py:203][0m step: 44800, current TD loss: 5.25267387275e-05
[32m[0315 20:48:04 @network.py:203][0m step: 44900, current TD loss: 0.0190543737262
[32m[0315 20:48:05 @dqn_agent.py:203][0m episode: 4182, total game step: 95000, epsilon: 0.95545099
[32m[0315 20:48:05 @network.py:203][0m step: 45000, current TD loss: 0.00324576464482
[32m[0315 20:48:05 @dqn_agent.py:216][0m At time step 45000, the target_network is updated
[32m[0315 20:48:06 @network.py:203][0m step: 45100, current TD loss: 0.00409580767155
[32m[0315 20:48:07 @network.py:203][0m step: 45200, current TD loss: 0.0184150375426
[32m[0315 20:48:08 @network.py:203][0m step: 45300, current TD loss: 0.00219384813681
[32m[0315 20:48:09 @network.py:203][0m step: 45400, current TD loss: 7.29049934307e-05
[32m[0315 20:48:09 @summary_handler.py:101][0m At episode: 95421, Reward: 0.06 (over 100 episodes)
[32m[0315 20:48:09 @summary_handler.py:102][0m Length: 20.7
[32m[0315 20:48:10 @network.py:203][0m step: 45500, current TD loss: 0.0021640334744
[32m[0315 20:48:11 @network.py:203][0m step: 45600, current TD loss: 0.00344150606543
[32m[0315 20:48:13 @network.py:203][0m step: 45700, current TD loss: 0.00234320643358
[32m[0315 20:48:14 @network.py:203][0m step: 45800, current TD loss: 0.0011867149733
[32m[0315 20:48:15 @network.py:203][0m step: 45900, current TD loss: 7.12559558451e-05
[32m[0315 20:48:16 @dqn_agent.py:203][0m episode: 4228, total game step: 96000, epsilon: 0.95446099
[32m[0315 20:48:16 @network.py:203][0m step: 46000, current TD loss: 0.0195444636047
[32m[0315 20:48:17 @network.py:203][0m step: 46100, current TD loss: 0.00116888666525
[32m[0315 20:48:18 @network.py:203][0m step: 46200, current TD loss: 0.00208324985579
[32m[0315 20:48:19 @network.py:203][0m step: 46300, current TD loss: 0.0188164170831
[32m[0315 20:48:20 @network.py:203][0m step: 46400, current TD loss: 0.00427138293162
[32m[0315 20:48:22 @network.py:203][0m step: 46500, current TD loss: 0.00314449612051
[32m[0315 20:48:23 @network.py:203][0m step: 46600, current TD loss: 0.00328026432544
[32m[0315 20:48:24 @network.py:203][0m step: 46700, current TD loss: 0.0020388213452
[32m[0315 20:48:25 @network.py:203][0m step: 46800, current TD loss: 0.00341509678401
[32m[0315 20:48:26 @network.py:203][0m step: 46900, current TD loss: 0.00121171853971
[32m[0315 20:48:28 @dqn_agent.py:203][0m episode: 4279, total game step: 97000, epsilon: 0.95347099
[32m[0315 20:48:28 @network.py:203][0m step: 47000, current TD loss: 0.00133161968552
[32m[0315 20:48:29 @network.py:203][0m step: 47100, current TD loss: 0.00210951943882
[32m[0315 20:48:30 @network.py:203][0m step: 47200, current TD loss: 0.00100153149106
[32m[0315 20:48:31 @network.py:203][0m step: 47300, current TD loss: 0.00104490458034
[32m[0315 20:48:32 @network.py:203][0m step: 47400, current TD loss: 0.00107753253542
[32m[0315 20:48:33 @summary_handler.py:101][0m At episode: 97446, Reward: 0.09 (over 100 episodes)
[32m[0315 20:48:33 @summary_handler.py:102][0m Length: 20.25
[32m[0315 20:48:33 @network.py:203][0m step: 47500, current TD loss: 0.00110063725151
[32m[0315 20:48:33 @dqn_agent.py:216][0m At time step 47500, the target_network is updated
[32m[0315 20:48:34 @network.py:203][0m step: 47600, current TD loss: 0.020287046209
[32m[0315 20:48:35 @network.py:203][0m step: 47700, current TD loss: 0.0202565193176
[32m[0315 20:48:36 @network.py:203][0m step: 47800, current TD loss: 0.00296450825408
[32m[0315 20:48:38 @network.py:203][0m step: 47900, current TD loss: 0.00405303528532
[32m[0315 20:48:39 @dqn_agent.py:203][0m episode: 4319, total game step: 98000, epsilon: 0.95248099
[32m[0315 20:48:39 @network.py:203][0m step: 48000, current TD loss: 0.0181417241693
[32m[0315 20:48:40 @network.py:203][0m step: 48100, current TD loss: 0.00241960398853
[32m[0315 20:48:41 @network.py:203][0m step: 48200, current TD loss: 0.00337010179646
[32m[0315 20:48:42 @network.py:203][0m step: 48300, current TD loss: 0.000996589194983
[32m[0315 20:48:43 @network.py:203][0m step: 48400, current TD loss: 0.0021452002693
[32m[0315 20:48:44 @network.py:203][0m step: 48500, current TD loss: 0.00406602071598
[32m[0315 20:48:46 @network.py:203][0m step: 48600, current TD loss: 0.00196701381356
[32m[0315 20:48:47 @network.py:203][0m step: 48700, current TD loss: 4.32259475929e-05
[32m[0315 20:48:48 @network.py:203][0m step: 48800, current TD loss: 0.00211922824383
[32m[0315 20:48:49 @network.py:203][0m step: 48900, current TD loss: 0.00211042189039
[32m[0315 20:48:50 @dqn_agent.py:203][0m episode: 4370, total game step: 99000, epsilon: 0.95149099
[32m[0315 20:48:50 @network.py:203][0m step: 49000, current TD loss: 0.00109821313526
[32m[0315 20:48:51 @network.py:203][0m step: 49100, current TD loss: 0.0318960174918
[32m[0315 20:48:52 @network.py:203][0m step: 49200, current TD loss: 0.00114014348947
[32m[0315 20:48:53 @network.py:203][0m step: 49300, current TD loss: 0.00215950934216
[32m[0315 20:48:54 @network.py:203][0m step: 49400, current TD loss: 0.0161018334329
[32m[0315 20:48:56 @network.py:203][0m step: 49500, current TD loss: 0.0194155927747
[32m[0315 20:48:57 @network.py:203][0m step: 49600, current TD loss: 0.00195628358051
[32m[0315 20:48:57 @summary_handler.py:101][0m At episode: 99667, Reward: 0.12 (over 100 episodes)
[32m[0315 20:48:57 @summary_handler.py:102][0m Length: 22.21
[32m[0315 20:48:58 @network.py:203][0m step: 49700, current TD loss: 0.00113458035048
[32m[0315 20:48:59 @network.py:203][0m step: 49800, current TD loss: 0.00217250059359
[32m[0315 20:49:00 @network.py:203][0m step: 49900, current TD loss: 0.00221261265688
[32m[0315 20:49:01 @dqn_agent.py:203][0m episode: 4419, total game step: 100000, epsilon: 0.95050099
[32m[0315 20:49:01 @network.py:203][0m step: 50000, current TD loss: 0.00105622154661
[32m[0315 20:49:01 @dqn_agent.py:216][0m At time step 50000, the target_network is updated
[32m[0315 20:49:02 @network.py:203][0m step: 50100, current TD loss: 0.00222284672782
[32m[0315 20:49:03 @network.py:203][0m step: 50200, current TD loss: 0.0220193266869
[32m[0315 20:49:05 @network.py:203][0m step: 50300, current TD loss: 3.03605920635e-05
[32m[0315 20:49:06 @network.py:203][0m step: 50400, current TD loss: 0.00325922155753
[32m[0315 20:49:07 @network.py:203][0m step: 50500, current TD loss: 0.00319629721344
[32m[0315 20:49:08 @network.py:203][0m step: 50600, current TD loss: 0.0170680303127
[32m[0315 20:49:09 @network.py:203][0m step: 50700, current TD loss: 0.0022072843276
[32m[0315 20:49:10 @network.py:203][0m step: 50800, current TD loss: 0.00101752055343
[32m[0315 20:49:12 @network.py:203][0m step: 50900, current TD loss: 0.0153650091961
[32m[0315 20:49:13 @dqn_agent.py:203][0m episode: 4458, total game step: 101000, epsilon: 0.94951099
[32m[0315 20:49:13 @network.py:203][0m step: 51000, current TD loss: 9.46848012973e-05
[32m[0315 20:49:14 @network.py:203][0m step: 51100, current TD loss: 0.00755013898015
[32m[0315 20:49:15 @network.py:203][0m step: 51200, current TD loss: 0.00317517411895
[32m[0315 20:49:16 @network.py:203][0m step: 51300, current TD loss: 0.0010278619593
[32m[0315 20:49:17 @network.py:203][0m step: 51400, current TD loss: 0.00131115538534
[32m[0315 20:49:18 @network.py:203][0m step: 51500, current TD loss: 0.00104750134051
[32m[0315 20:49:19 @network.py:203][0m step: 51600, current TD loss: 0.00205909786746
[32m[0315 20:49:21 @network.py:203][0m step: 51700, current TD loss: 0.0195868816227
[32m[0315 20:49:22 @network.py:203][0m step: 51800, current TD loss: 0.0173876192421
[32m[0315 20:49:23 @summary_handler.py:101][0m At episode: 101894, Reward: 0.15 (over 100 episodes)
[32m[0315 20:49:23 @summary_handler.py:102][0m Length: 22.27
[32m[0315 20:49:23 @network.py:203][0m step: 51900, current TD loss: 0.00113093655091
[32m[0315 20:49:24 @dqn_agent.py:203][0m episode: 4502, total game step: 102000, epsilon: 0.94852099
[32m[0315 20:49:24 @network.py:203][0m step: 52000, current TD loss: 0.0022713476792
[32m[0315 20:49:25 @network.py:203][0m step: 52100, current TD loss: 0.00108152453322
[32m[0315 20:49:26 @network.py:203][0m step: 52200, current TD loss: 0.0341421253979
[32m[0315 20:49:27 @network.py:203][0m step: 52300, current TD loss: 0.00213073845953
[32m[0315 20:49:28 @network.py:203][0m step: 52400, current TD loss: 0.0179693531245
[32m[0315 20:49:30 @network.py:203][0m step: 52500, current TD loss: 0.0159577112645
[32m[0315 20:49:30 @dqn_agent.py:216][0m At time step 52500, the target_network is updated
[32m[0315 20:49:31 @network.py:203][0m step: 52600, current TD loss: 0.000982806319371
[32m[0315 20:49:32 @network.py:203][0m step: 52700, current TD loss: 0.0173193309456
[32m[0315 20:49:33 @network.py:203][0m step: 52800, current TD loss: 0.00305424816906
[32m[0315 20:49:34 @network.py:203][0m step: 52900, current TD loss: 0.0329744815826
[32m[0315 20:49:35 @dqn_agent.py:203][0m episode: 4549, total game step: 103000, epsilon: 0.94753099
[32m[0315 20:49:35 @network.py:203][0m step: 53000, current TD loss: 0.0182266552001
[32m[0315 20:49:36 @network.py:203][0m step: 53100, current TD loss: 6.04600718361e-05
[32m[0315 20:49:37 @network.py:203][0m step: 53200, current TD loss: 0.00105911307037
[32m[0315 20:49:39 @network.py:203][0m step: 53300, current TD loss: 0.00518294936046
[32m[0315 20:49:40 @network.py:203][0m step: 53400, current TD loss: 0.00197660364211
[32m[0315 20:49:41 @network.py:203][0m step: 53500, current TD loss: 0.00100943655707
[32m[0315 20:49:42 @network.py:203][0m step: 53600, current TD loss: 0.0320762991905
[32m[0315 20:49:43 @network.py:203][0m step: 53700, current TD loss: 0.00297877588309
[32m[0315 20:49:44 @network.py:203][0m step: 53800, current TD loss: 0.017882861197
[32m[0315 20:49:45 @network.py:203][0m step: 53900, current TD loss: 0.00315282237716
[32m[0315 20:49:46 @dqn_agent.py:203][0m episode: 4595, total game step: 104000, epsilon: 0.94654099
[32m[0315 20:49:46 @network.py:203][0m step: 54000, current TD loss: 0.0020815404132
[32m[0315 20:49:47 @summary_handler.py:101][0m At episode: 104073, Reward: 0.1 (over 100 episodes)
[32m[0315 20:49:47 @summary_handler.py:102][0m Length: 21.79
[32m[0315 20:49:47 @network.py:203][0m step: 54100, current TD loss: 0.00214899447747
[32m[0315 20:49:49 @network.py:203][0m step: 54200, current TD loss: 0.0179132577032
[32m[0315 20:49:50 @network.py:203][0m step: 54300, current TD loss: 3.12523334287e-05
[32m[0315 20:49:51 @network.py:203][0m step: 54400, current TD loss: 0.00107129698154
[32m[0315 20:49:52 @network.py:203][0m step: 54500, current TD loss: 0.0176539681852
[32m[0315 20:49:53 @network.py:203][0m step: 54600, current TD loss: 0.0191918183118
[32m[0315 20:49:54 @network.py:203][0m step: 54700, current TD loss: 0.0166807696223
[32m[0315 20:49:56 @network.py:203][0m step: 54800, current TD loss: 0.00316866114736
[32m[0315 20:49:57 @network.py:203][0m step: 54900, current TD loss: 0.00518314074725
[32m[0315 20:49:58 @dqn_agent.py:203][0m episode: 4652, total game step: 105000, epsilon: 0.94555099
[32m[0315 20:49:58 @network.py:203][0m step: 55000, current TD loss: 0.00201877881773
[32m[0315 20:49:58 @dqn_agent.py:216][0m At time step 55000, the target_network is updated
[32m[0315 20:49:59 @network.py:203][0m step: 55100, current TD loss: 0.00381974270567
[32m[0315 20:50:00 @network.py:203][0m step: 55200, current TD loss: 0.0020631426014
[32m[0315 20:50:01 @network.py:203][0m step: 55300, current TD loss: 0.0197356585413
[32m[0315 20:50:02 @network.py:203][0m step: 55400, current TD loss: 2.93216016871e-05
[32m[0315 20:50:03 @network.py:203][0m step: 55500, current TD loss: 0.00200493074954
[32m[0315 20:50:04 @network.py:203][0m step: 55600, current TD loss: 0.00103066070005
[32m[0315 20:50:06 @network.py:203][0m step: 55700, current TD loss: 0.0171610116959
[32m[0315 20:50:07 @network.py:203][0m step: 55800, current TD loss: 0.000997748225927
[32m[0315 20:50:08 @network.py:203][0m step: 55900, current TD loss: 0.00195198669098
[32m[0315 20:50:09 @dqn_agent.py:203][0m episode: 4693, total game step: 106000, epsilon: 0.94456099
[32m[0315 20:50:09 @network.py:203][0m step: 56000, current TD loss: 0.032792057842
[32m[0315 20:50:10 @network.py:203][0m step: 56100, current TD loss: 0.00106554094236
[32m[0315 20:50:10 @summary_handler.py:101][0m At episode: 106126, Reward: 0.09 (over 100 episodes)
[32m[0315 20:50:10 @summary_handler.py:102][0m Length: 20.53
[32m[0315 20:50:11 @network.py:203][0m step: 56200, current TD loss: 0.00204196153209
[32m[0315 20:50:12 @network.py:203][0m step: 56300, current TD loss: 0.00193207233679
[32m[0315 20:50:13 @network.py:203][0m step: 56400, current TD loss: 0.00192149472423
[32m[0315 20:50:15 @network.py:203][0m step: 56500, current TD loss: 0.00189471349586
[32m[0315 20:50:16 @network.py:203][0m step: 56600, current TD loss: 0.00226495554671
[32m[0315 20:50:17 @network.py:203][0m step: 56700, current TD loss: 0.000980635755695
[32m[0315 20:50:18 @network.py:203][0m step: 56800, current TD loss: 0.00398590089753
[32m[0315 20:50:19 @network.py:203][0m step: 56900, current TD loss: 0.00292739085853
[32m[0315 20:50:20 @dqn_agent.py:203][0m episode: 4736, total game step: 107000, epsilon: 0.94357099
[32m[0315 20:50:20 @network.py:203][0m step: 57000, current TD loss: 0.00202227896079
[32m[0315 20:50:21 @network.py:203][0m step: 57100, current TD loss: 6.68427528581e-05
[32m[0315 20:50:23 @network.py:203][0m step: 57200, current TD loss: 0.00233657262288
[32m[0315 20:50:24 @network.py:203][0m step: 57300, current TD loss: 0.00213280506432
[32m[0315 20:50:25 @network.py:203][0m step: 57400, current TD loss: 0.00102928944398
[32m[0315 20:50:26 @network.py:203][0m step: 57500, current TD loss: 5.07885270054e-05
[32m[0315 20:50:26 @dqn_agent.py:216][0m At time step 57500, the target_network is updated
[32m[0315 20:50:27 @network.py:203][0m step: 57600, current TD loss: 0.0344928950071
[32m[0315 20:50:28 @network.py:203][0m step: 57700, current TD loss: 0.0175248533487
[32m[0315 20:50:29 @network.py:203][0m step: 57800, current TD loss: 0.00208614347503
[32m[0315 20:50:30 @network.py:203][0m step: 57900, current TD loss: 0.00283581065014
[32m[0315 20:50:32 @dqn_agent.py:203][0m episode: 4786, total game step: 108000, epsilon: 0.94258099
[32m[0315 20:50:32 @network.py:203][0m step: 58000, current TD loss: 3.5874232708e-05
[32m[0315 20:50:33 @network.py:203][0m step: 58100, current TD loss: 0.000913787051104
[32m[0315 20:50:34 @network.py:203][0m step: 58200, current TD loss: 0.0027945144102
[32m[0315 20:50:34 @summary_handler.py:101][0m At episode: 108201, Reward: 0.15 (over 100 episodes)
[32m[0315 20:50:34 @summary_handler.py:102][0m Length: 20.75
[32m[0315 20:50:35 @network.py:203][0m step: 58300, current TD loss: 0.00280107324943
[32m[0315 20:50:36 @network.py:203][0m step: 58400, current TD loss: 0.00101956678554
[32m[0315 20:50:37 @network.py:203][0m step: 58500, current TD loss: 0.00383680406958
[32m[0315 20:50:38 @network.py:203][0m step: 58600, current TD loss: 0.000999080948532
[32m[0315 20:50:40 @network.py:203][0m step: 58700, current TD loss: 5.77401151531e-05
[32m[0315 20:50:41 @network.py:203][0m step: 58800, current TD loss: 0.00176947389264
[32m[0315 20:50:42 @network.py:203][0m step: 58900, current TD loss: 0.00404189527035
[32m[0315 20:50:43 @dqn_agent.py:203][0m episode: 4839, total game step: 109000, epsilon: 0.94159099
[32m[0315 20:50:43 @network.py:203][0m step: 59000, current TD loss: 0.000860586296767
[32m[0315 20:50:44 @network.py:203][0m step: 59100, current TD loss: 0.00288577005267
[32m[0315 20:50:45 @network.py:203][0m step: 59200, current TD loss: 0.000949233304709
[32m[0315 20:50:46 @network.py:203][0m step: 59300, current TD loss: 4.58929462184e-05
[32m[0315 20:50:48 @network.py:203][0m step: 59400, current TD loss: 0.00285408925265
[32m[0315 20:50:49 @network.py:203][0m step: 59500, current TD loss: 0.00107378303073
[32m[0315 20:50:50 @network.py:203][0m step: 59600, current TD loss: 0.00279145734385
[32m[0315 20:50:51 @network.py:203][0m step: 59700, current TD loss: 0.00109114486258
[32m[0315 20:50:52 @network.py:203][0m step: 59800, current TD loss: 0.00191002769861
[32m[0315 20:50:53 @network.py:203][0m step: 59900, current TD loss: 0.00281405774876
[32m[0315 20:50:54 @dqn_agent.py:203][0m episode: 4891, total game step: 110000, epsilon: 0.94060099
[32m[0315 20:50:54 @network.py:203][0m step: 60000, current TD loss: 0.00204086862504
[32m[0315 20:50:54 @dqn_agent.py:216][0m At time step 60000, the target_network is updated
[32m[0315 20:50:55 @network.py:203][0m step: 60100, current TD loss: 0.0019552775193
[32m[0315 20:50:57 @network.py:203][0m step: 60200, current TD loss: 0.000113104455522
[32m[0315 20:50:57 @summary_handler.py:101][0m At episode: 110210, Reward: 0.1 (over 100 episodes)
[32m[0315 20:50:57 @summary_handler.py:102][0m Length: 20.09
[32m[0315 20:50:58 @network.py:203][0m step: 60300, current TD loss: 2.40007902903e-05
[32m[0315 20:50:59 @network.py:203][0m step: 60400, current TD loss: 0.0175064038485
[32m[0315 20:51:00 @network.py:203][0m step: 60500, current TD loss: 0.0176470484585
[32m[0315 20:51:01 @network.py:203][0m step: 60600, current TD loss: 0.000974935828708
[32m[0315 20:51:02 @network.py:203][0m step: 60700, current TD loss: 0.00199305941351
[32m[0315 20:51:03 @network.py:203][0m step: 60800, current TD loss: 8.58702551341e-05
[32m[0315 20:51:04 @network.py:203][0m step: 60900, current TD loss: 0.0157726556063
[32m[0315 20:51:05 @dqn_agent.py:203][0m episode: 4929, total game step: 111000, epsilon: 0.93961099
[32m[0315 20:51:05 @network.py:203][0m step: 61000, current TD loss: 0.000985912629403
[32m[0315 20:51:07 @network.py:203][0m step: 61100, current TD loss: 5.02474831592e-05
[32m[0315 20:51:08 @network.py:203][0m step: 61200, current TD loss: 0.0010849685641
[32m[0315 20:51:09 @network.py:203][0m step: 61300, current TD loss: 0.0009969152743
[32m[0315 20:51:10 @network.py:203][0m step: 61400, current TD loss: 0.0186841059476
[32m[0315 20:51:11 @network.py:203][0m step: 61500, current TD loss: 0.00103149411734
[32m[0315 20:51:12 @network.py:203][0m step: 61600, current TD loss: 0.033502779901
[32m[0315 20:51:13 @network.py:203][0m step: 61700, current TD loss: 5.83739310969e-05
[32m[0315 20:51:14 @network.py:203][0m step: 61800, current TD loss: 0.00105863716453
[32m[0315 20:51:16 @network.py:203][0m step: 61900, current TD loss: 0.00216808356345
[32m[0315 20:51:17 @dqn_agent.py:203][0m episode: 4978, total game step: 112000, epsilon: 0.93862099
[32m[0315 20:51:17 @network.py:203][0m step: 62000, current TD loss: 0.000979394302703
[32m[0315 20:51:18 @network.py:203][0m step: 62100, current TD loss: 0.0155966570601
[32m[0315 20:51:19 @network.py:203][0m step: 62200, current TD loss: 0.018504280597
[32m[0315 20:51:20 @network.py:203][0m step: 62300, current TD loss: 0.000116227965918
[32m[0315 20:51:21 @network.py:203][0m step: 62400, current TD loss: 0.00403361860663
[32m[0315 20:51:23 @network.py:203][0m step: 62500, current TD loss: 0.00311452127062
[32m[0315 20:51:23 @dqn_agent.py:216][0m At time step 62500, the target_network is updated
[32m[0315 20:51:23 @summary_handler.py:101][0m At episode: 112516, Reward: 0.18 (over 100 episodes)
[32m[0315 20:51:23 @summary_handler.py:102][0m Length: 23.06
[32m[0315 20:51:24 @network.py:203][0m step: 62600, current TD loss: 0.00207184767351
[32m[0315 20:51:25 @network.py:203][0m step: 62700, current TD loss: 0.00239933794364
[32m[0315 20:51:26 @network.py:203][0m step: 62800, current TD loss: 0.00424919696525
[32m[0315 20:51:27 @network.py:203][0m step: 62900, current TD loss: 0.00109208375216
[32m[0315 20:51:28 @dqn_agent.py:203][0m episode: 5021, total game step: 113000, epsilon: 0.93763099
[32m[0315 20:51:28 @network.py:203][0m step: 63000, current TD loss: 0.0165787693113
[32m[0315 20:51:29 @network.py:203][0m step: 63100, current TD loss: 0.00113405659795
[32m[0315 20:51:30 @network.py:203][0m step: 63200, current TD loss: 2.4485098038e-05
[32m[0315 20:51:32 @network.py:203][0m step: 63300, current TD loss: 0.00123250822071
[32m[0315 20:51:33 @network.py:203][0m step: 63400, current TD loss: 0.00406924262643
[32m[0315 20:51:34 @network.py:203][0m step: 63500, current TD loss: 0.00110232643783
[32m[0315 20:51:35 @network.py:203][0m step: 63600, current TD loss: 0.00306599284522
[32m[0315 20:51:36 @network.py:203][0m step: 63700, current TD loss: 0.00109248445369
[32m[0315 20:51:37 @network.py:203][0m step: 63800, current TD loss: 0.00219411705621
[32m[0315 20:51:38 @network.py:203][0m step: 63900, current TD loss: 0.00480091013014
[32m[0315 20:51:39 @dqn_agent.py:203][0m episode: 5070, total game step: 114000, epsilon: 0.93664099
[32m[0315 20:51:39 @network.py:203][0m step: 64000, current TD loss: 0.00103227980435
[32m[0315 20:51:41 @network.py:203][0m step: 64100, current TD loss: 0.00217956444249
[32m[0315 20:51:42 @network.py:203][0m step: 64200, current TD loss: 0.0020685615018
[32m[0315 20:51:43 @network.py:203][0m step: 64300, current TD loss: 0.0180764459074
[32m[0315 20:51:44 @network.py:203][0m step: 64400, current TD loss: 0.00330823287368
[32m[0315 20:51:45 @network.py:203][0m step: 64500, current TD loss: 0.00200744438916
[32m[0315 20:51:46 @summary_handler.py:101][0m At episode: 114546, Reward: 0.08 (over 100 episodes)
[32m[0315 20:51:46 @summary_handler.py:102][0m Length: 20.3
[32m[0315 20:51:46 @network.py:203][0m step: 64600, current TD loss: 0.0032738216687
[32m[0315 20:51:47 @network.py:203][0m step: 64700, current TD loss: 0.0178406927735
[32m[0315 20:51:49 @network.py:203][0m step: 64800, current TD loss: 0.00200294563547
[32m[0315 20:51:50 @network.py:203][0m step: 64900, current TD loss: 0.00101125717629
[32m[0315 20:51:51 @dqn_agent.py:203][0m episode: 5120, total game step: 115000, epsilon: 0.93565099
[32m[0315 20:51:51 @network.py:203][0m step: 65000, current TD loss: 0.00108406378422
[32m[0315 20:51:51 @dqn_agent.py:216][0m At time step 65000, the target_network is updated
[32m[0315 20:51:52 @network.py:203][0m step: 65100, current TD loss: 0.00108390313108
[32m[0315 20:51:53 @network.py:203][0m step: 65200, current TD loss: 0.000930184149183
[32m[0315 20:51:54 @network.py:203][0m step: 65300, current TD loss: 0.0152503363788
[32m[0315 20:51:56 @network.py:203][0m step: 65400, current TD loss: 0.0018903571181
[32m[0315 20:51:57 @network.py:203][0m step: 65500, current TD loss: 0.0155080659315
[32m[0315 20:51:58 @network.py:203][0m step: 65600, current TD loss: 0.0019855084829
[32m[0315 20:51:59 @network.py:203][0m step: 65700, current TD loss: 0.00190896040294
[32m[0315 20:52:00 @network.py:203][0m step: 65800, current TD loss: 0.0322341397405
[32m[0315 20:52:01 @network.py:203][0m step: 65900, current TD loss: 0.00202864222229
[32m[0315 20:52:02 @dqn_agent.py:203][0m episode: 5163, total game step: 116000, epsilon: 0.93466099
[32m[0315 20:52:02 @network.py:203][0m step: 66000, current TD loss: 0.00199199328199
[32m[0315 20:52:04 @network.py:203][0m step: 66100, current TD loss: 3.17053054459e-05
[32m[0315 20:52:05 @network.py:203][0m step: 66200, current TD loss: 0.00290175806731
[32m[0315 20:52:06 @network.py:203][0m step: 66300, current TD loss: 0.00184894935228
[32m[0315 20:52:07 @network.py:203][0m step: 66400, current TD loss: 0.000114070913696
[32m[0315 20:52:08 @network.py:203][0m step: 66500, current TD loss: 0.000941136328038
[32m[0315 20:52:09 @network.py:203][0m step: 66600, current TD loss: 0.00313610886224
[32m[0315 20:52:10 @network.py:203][0m step: 66700, current TD loss: 0.00466690585017
[32m[0315 20:52:11 @network.py:203][0m step: 66800, current TD loss: 5.81601416343e-05
[32m[0315 20:52:12 @network.py:203][0m step: 66900, current TD loss: 0.0168965701014
[32m[0315 20:52:13 @summary_handler.py:101][0m At episode: 116954, Reward: 0.16 (over 100 episodes)
[32m[0315 20:52:13 @summary_handler.py:102][0m Length: 24.08
[32m[0315 20:52:13 @dqn_agent.py:203][0m episode: 5200, total game step: 117000, epsilon: 0.93367099
[32m[0315 20:52:13 @network.py:203][0m step: 67000, current TD loss: 0.0161499846727
[32m[0315 20:52:15 @network.py:203][0m step: 67100, current TD loss: 5.22837726749e-05
[32m[0315 20:52:16 @network.py:203][0m step: 67200, current TD loss: 0.00159591808915
[32m[0315 20:52:17 @network.py:203][0m step: 67300, current TD loss: 0.00278485612944
[32m[0315 20:52:18 @network.py:203][0m step: 67400, current TD loss: 8.30401404528e-05
[32m[0315 20:52:19 @network.py:203][0m step: 67500, current TD loss: 0.0172951985151
[32m[0315 20:52:19 @dqn_agent.py:216][0m At time step 67500, the target_network is updated
[32m[0315 20:52:20 @network.py:203][0m step: 67600, current TD loss: 0.000947655062191
[32m[0315 20:52:21 @network.py:203][0m step: 67700, current TD loss: 0.000934719806537
[32m[0315 20:52:22 @network.py:203][0m step: 67800, current TD loss: 0.0178522244096
[32m[0315 20:52:23 @network.py:203][0m step: 67900, current TD loss: 0.00182901287917
[32m[0315 20:52:24 @dqn_agent.py:203][0m episode: 5236, total game step: 118000, epsilon: 0.93268099
[32m[0315 20:52:24 @network.py:203][0m step: 68000, current TD loss: 0.00181244523264
[32m[0315 20:52:26 @network.py:203][0m step: 68100, current TD loss: 0.00267994962633
[32m[0315 20:52:27 @network.py:203][0m step: 68200, current TD loss: 0.000980963348411
[32m[0315 20:52:28 @network.py:203][0m step: 68300, current TD loss: 0.00173504184932
[32m[0315 20:52:29 @network.py:203][0m step: 68400, current TD loss: 0.0166112724692
[32m[0315 20:52:30 @network.py:203][0m step: 68500, current TD loss: 0.00164167606272
[32m[0315 20:52:31 @network.py:203][0m step: 68600, current TD loss: 0.00190382881556
[32m[0315 20:52:33 @network.py:203][0m step: 68700, current TD loss: 0.00085602409672
[32m[0315 20:52:34 @network.py:203][0m step: 68800, current TD loss: 0.0170792993158
[32m[0315 20:52:35 @network.py:203][0m step: 68900, current TD loss: 0.000935268355533
[32m[0315 20:52:36 @dqn_agent.py:203][0m episode: 5291, total game step: 119000, epsilon: 0.93169099
[32m[0315 20:52:36 @network.py:203][0m step: 69000, current TD loss: 0.00196093181148
[32m[0315 20:52:37 @network.py:203][0m step: 69100, current TD loss: 0.0028865323402
[32m[0315 20:52:38 @summary_handler.py:101][0m At episode: 119183, Reward: 0.11 (over 100 episodes)
[32m[0315 20:52:38 @summary_handler.py:102][0m Length: 22.29
[32m[0315 20:52:38 @network.py:203][0m step: 69200, current TD loss: 0.00100108853076
[32m[0315 20:52:40 @network.py:203][0m step: 69300, current TD loss: 4.77689827676e-05
[32m[0315 20:52:41 @network.py:203][0m step: 69400, current TD loss: 5.22256559634e-05
[32m[0315 20:52:42 @network.py:203][0m step: 69500, current TD loss: 0.00181562150829
[32m[0315 20:52:43 @network.py:203][0m step: 69600, current TD loss: 0.0166933629662
[32m[0315 20:52:44 @network.py:203][0m step: 69700, current TD loss: 0.00182342319749
[32m[0315 20:52:45 @network.py:203][0m step: 69800, current TD loss: 0.0010464937659
[32m[0315 20:52:46 @network.py:203][0m step: 69900, current TD loss: 0.0162167884409
[32m[0315 20:52:47 @dqn_agent.py:203][0m episode: 5336, total game step: 120000, epsilon: 0.93070099
[32m[0315 20:52:47 @network.py:203][0m step: 70000, current TD loss: 0.000964649021626
[32m[0315 20:52:47 @dqn_agent.py:216][0m At time step 70000, the target_network is updated
[32m[0315 20:52:48 @network.py:203][0m step: 70100, current TD loss: 0.00182287278585
[32m[0315 20:52:50 @network.py:203][0m step: 70200, current TD loss: 0.00190706504509
[32m[0315 20:52:51 @network.py:203][0m step: 70300, current TD loss: 0.00292452052236
[32m[0315 20:52:52 @network.py:203][0m step: 70400, current TD loss: 0.00260891485959
[32m[0315 20:52:53 @network.py:203][0m step: 70500, current TD loss: 0.000945249747019
[32m[0315 20:52:54 @network.py:203][0m step: 70600, current TD loss: 0.000841294822749
[32m[0315 20:52:55 @network.py:203][0m step: 70700, current TD loss: 0.0193709507585
[32m[0315 20:52:56 @network.py:203][0m step: 70800, current TD loss: 0.00179881369695
[32m[0315 20:52:57 @network.py:203][0m step: 70900, current TD loss: 4.21241420554e-05
[32m[0315 20:52:59 @dqn_agent.py:203][0m episode: 5383, total game step: 121000, epsilon: 0.92971099
[32m[0315 20:52:59 @network.py:203][0m step: 71000, current TD loss: 0.00191856687889
[32m[0315 20:53:00 @network.py:203][0m step: 71100, current TD loss: 0.00263474276289
[32m[0315 20:53:01 @network.py:203][0m step: 71200, current TD loss: 0.00276134116575
[32m[0315 20:53:02 @network.py:203][0m step: 71300, current TD loss: 0.00104812078644
[32m[0315 20:53:03 @summary_handler.py:101][0m At episode: 121333, Reward: 0.09 (over 100 episodes)
[32m[0315 20:53:03 @summary_handler.py:102][0m Length: 21.5
[32m[0315 20:53:03 @network.py:203][0m step: 71400, current TD loss: 7.17747607268e-05
[32m[0315 20:53:04 @network.py:203][0m step: 71500, current TD loss: 0.0169030949473
[32m[0315 20:53:06 @network.py:203][0m step: 71600, current TD loss: 0.000925986620132
[32m[0315 20:53:07 @network.py:203][0m step: 71700, current TD loss: 2.87937873509e-05
[32m[0315 20:53:08 @network.py:203][0m step: 71800, current TD loss: 0.0012070274679
[32m[0315 20:53:09 @network.py:203][0m step: 71900, current TD loss: 7.21836040611e-05
[32m[0315 20:53:10 @dqn_agent.py:203][0m episode: 5428, total game step: 122000, epsilon: 0.92872099
[32m[0315 20:53:10 @network.py:203][0m step: 72000, current TD loss: 0.00175610627048
[32m[0315 20:53:11 @network.py:203][0m step: 72100, current TD loss: 0.00191661994904
[32m[0315 20:53:12 @network.py:203][0m step: 72200, current TD loss: 0.00480485893786
[32m[0315 20:53:13 @network.py:203][0m step: 72300, current TD loss: 0.00098656793125
[32m[0315 20:53:15 @network.py:203][0m step: 72400, current TD loss: 0.00094201246975
[32m[0315 20:53:16 @network.py:203][0m step: 72500, current TD loss: 0.00103331333958
[32m[0315 20:53:16 @dqn_agent.py:216][0m At time step 72500, the target_network is updated
[32m[0315 20:53:17 @network.py:203][0m step: 72600, current TD loss: 0.0172977726907
[32m[0315 20:53:18 @network.py:203][0m step: 72700, current TD loss: 0.0027451091446
[32m[0315 20:53:19 @network.py:203][0m step: 72800, current TD loss: 0.00113195809536
[32m[0315 20:53:20 @network.py:203][0m step: 72900, current TD loss: 0.000991823617369
[32m[0315 20:53:21 @dqn_agent.py:203][0m episode: 5460, total game step: 123000, epsilon: 0.92773099
[32m[0315 20:53:21 @network.py:203][0m step: 73000, current TD loss: 0.00190912501421
[32m[0315 20:53:23 @network.py:203][0m step: 73100, current TD loss: 0.0165404826403
[32m[0315 20:53:24 @network.py:203][0m step: 73200, current TD loss: 0.000832512159832
[32m[0315 20:53:25 @network.py:203][0m step: 73300, current TD loss: 4.12948866142e-05
[32m[0315 20:53:26 @network.py:203][0m step: 73400, current TD loss: 0.0186865124851
[32m[0315 20:53:27 @network.py:203][0m step: 73500, current TD loss: 0.000965092680417
[32m[0315 20:53:28 @network.py:203][0m step: 73600, current TD loss: 0.0161528661847
[32m[0315 20:53:29 @summary_handler.py:101][0m At episode: 123668, Reward: 0.17 (over 100 episodes)
[32m[0315 20:53:29 @summary_handler.py:102][0m Length: 23.35
[32m[0315 20:53:29 @network.py:203][0m step: 73700, current TD loss: 0.0170234069228
[32m[0315 20:53:30 @network.py:203][0m step: 73800, current TD loss: 5.93940349063e-05
[32m[0315 20:53:32 @network.py:203][0m step: 73900, current TD loss: 0.00103300740011
[32m[0315 20:53:33 @dqn_agent.py:203][0m episode: 5510, total game step: 124000, epsilon: 0.92674099
[32m[0315 20:53:33 @network.py:203][0m step: 74000, current TD loss: 0.00302555784583
[32m[0315 20:53:34 @network.py:203][0m step: 74100, current TD loss: 0.0155633576214
[32m[0315 20:53:35 @network.py:203][0m step: 74200, current TD loss: 0.0177272502333
[32m[0315 20:53:36 @network.py:203][0m step: 74300, current TD loss: 0.0165550448
[32m[0315 20:53:37 @network.py:203][0m step: 74400, current TD loss: 0.000980907236226
[32m[0315 20:53:38 @network.py:203][0m step: 74500, current TD loss: 0.00176333880518
[32m[0315 20:53:39 @network.py:203][0m step: 74600, current TD loss: 0.0039301244542
[32m[0315 20:53:40 @network.py:203][0m step: 74700, current TD loss: 0.0205152966082
[32m[0315 20:53:42 @network.py:203][0m step: 74800, current TD loss: 0.00179997191299
[32m[0315 20:53:43 @network.py:203][0m step: 74900, current TD loss: 2.05984597414e-05
[32m[0315 20:53:44 @dqn_agent.py:203][0m episode: 5546, total game step: 125000, epsilon: 0.92575099
[32m[0315 20:53:44 @network.py:203][0m step: 75000, current TD loss: 0.000888798560482
[32m[0315 20:53:44 @dqn_agent.py:216][0m At time step 75000, the target_network is updated
[32m[0315 20:53:45 @network.py:203][0m step: 75100, current TD loss: 0.0164053533226
[32m[0315 20:53:46 @network.py:203][0m step: 75200, current TD loss: 0.000979153555818
[32m[0315 20:53:47 @network.py:203][0m step: 75300, current TD loss: 0.0026518907398
[32m[0315 20:53:48 @network.py:203][0m step: 75400, current TD loss: 0.00268191331998
[32m[0315 20:53:49 @network.py:203][0m step: 75500, current TD loss: 0.00280576967634
[32m[0315 20:53:51 @network.py:203][0m step: 75600, current TD loss: 0.000958541873842
[32m[0315 20:53:52 @network.py:203][0m step: 75700, current TD loss: 0.00187066441868
[32m[0315 20:53:53 @network.py:203][0m step: 75800, current TD loss: 0.0180848073214
[32m[0315 20:53:54 @network.py:203][0m step: 75900, current TD loss: 0.0166482124478
[32m[0315 20:53:55 @dqn_agent.py:203][0m episode: 5590, total game step: 126000, epsilon: 0.92476099
[32m[0315 20:53:55 @network.py:203][0m step: 76000, current TD loss: 0.00261885952204
[32m[0315 20:53:56 @network.py:203][0m step: 76100, current TD loss: 0.00107652554289
[32m[0315 20:53:57 @network.py:203][0m step: 76200, current TD loss: 0.00264200940728
[32m[0315 20:53:58 @summary_handler.py:101][0m At episode: 126274, Reward: 0.18 (over 100 episodes)
[32m[0315 20:53:58 @summary_handler.py:102][0m Length: 26.06
[32m[0315 20:53:59 @network.py:203][0m step: 76300, current TD loss: 3.21995212289e-05
[32m[0315 20:54:00 @network.py:203][0m step: 76400, current TD loss: 0.000897620280739
[32m[0315 20:54:01 @network.py:203][0m step: 76500, current TD loss: 0.00176716852002
[32m[0315 20:54:02 @network.py:203][0m step: 76600, current TD loss: 0.002088079229
[32m[0315 20:54:03 @network.py:203][0m step: 76700, current TD loss: 0.00108819198795
[32m[0315 20:54:04 @network.py:203][0m step: 76800, current TD loss: 0.0017434200272
[32m[0315 20:54:05 @network.py:203][0m step: 76900, current TD loss: 0.016786981374
[32m[0315 20:54:06 @dqn_agent.py:203][0m episode: 5637, total game step: 127000, epsilon: 0.92377099
[32m[0315 20:54:06 @network.py:203][0m step: 77000, current TD loss: 0.0172178838402
[32m[0315 20:54:08 @network.py:203][0m step: 77100, current TD loss: 0.00218704389408
[32m[0315 20:54:09 @network.py:203][0m step: 77200, current TD loss: 0.00191623403225
[32m[0315 20:54:10 @network.py:203][0m step: 77300, current TD loss: 0.00182594358921
[32m[0315 20:54:11 @network.py:203][0m step: 77400, current TD loss: 0.0017698770389
[32m[0315 20:54:12 @network.py:203][0m step: 77500, current TD loss: 0.0035379617475
[32m[0315 20:54:12 @dqn_agent.py:216][0m At time step 77500, the target_network is updated
[32m[0315 20:54:13 @network.py:203][0m step: 77600, current TD loss: 0.00373615021817
[32m[0315 20:54:14 @network.py:203][0m step: 77700, current TD loss: 0.00519618391991
[32m[0315 20:54:15 @network.py:203][0m step: 77800, current TD loss: 0.000992118613794
[32m[0315 20:54:16 @network.py:203][0m step: 77900, current TD loss: 0.00102061661892
[32m[0315 20:54:18 @dqn_agent.py:203][0m episode: 5678, total game step: 128000, epsilon: 0.92278099
[32m[0315 20:54:18 @network.py:203][0m step: 78000, current TD loss: 0.000969397835433
[32m[0315 20:54:19 @network.py:203][0m step: 78100, current TD loss: 4.47215425083e-05
[32m[0315 20:54:20 @network.py:203][0m step: 78200, current TD loss: 0.018070327118
[32m[0315 20:54:21 @network.py:203][0m step: 78300, current TD loss: 1.80178867595e-05
[32m[0315 20:54:22 @network.py:203][0m step: 78400, current TD loss: 0.00500406790525
[32m[0315 20:54:23 @summary_handler.py:101][0m At episode: 128484, Reward: 0.11 (over 100 episodes)
[32m[0315 20:54:23 @summary_handler.py:102][0m Length: 22.1
[32m[0315 20:54:23 @network.py:203][0m step: 78500, current TD loss: 4.41563388449e-05
[32m[0315 20:54:24 @network.py:203][0m step: 78600, current TD loss: 6.66382547934e-05
[32m[0315 20:54:26 @network.py:203][0m step: 78700, current TD loss: 0.000957131152973
[32m[0315 20:54:27 @network.py:203][0m step: 78800, current TD loss: 0.00204272707924
[32m[0315 20:54:28 @network.py:203][0m step: 78900, current TD loss: 0.00270089879632
[32m[0315 20:54:29 @dqn_agent.py:203][0m episode: 5727, total game step: 129000, epsilon: 0.92179099
[32m[0315 20:54:29 @network.py:203][0m step: 79000, current TD loss: 0.00262424675748
[32m[0315 20:54:30 @network.py:203][0m step: 79100, current TD loss: 0.000761564646382
[32m[0315 20:54:31 @network.py:203][0m step: 79200, current TD loss: 0.0183865781873
[32m[0315 20:54:32 @network.py:203][0m step: 79300, current TD loss: 7.35502908356e-05
[32m[0315 20:54:34 @network.py:203][0m step: 79400, current TD loss: 0.000881480576936
[32m[0315 20:54:35 @network.py:203][0m step: 79500, current TD loss: 0.000825260998681
[32m[0315 20:54:36 @network.py:203][0m step: 79600, current TD loss: 0.00194681691937
[32m[0315 20:54:37 @network.py:203][0m step: 79700, current TD loss: 0.00447509344667
[32m[0315 20:54:38 @network.py:203][0m step: 79800, current TD loss: 0.0027089768555
[32m[0315 20:54:39 @network.py:203][0m step: 79900, current TD loss: 0.00193083425984
[32m[0315 20:54:40 @dqn_agent.py:203][0m episode: 5776, total game step: 130000, epsilon: 0.92080099
[32m[0315 20:54:40 @network.py:203][0m step: 80000, current TD loss: 0.0170009247959
[32m[0315 20:54:40 @dqn_agent.py:216][0m At time step 80000, the target_network is updated
[32m[0315 20:54:42 @network.py:203][0m step: 80100, current TD loss: 0.0010048057884
[32m[0315 20:54:43 @network.py:203][0m step: 80200, current TD loss: 0.000867123773787
[32m[0315 20:54:44 @network.py:203][0m step: 80300, current TD loss: 0.000895570090506
[32m[0315 20:54:45 @network.py:203][0m step: 80400, current TD loss: 2.09852296393e-05
[32m[0315 20:54:46 @summary_handler.py:101][0m At episode: 130496, Reward: 0.11 (over 100 episodes)
[32m[0315 20:54:46 @summary_handler.py:102][0m Length: 20.12
[32m[0315 20:54:46 @network.py:203][0m step: 80500, current TD loss: 0.00236346875317
[32m[0315 20:54:47 @network.py:203][0m step: 80600, current TD loss: 0.0186182130128
[32m[0315 20:54:48 @network.py:203][0m step: 80700, current TD loss: 0.00459009082988
[32m[0315 20:54:50 @network.py:203][0m step: 80800, current TD loss: 0.00167475338094
[32m[0315 20:54:51 @network.py:203][0m step: 80900, current TD loss: 0.00187479285523
[32m[0315 20:54:52 @dqn_agent.py:203][0m episode: 5826, total game step: 131000, epsilon: 0.91981099
[32m[0315 20:54:52 @network.py:203][0m step: 81000, current TD loss: 2.92558870569e-05
[32m[0315 20:54:53 @network.py:203][0m step: 81100, current TD loss: 0.0181146599352
[32m[0315 20:54:54 @network.py:203][0m step: 81200, current TD loss: 0.000897639896721
[32m[0315 20:54:55 @network.py:203][0m step: 81300, current TD loss: 0.00249260850251
[32m[0315 20:54:57 @network.py:203][0m step: 81400, current TD loss: 0.000922987877857
[32m[0315 20:54:58 @network.py:203][0m step: 81500, current TD loss: 0.0157480668277
[32m[0315 20:54:59 @network.py:203][0m step: 81600, current TD loss: 0.00188507093117
[32m[0315 20:55:00 @network.py:203][0m step: 81700, current TD loss: 0.0166259799153
[32m[0315 20:55:01 @network.py:203][0m step: 81800, current TD loss: 0.000918446399737
[32m[0315 20:55:02 @network.py:203][0m step: 81900, current TD loss: 0.00089927361114
[32m[0315 20:55:03 @dqn_agent.py:203][0m episode: 5874, total game step: 132000, epsilon: 0.91882099
[32m[0315 20:55:03 @network.py:203][0m step: 82000, current TD loss: 0.00171915104147
[32m[0315 20:55:04 @network.py:203][0m step: 82100, current TD loss: 0.0155010176823
[32m[0315 20:55:06 @network.py:203][0m step: 82200, current TD loss: 0.0177956391126
[32m[0315 20:55:07 @network.py:203][0m step: 82300, current TD loss: 0.0178803484887
[32m[0315 20:55:08 @network.py:203][0m step: 82400, current TD loss: 0.00171275436878
[32m[0315 20:55:09 @network.py:203][0m step: 82500, current TD loss: 0.0189039818943
[32m[0315 20:55:09 @dqn_agent.py:216][0m At time step 82500, the target_network is updated
[32m[0315 20:55:10 @summary_handler.py:101][0m At episode: 132569, Reward: 0.1 (over 100 episodes)
[32m[0315 20:55:10 @summary_handler.py:102][0m Length: 20.73
[32m[0315 20:55:10 @network.py:203][0m step: 82600, current TD loss: 0.000837870233227
[32m[0315 20:55:11 @network.py:203][0m step: 82700, current TD loss: 0.00243302527815
[32m[0315 20:55:12 @network.py:203][0m step: 82800, current TD loss: 0.000800273497589
[32m[0315 20:55:13 @network.py:203][0m step: 82900, current TD loss: 6.46610715194e-05
[32m[0315 20:55:15 @dqn_agent.py:203][0m episode: 5913, total game step: 133000, epsilon: 0.91783099
[32m[0315 20:55:15 @network.py:203][0m step: 83000, current TD loss: 0.0169038437307
[32m[0315 20:55:16 @network.py:203][0m step: 83100, current TD loss: 0.00153315637726
[32m[0315 20:55:17 @network.py:203][0m step: 83200, current TD loss: 0.000838916283101
[32m[0315 20:55:18 @network.py:203][0m step: 83300, current TD loss: 0.00325255445205
[32m[0315 20:55:19 @network.py:203][0m step: 83400, current TD loss: 0.00197862065397
[32m[0315 20:55:20 @network.py:203][0m step: 83500, current TD loss: 0.0019213281339
[32m[0315 20:55:21 @network.py:203][0m step: 83600, current TD loss: 0.00154474354349
[32m[0315 20:55:22 @network.py:203][0m step: 83700, current TD loss: 0.000961812678725
[32m[0315 20:55:24 @network.py:203][0m step: 83800, current TD loss: 0.00231743324548
[32m[0315 20:55:25 @network.py:203][0m step: 83900, current TD loss: 5.71335549466e-05
[32m[0315 20:55:26 @dqn_agent.py:203][0m episode: 5951, total game step: 134000, epsilon: 0.91684099
[32m[0315 20:55:26 @network.py:203][0m step: 84000, current TD loss: 0.00084473984316
[32m[0315 20:55:27 @network.py:203][0m step: 84100, current TD loss: 0.000815124891233
[32m[0315 20:55:28 @network.py:203][0m step: 84200, current TD loss: 0.00150424055755
[32m[0315 20:55:29 @network.py:203][0m step: 84300, current TD loss: 0.0170090943575
[32m[0315 20:55:30 @network.py:203][0m step: 84400, current TD loss: 0.00224507087842
[32m[0315 20:55:31 @network.py:203][0m step: 84500, current TD loss: 0.000693333277013
[32m[0315 20:55:33 @network.py:203][0m step: 84600, current TD loss: 0.000886384572368
[32m[0315 20:55:34 @network.py:203][0m step: 84700, current TD loss: 0.000771428109147
[32m[0315 20:55:35 @network.py:203][0m step: 84800, current TD loss: 0.00331106409431
[32m[0315 20:55:36 @network.py:203][0m step: 84900, current TD loss: 0.00405086763203
[32m[0315 20:55:37 @dqn_agent.py:203][0m episode: 5991, total game step: 135000, epsilon: 0.91585099
[32m[0315 20:55:37 @network.py:203][0m step: 85000, current TD loss: 0.000780619855504
[32m[0315 20:55:37 @dqn_agent.py:216][0m At time step 85000, the target_network is updated
[32m[0315 20:55:38 @network.py:203][0m step: 85100, current TD loss: 0.00194001221098
[32m[0315 20:55:39 @summary_handler.py:101][0m At episode: 135188, Reward: 0.16 (over 100 episodes)
[32m[0315 20:55:39 @summary_handler.py:102][0m Length: 26.19
[32m[0315 20:55:39 @network.py:203][0m step: 85200, current TD loss: 0.00126741151325
[32m[0315 20:55:40 @network.py:203][0m step: 85300, current TD loss: 0.000828086398542
[32m[0315 20:55:42 @network.py:203][0m step: 85400, current TD loss: 0.0193807613105
[32m[0315 20:55:43 @network.py:203][0m step: 85500, current TD loss: 0.00171137205325
[32m[0315 20:55:44 @network.py:203][0m step: 85600, current TD loss: 0.00167217315175
[32m[0315 20:55:45 @network.py:203][0m step: 85700, current TD loss: 0.00272386684082
[32m[0315 20:55:46 @network.py:203][0m step: 85800, current TD loss: 0.0172870848328
[32m[0315 20:55:47 @network.py:203][0m step: 85900, current TD loss: 0.0162606351078
[32m[0315 20:55:49 @dqn_agent.py:203][0m episode: 6041, total game step: 136000, epsilon: 0.91486099
[32m[0315 20:55:49 @network.py:203][0m step: 86000, current TD loss: 0.0158321876079
[32m[0315 20:55:50 @network.py:203][0m step: 86100, current TD loss: 0.0165654271841
[32m[0315 20:55:51 @network.py:203][0m step: 86200, current TD loss: 0.000788742909208
[32m[0315 20:55:52 @network.py:203][0m step: 86300, current TD loss: 0.00264943297952
[32m[0315 20:55:53 @network.py:203][0m step: 86400, current TD loss: 0.00265117757954
[32m[0315 20:55:54 @network.py:203][0m step: 86500, current TD loss: 0.000785069074482
[32m[0315 20:55:55 @network.py:203][0m step: 86600, current TD loss: 0.00179415964521
[32m[0315 20:55:56 @network.py:203][0m step: 86700, current TD loss: 0.00245988974348
[32m[0315 20:55:58 @network.py:203][0m step: 86800, current TD loss: 0.00249640736729
[32m[0315 20:55:59 @network.py:203][0m step: 86900, current TD loss: 0.00258118263446
[32m[0315 20:56:00 @dqn_agent.py:203][0m episode: 6081, total game step: 137000, epsilon: 0.91387099
[32m[0315 20:56:00 @network.py:203][0m step: 87000, current TD loss: 0.00239282939583
[32m[0315 20:56:01 @network.py:203][0m step: 87100, current TD loss: 0.00231587677263
[32m[0315 20:56:02 @network.py:203][0m step: 87200, current TD loss: 2.60481574514e-05
[32m[0315 20:56:03 @network.py:203][0m step: 87300, current TD loss: 3.30552575178e-05
[32m[0315 20:56:04 @network.py:203][0m step: 87400, current TD loss: 0.00155998626724
[32m[0315 20:56:04 @summary_handler.py:101][0m At episode: 137406, Reward: 0.12 (over 100 episodes)
[32m[0315 20:56:04 @summary_handler.py:102][0m Length: 22.18
[32m[0315 20:56:05 @network.py:203][0m step: 87500, current TD loss: 2.28101525863e-05
[32m[0315 20:56:05 @dqn_agent.py:216][0m At time step 87500, the target_network is updated
[32m[0315 20:56:07 @network.py:203][0m step: 87600, current TD loss: 0.0317855477333
[32m[0315 20:56:08 @network.py:203][0m step: 87700, current TD loss: 0.00258443178609
[32m[0315 20:56:09 @network.py:203][0m step: 87800, current TD loss: 0.000853102537803
[32m[0315 20:56:10 @network.py:203][0m step: 87900, current TD loss: 0.000993047957309
[32m[0315 20:56:11 @dqn_agent.py:203][0m episode: 6130, total game step: 138000, epsilon: 0.91288099
[32m[0315 20:56:11 @network.py:203][0m step: 88000, current TD loss: 0.00174062978476
[32m[0315 20:56:12 @network.py:203][0m step: 88100, current TD loss: 0.000899905047845
[32m[0315 20:56:13 @network.py:203][0m step: 88200, current TD loss: 0.0167091544718
[32m[0315 20:56:14 @network.py:203][0m step: 88300, current TD loss: 0.00341663509607
[32m[0315 20:56:16 @network.py:203][0m step: 88400, current TD loss: 0.000873643846717
[32m[0315 20:56:17 @network.py:203][0m step: 88500, current TD loss: 0.00198241579346
[32m[0315 20:56:18 @network.py:203][0m step: 88600, current TD loss: 0.000841750064865
[32m[0315 20:56:19 @network.py:203][0m step: 88700, current TD loss: 0.0176873262972
[32m[0315 20:56:20 @network.py:203][0m step: 88800, current TD loss: 0.0160344559699
[32m[0315 20:56:21 @network.py:203][0m step: 88900, current TD loss: 0.00275914371014
[32m[0315 20:56:22 @dqn_agent.py:203][0m episode: 6173, total game step: 139000, epsilon: 0.91189099
[32m[0315 20:56:22 @network.py:203][0m step: 89000, current TD loss: 8.5409359599e-05
[32m[0315 20:56:24 @network.py:203][0m step: 89100, current TD loss: 0.00184920814354
[32m[0315 20:56:25 @network.py:203][0m step: 89200, current TD loss: 0.0362597331405
[32m[0315 20:56:26 @network.py:203][0m step: 89300, current TD loss: 0.00251237815246
[32m[0315 20:56:27 @network.py:203][0m step: 89400, current TD loss: 3.0784169212e-05
[32m[0315 20:56:28 @summary_handler.py:101][0m At episode: 139488, Reward: 0.13 (over 100 episodes)
[32m[0315 20:56:28 @summary_handler.py:102][0m Length: 20.82
[32m[0315 20:56:28 @network.py:203][0m step: 89500, current TD loss: 0.003483094275
[32m[0315 20:56:29 @network.py:203][0m step: 89600, current TD loss: 0.00165564450435
[32m[0315 20:56:30 @network.py:203][0m step: 89700, current TD loss: 0.00287589849904
[32m[0315 20:56:32 @network.py:203][0m step: 89800, current TD loss: 9.94571892079e-05
[32m[0315 20:56:33 @network.py:203][0m step: 89900, current TD loss: 0.0155540434644
[32m[0315 20:56:34 @dqn_agent.py:203][0m episode: 6229, total game step: 140000, epsilon: 0.91090099
[32m[0315 20:56:34 @network.py:203][0m step: 90000, current TD loss: 0.00170869519934
[32m[0315 20:56:34 @dqn_agent.py:216][0m At time step 90000, the target_network is updated
[32m[0315 20:56:35 @network.py:203][0m step: 90100, current TD loss: 0.00184305768926
[32m[0315 20:56:36 @network.py:203][0m step: 90200, current TD loss: 0.000967627565842
[32m[0315 20:56:37 @network.py:203][0m step: 90300, current TD loss: 0.00210600858554
[32m[0315 20:56:38 @network.py:203][0m step: 90400, current TD loss: 0.00166342663579
[32m[0315 20:56:40 @network.py:203][0m step: 90500, current TD loss: 0.0166910998523
[32m[0315 20:56:41 @network.py:203][0m step: 90600, current TD loss: 0.000950856425334
[32m[0315 20:56:42 @network.py:203][0m step: 90700, current TD loss: 0.00181523011997
[32m[0315 20:56:43 @network.py:203][0m step: 90800, current TD loss: 0.0174633283168
[32m[0315 20:56:44 @network.py:203][0m step: 90900, current TD loss: 0.00178335071541
[32m[0315 20:56:45 @dqn_agent.py:203][0m episode: 6275, total game step: 141000, epsilon: 0.90991099
[32m[0315 20:56:45 @network.py:203][0m step: 91000, current TD loss: 0.0169583205134
[32m[0315 20:56:46 @network.py:203][0m step: 91100, current TD loss: 0.00177541340236
[32m[0315 20:56:48 @network.py:203][0m step: 91200, current TD loss: 0.00289962394163
[32m[0315 20:56:49 @network.py:203][0m step: 91300, current TD loss: 0.00292208488099
[32m[0315 20:56:50 @network.py:203][0m step: 91400, current TD loss: 0.000909896800295
[32m[0315 20:56:51 @network.py:203][0m step: 91500, current TD loss: 0.00205886131153
[32m[0315 20:56:51 @summary_handler.py:101][0m At episode: 141533, Reward: 0.09 (over 100 episodes)
[32m[0315 20:56:51 @summary_handler.py:102][0m Length: 20.45
[32m[0315 20:56:52 @network.py:203][0m step: 91600, current TD loss: 0.000916646444239
[32m[0315 20:56:53 @network.py:203][0m step: 91700, current TD loss: 0.00188588537276
[32m[0315 20:56:54 @network.py:203][0m step: 91800, current TD loss: 0.00182408280671
[32m[0315 20:56:55 @network.py:203][0m step: 91900, current TD loss: 0.001016461174
[32m[0315 20:56:57 @dqn_agent.py:203][0m episode: 6324, total game step: 142000, epsilon: 0.90892099
[32m[0315 20:56:57 @network.py:203][0m step: 92000, current TD loss: 0.000915448123123
[32m[0315 20:56:58 @network.py:203][0m step: 92100, current TD loss: 0.00183752411976
[32m[0315 20:56:59 @network.py:203][0m step: 92200, current TD loss: 0.0173534229398
[32m[0315 20:57:00 @network.py:203][0m step: 92300, current TD loss: 7.82168935984e-05
[32m[0315 20:57:01 @network.py:203][0m step: 92400, current TD loss: 6.24119929853e-05
[32m[0315 20:57:02 @network.py:203][0m step: 92500, current TD loss: 0.00262314733118
[32m[0315 20:57:02 @dqn_agent.py:216][0m At time step 92500, the target_network is updated
[32m[0315 20:57:03 @network.py:203][0m step: 92600, current TD loss: 0.00275686080568
[32m[0315 20:57:05 @network.py:203][0m step: 92700, current TD loss: 0.00300200004131
[32m[0315 20:57:06 @network.py:203][0m step: 92800, current TD loss: 7.45841025491e-05
[32m[0315 20:57:07 @network.py:203][0m step: 92900, current TD loss: 0.00171509594657
[32m[0315 20:57:08 @dqn_agent.py:203][0m episode: 6377, total game step: 143000, epsilon: 0.90793099
[32m[0315 20:57:08 @network.py:203][0m step: 93000, current TD loss: 0.000914386007935
[32m[0315 20:57:09 @network.py:203][0m step: 93100, current TD loss: 0.00402964651585
[32m[0315 20:57:10 @network.py:203][0m step: 93200, current TD loss: 0.00399419479072
[32m[0315 20:57:11 @network.py:203][0m step: 93300, current TD loss: 0.00312939751893
[32m[0315 20:57:12 @network.py:203][0m step: 93400, current TD loss: 0.000864062982146
[32m[0315 20:57:14 @network.py:203][0m step: 93500, current TD loss: 0.00199176277965
[32m[0315 20:57:14 @summary_handler.py:101][0m At episode: 143550, Reward: 0.08 (over 100 episodes)
[32m[0315 20:57:14 @summary_handler.py:102][0m Length: 20.17
[32m[0315 20:57:15 @network.py:203][0m step: 93600, current TD loss: 0.00109697715379
[32m[0315 20:57:16 @network.py:203][0m step: 93700, current TD loss: 0.000945224426687
[32m[0315 20:57:17 @network.py:203][0m step: 93800, current TD loss: 0.0193112473935
[32m[0315 20:57:18 @network.py:203][0m step: 93900, current TD loss: 0.00190265232231
[32m[0315 20:57:19 @dqn_agent.py:203][0m episode: 6424, total game step: 144000, epsilon: 0.90694099
[32m[0315 20:57:19 @network.py:203][0m step: 94000, current TD loss: 0.00283002061769
[32m[0315 20:57:20 @network.py:203][0m step: 94100, current TD loss: 0.0185621641576
[32m[0315 20:57:22 @network.py:203][0m step: 94200, current TD loss: 0.00285147596151
[32m[0315 20:57:23 @network.py:203][0m step: 94300, current TD loss: 0.002163000172
[32m[0315 20:57:24 @network.py:203][0m step: 94400, current TD loss: 0.0185277294368
[32m[0315 20:57:25 @network.py:203][0m step: 94500, current TD loss: 1.57157846843e-05
[32m[0315 20:57:26 @network.py:203][0m step: 94600, current TD loss: 0.0332147143781
[32m[0315 20:57:27 @network.py:203][0m step: 94700, current TD loss: 0.00225291773677
[32m[0315 20:57:28 @network.py:203][0m step: 94800, current TD loss: 7.61755291023e-05
[32m[0315 20:57:30 @network.py:203][0m step: 94900, current TD loss: 7.32849148335e-05
[32m[0315 20:57:31 @dqn_agent.py:203][0m episode: 6472, total game step: 145000, epsilon: 0.90595099
[32m[0315 20:57:31 @network.py:203][0m step: 95000, current TD loss: 0.00348565401509
[32m[0315 20:57:31 @dqn_agent.py:216][0m At time step 95000, the target_network is updated
[32m[0315 20:57:32 @network.py:203][0m step: 95100, current TD loss: 0.033388890326
[32m[0315 20:57:33 @network.py:203][0m step: 95200, current TD loss: 0.00105395063292
[32m[0315 20:57:34 @network.py:203][0m step: 95300, current TD loss: 0.0034410264343
[32m[0315 20:57:35 @network.py:203][0m step: 95400, current TD loss: 0.00304925907403
[32m[0315 20:57:36 @network.py:203][0m step: 95500, current TD loss: 0.00472530163825
[32m[0315 20:57:37 @network.py:203][0m step: 95600, current TD loss: 0.00010843972268
[32m[0315 20:57:39 @summary_handler.py:101][0m At episode: 145693, Reward: 0.12 (over 100 episodes)
[32m[0315 20:57:39 @summary_handler.py:102][0m Length: 21.43
[32m[0315 20:57:39 @network.py:203][0m step: 95700, current TD loss: 7.90743288235e-05
[32m[0315 20:57:40 @network.py:203][0m step: 95800, current TD loss: 0.00203941529617
[32m[0315 20:57:41 @network.py:203][0m step: 95900, current TD loss: 0.00285064103082
[32m[0315 20:57:42 @dqn_agent.py:203][0m episode: 6512, total game step: 146000, epsilon: 0.90496099
[32m[0315 20:57:42 @network.py:203][0m step: 96000, current TD loss: 0.0010139941005
[32m[0315 20:57:43 @network.py:203][0m step: 96100, current TD loss: 0.001992338337
[32m[0315 20:57:44 @network.py:203][0m step: 96200, current TD loss: 0.0186435040087
[32m[0315 20:57:45 @network.py:203][0m step: 96300, current TD loss: 5.05725984112e-05
[32m[0315 20:57:46 @network.py:203][0m step: 96400, current TD loss: 0.00332266069017
[32m[0315 20:57:48 @network.py:203][0m step: 96500, current TD loss: 0.000918775331229
[32m[0315 20:57:49 @network.py:203][0m step: 96600, current TD loss: 0.00451957248151
[32m[0315 20:57:50 @network.py:203][0m step: 96700, current TD loss: 9.29948873818e-05
[32m[0315 20:57:51 @network.py:203][0m step: 96800, current TD loss: 0.000992278801277
[32m[0315 20:57:52 @network.py:203][0m step: 96900, current TD loss: 0.00093311391538
[32m[0315 20:57:53 @dqn_agent.py:203][0m episode: 6559, total game step: 147000, epsilon: 0.90397099
[32m[0315 20:57:53 @network.py:203][0m step: 97000, current TD loss: 0.00221654796042
[32m[0315 20:57:54 @network.py:203][0m step: 97100, current TD loss: 7.03918485669e-05
[32m[0315 20:57:56 @network.py:203][0m step: 97200, current TD loss: 0.00201951921917
[32m[0315 20:57:57 @network.py:203][0m step: 97300, current TD loss: 0.00292783346958
[32m[0315 20:57:58 @network.py:203][0m step: 97400, current TD loss: 0.0179450400174
[32m[0315 20:57:59 @network.py:203][0m step: 97500, current TD loss: 0.000926303619053
[32m[0315 20:57:59 @dqn_agent.py:216][0m At time step 97500, the target_network is updated
[32m[0315 20:58:00 @network.py:203][0m step: 97600, current TD loss: 0.000990511500277
[32m[0315 20:58:01 @network.py:203][0m step: 97700, current TD loss: 8.72120144777e-05
[32m[0315 20:58:02 @network.py:203][0m step: 97800, current TD loss: 0.000991777284071
[32m[0315 20:58:04 @network.py:203][0m step: 97900, current TD loss: 0.0173992440104
[32m[0315 20:58:04 @summary_handler.py:101][0m At episode: 147932, Reward: 0.12 (over 100 episodes)
[32m[0315 20:58:04 @summary_handler.py:102][0m Length: 22.39
[32m[0315 20:58:05 @dqn_agent.py:203][0m episode: 6604, total game step: 148000, epsilon: 0.90298099
[32m[0315 20:58:05 @network.py:203][0m step: 98000, current TD loss: 0.000921231810935
[32m[0315 20:58:06 @network.py:203][0m step: 98100, current TD loss: 0.00288995332085
[32m[0315 20:58:07 @network.py:203][0m step: 98200, current TD loss: 0.00197163340636
[32m[0315 20:58:08 @network.py:203][0m step: 98300, current TD loss: 0.000939118443057
[32m[0315 20:58:09 @network.py:203][0m step: 98400, current TD loss: 9.91791457636e-05
[32m[0315 20:58:10 @network.py:203][0m step: 98500, current TD loss: 0.0177730638534
[32m[0315 20:58:12 @network.py:203][0m step: 98600, current TD loss: 0.00132678216323
[32m[0315 20:58:13 @network.py:203][0m step: 98700, current TD loss: 0.0182365197688
[32m[0315 20:58:14 @network.py:203][0m step: 98800, current TD loss: 0.0020241313614
[32m[0315 20:58:15 @network.py:203][0m step: 98900, current TD loss: 0.00095692841569
[32m[0315 20:58:16 @dqn_agent.py:203][0m episode: 6650, total game step: 149000, epsilon: 0.90199099
[32m[0315 20:58:16 @network.py:203][0m step: 99000, current TD loss: 0.00317915854976
[32m[0315 20:58:17 @network.py:203][0m step: 99100, current TD loss: 0.000991254812106
[32m[0315 20:58:18 @network.py:203][0m step: 99200, current TD loss: 0.00213514221832
[32m[0315 20:58:19 @network.py:203][0m step: 99300, current TD loss: 0.00192794646136
[32m[0315 20:58:21 @network.py:203][0m step: 99400, current TD loss: 0.00101387267932
[32m[0315 20:58:22 @network.py:203][0m step: 99500, current TD loss: 3.30578623107e-05
[32m[0315 20:58:23 @network.py:203][0m step: 99600, current TD loss: 0.0010308570927
[32m[0315 20:58:24 @network.py:203][0m step: 99700, current TD loss: 0.00386034324765
[32m[0315 20:58:25 @network.py:203][0m step: 99800, current TD loss: 0.00197590631433
[32m[0315 20:58:26 @network.py:203][0m step: 99900, current TD loss: 0.00399852218106
[32m[0315 20:58:28 @dqn_agent.py:203][0m episode: 6695, total game step: 150000, epsilon: 0.90100099
[32m[0315 20:58:28 @network.py:203][0m step: 100000, current TD loss: 0.0188558641821
[32m[0315 20:58:28 @dqn_agent.py:216][0m At time step 100000, the target_network is updated
[32m[0315 20:58:28 @summary_handler.py:101][0m At episode: 150076, Reward: 0.13 (over 100 episodes)
[32m[0315 20:58:28 @summary_handler.py:102][0m Length: 21.44
[32m[0315 20:58:29 @network.py:203][0m step: 100100, current TD loss: 0.00179873069283
[32m[0315 20:58:30 @network.py:203][0m step: 100200, current TD loss: 0.0184908285737
[32m[0315 20:58:31 @network.py:203][0m step: 100300, current TD loss: 0.000869301497005
[32m[0315 20:58:32 @network.py:203][0m step: 100400, current TD loss: 0.0170244015753
[32m[0315 20:58:33 @network.py:203][0m step: 100500, current TD loss: 0.000878470484167
[32m[0315 20:58:34 @network.py:203][0m step: 100600, current TD loss: 0.00385115086101
[32m[0315 20:58:35 @network.py:203][0m step: 100700, current TD loss: 0.000850636686664
[32m[0315 20:58:36 @network.py:203][0m step: 100800, current TD loss: 0.00413721194491
[32m[0315 20:58:38 @network.py:203][0m step: 100900, current TD loss: 0.00257645361125
[32m[0315 20:58:39 @dqn_agent.py:203][0m episode: 6743, total game step: 151000, epsilon: 0.90001099
[32m[0315 20:58:39 @network.py:203][0m step: 101000, current TD loss: 0.00255320873111
[32m[0315 20:58:40 @network.py:203][0m step: 101100, current TD loss: 0.00265918392688
[32m[0315 20:58:41 @network.py:203][0m step: 101200, current TD loss: 0.034843981266
[32m[0315 20:58:42 @network.py:203][0m step: 101300, current TD loss: 0.000953540729824
[32m[0315 20:58:43 @network.py:203][0m step: 101400, current TD loss: 0.0176159571856
[32m[0315 20:58:45 @network.py:203][0m step: 101500, current TD loss: 0.000965987797827
[32m[0315 20:58:46 @network.py:203][0m step: 101600, current TD loss: 0.000928641646169
[32m[0315 20:58:47 @network.py:203][0m step: 101700, current TD loss: 0.000989509397186
[32m[0315 20:58:48 @network.py:203][0m step: 101800, current TD loss: 0.000910268863663
[32m[0315 20:58:49 @network.py:203][0m step: 101900, current TD loss: 0.00351500371471
[32m[0315 20:58:50 @dqn_agent.py:203][0m episode: 6788, total game step: 152000, epsilon: 0.89902099
[32m[0315 20:58:50 @network.py:203][0m step: 102000, current TD loss: 0.000837332860101
[32m[0315 20:58:51 @network.py:203][0m step: 102100, current TD loss: 0.0177582204342
[32m[0315 20:58:52 @network.py:203][0m step: 102200, current TD loss: 0.00204605096951
[32m[0315 20:58:54 @network.py:203][0m step: 102300, current TD loss: 0.00182718003634
[32m[0315 20:58:54 @summary_handler.py:101][0m At episode: 152303, Reward: 0.13 (over 100 episodes)
[32m[0315 20:58:54 @summary_handler.py:102][0m Length: 22.27
[32m[0315 20:58:55 @network.py:203][0m step: 102400, current TD loss: 0.000897690071724
[32m[0315 20:58:56 @network.py:203][0m step: 102500, current TD loss: 0.00169496564195
[32m[0315 20:58:56 @dqn_agent.py:216][0m At time step 102500, the target_network is updated
[32m[0315 20:58:57 @network.py:203][0m step: 102600, current TD loss: 3.89921115129e-05
[32m[0315 20:58:58 @network.py:203][0m step: 102700, current TD loss: 0.00265976600349
[32m[0315 20:58:59 @network.py:203][0m step: 102800, current TD loss: 0.00189522455912
[32m[0315 20:59:00 @network.py:203][0m step: 102900, current TD loss: 0.0198143571615
[32m[0315 20:59:01 @dqn_agent.py:203][0m episode: 6834, total game step: 153000, epsilon: 0.89803099
[32m[0315 20:59:01 @network.py:203][0m step: 103000, current TD loss: 0.00486276205629
[32m[0315 20:59:02 @network.py:203][0m step: 103100, current TD loss: 0.0024095531553
[32m[0315 20:59:04 @network.py:203][0m step: 103200, current TD loss: 0.00178494350985
[32m[0315 20:59:05 @network.py:203][0m step: 103300, current TD loss: 0.00377336842939
[32m[0315 20:59:06 @network.py:203][0m step: 103400, current TD loss: 0.00251411786303
[32m[0315 20:59:07 @network.py:203][0m step: 103500, current TD loss: 7.26415819372e-05
[32m[0315 20:59:08 @network.py:203][0m step: 103600, current TD loss: 3.50826448994e-05
[32m[0315 20:59:09 @network.py:203][0m step: 103700, current TD loss: 0.000871581840329
[32m[0315 20:59:10 @network.py:203][0m step: 103800, current TD loss: 0.00104668247513
[32m[0315 20:59:12 @network.py:203][0m step: 103900, current TD loss: 0.00331628322601
[32m[0315 20:59:13 @dqn_agent.py:203][0m episode: 6879, total game step: 154000, epsilon: 0.89704099
[32m[0315 20:59:13 @network.py:203][0m step: 104000, current TD loss: 0.00160215387587
[32m[0315 20:59:14 @network.py:203][0m step: 104100, current TD loss: 0.00085835106438
[32m[0315 20:59:15 @network.py:203][0m step: 104200, current TD loss: 0.00181055639405
[32m[0315 20:59:16 @network.py:203][0m step: 104300, current TD loss: 5.21904075867e-05
[32m[0315 20:59:17 @network.py:203][0m step: 104400, current TD loss: 0.000892427517101
[32m[0315 20:59:18 @network.py:203][0m step: 104500, current TD loss: 0.00194639398251
[32m[0315 20:59:18 @summary_handler.py:101][0m At episode: 154507, Reward: 0.13 (over 100 episodes)
[32m[0315 20:59:18 @summary_handler.py:102][0m Length: 22.04
[32m[0315 20:59:20 @network.py:203][0m step: 104600, current TD loss: 0.00185808795504
[32m[0315 20:59:21 @network.py:203][0m step: 104700, current TD loss: 0.017151074484
[32m[0315 20:59:22 @network.py:203][0m step: 104800, current TD loss: 0.000983216799796
[32m[0315 20:59:23 @network.py:203][0m step: 104900, current TD loss: 0.000941931968555
[32m[0315 20:59:24 @dqn_agent.py:203][0m episode: 6923, total game step: 155000, epsilon: 0.89605099
[32m[0315 20:59:24 @network.py:203][0m step: 105000, current TD loss: 0.00090452603763
[32m[0315 20:59:24 @dqn_agent.py:216][0m At time step 105000, the target_network is updated
[32m[0315 20:59:25 @network.py:203][0m step: 105100, current TD loss: 0.00117779814173
[32m[0315 20:59:26 @network.py:203][0m step: 105200, current TD loss: 0.00199963175692
[32m[0315 20:59:28 @network.py:203][0m step: 105300, current TD loss: 0.000919775338843
[32m[0315 20:59:29 @network.py:203][0m step: 105400, current TD loss: 0.00261382129975
[32m[0315 20:59:30 @network.py:203][0m step: 105500, current TD loss: 0.0017508068122
[32m[0315 20:59:31 @network.py:203][0m step: 105600, current TD loss: 0.000885959190782
[32m[0315 20:59:32 @network.py:203][0m step: 105700, current TD loss: 0.00232818932272
[32m[0315 20:59:33 @network.py:203][0m step: 105800, current TD loss: 0.000970519788098
[32m[0315 20:59:34 @network.py:203][0m step: 105900, current TD loss: 0.00202646618709
[32m[0315 20:59:36 @dqn_agent.py:203][0m episode: 6962, total game step: 156000, epsilon: 0.89506099
[32m[0315 20:59:36 @network.py:203][0m step: 106000, current TD loss: 0.00460404902697
[32m[0315 20:59:37 @network.py:203][0m step: 106100, current TD loss: 0.00339951249771
[32m[0315 20:59:38 @network.py:203][0m step: 106200, current TD loss: 0.000987100414932
[32m[0315 20:59:39 @network.py:203][0m step: 106300, current TD loss: 0.00278140790761
[32m[0315 20:59:40 @network.py:203][0m step: 106400, current TD loss: 0.000922580482438
[32m[0315 20:59:41 @network.py:203][0m step: 106500, current TD loss: 0.0176017601043
[32m[0315 20:59:42 @network.py:203][0m step: 106600, current TD loss: 7.48633901821e-05
[32m[0315 20:59:43 @network.py:203][0m step: 106700, current TD loss: 5.37144660484e-05
[32m[0315 20:59:44 @network.py:203][0m step: 106800, current TD loss: 2.85357982648e-05
[32m[0315 20:59:46 @network.py:203][0m step: 106900, current TD loss: 0.000934853567742
[32m[0315 20:59:46 @summary_handler.py:101][0m At episode: 156934, Reward: 0.19 (over 100 episodes)
[32m[0315 20:59:46 @summary_handler.py:102][0m Length: 24.27
[32m[0315 20:59:47 @dqn_agent.py:203][0m episode: 7004, total game step: 157000, epsilon: 0.89407099
[32m[0315 20:59:47 @network.py:203][0m step: 107000, current TD loss: 0.0177044309676
[32m[0315 20:59:48 @network.py:203][0m step: 107100, current TD loss: 0.0173496995121
[32m[0315 20:59:49 @network.py:203][0m step: 107200, current TD loss: 0.000911963696126
[32m[0315 20:59:50 @network.py:203][0m step: 107300, current TD loss: 0.0170647818595
[32m[0315 20:59:51 @network.py:203][0m step: 107400, current TD loss: 6.00096973358e-05
[32m[0315 20:59:53 @network.py:203][0m step: 107500, current TD loss: 0.000960721052252
[32m[0315 20:59:53 @dqn_agent.py:216][0m At time step 107500, the target_network is updated
[32m[0315 20:59:54 @network.py:203][0m step: 107600, current TD loss: 0.00166390207596
[32m[0315 20:59:55 @network.py:203][0m step: 107700, current TD loss: 0.00162549002562
[32m[0315 20:59:56 @network.py:203][0m step: 107800, current TD loss: 0.00184901931789
[32m[0315 20:59:57 @network.py:203][0m step: 107900, current TD loss: 0.000883201719262
[32m[0315 20:59:58 @dqn_agent.py:203][0m episode: 7052, total game step: 158000, epsilon: 0.89308099
[32m[0315 20:59:58 @network.py:203][0m step: 108000, current TD loss: 0.00166251091287
[32m[0315 20:59:59 @network.py:203][0m step: 108100, current TD loss: 0.0349597483873
[32m[0315 21:00:00 @network.py:203][0m step: 108200, current TD loss: 0.00182354543358
[32m[0315 21:00:01 @network.py:203][0m step: 108300, current TD loss: 0.00173945550341
[32m[0315 21:00:03 @network.py:203][0m step: 108400, current TD loss: 0.00172812398523
[32m[0315 21:00:04 @network.py:203][0m step: 108500, current TD loss: 9.28160588956e-05
[32m[0315 21:00:05 @network.py:203][0m step: 108600, current TD loss: 0.016836328432
[32m[0315 21:00:06 @network.py:203][0m step: 108700, current TD loss: 0.00274951430038
[32m[0315 21:00:07 @network.py:203][0m step: 108800, current TD loss: 0.0171172134578
[32m[0315 21:00:08 @network.py:203][0m step: 108900, current TD loss: 0.00382287614048
[32m[0315 21:00:09 @dqn_agent.py:203][0m episode: 7091, total game step: 159000, epsilon: 0.89209099
[32m[0315 21:00:09 @network.py:203][0m step: 109000, current TD loss: 0.00110454740934
[32m[0315 21:00:10 @network.py:203][0m step: 109100, current TD loss: 7.07524814061e-05
[32m[0315 21:00:11 @network.py:203][0m step: 109200, current TD loss: 0.0177464857697
[32m[0315 21:00:12 @summary_handler.py:101][0m At episode: 159227, Reward: 0.2 (over 100 episodes)
[32m[0315 21:00:12 @summary_handler.py:102][0m Length: 22.93
[32m[0315 21:00:13 @network.py:203][0m step: 109300, current TD loss: 0.0191692039371
[32m[0315 21:00:14 @network.py:203][0m step: 109400, current TD loss: 0.00251198583283
[32m[0315 21:00:15 @network.py:203][0m step: 109500, current TD loss: 5.62538771192e-05
[32m[0315 21:00:16 @network.py:203][0m step: 109600, current TD loss: 0.000889679591637
[32m[0315 21:00:17 @network.py:203][0m step: 109700, current TD loss: 2.4350005333e-05
[32m[0315 21:00:18 @network.py:203][0m step: 109800, current TD loss: 0.00106921070255
[32m[0315 21:00:20 @network.py:203][0m step: 109900, current TD loss: 0.00183976907283
[32m[0315 21:00:21 @dqn_agent.py:203][0m episode: 7136, total game step: 160000, epsilon: 0.89110099
[32m[0315 21:00:21 @network.py:203][0m step: 110000, current TD loss: 0.00107260514051
[32m[0315 21:00:21 @dqn_agent.py:216][0m At time step 110000, the target_network is updated
[32m[0315 21:00:22 @network.py:203][0m step: 110100, current TD loss: 0.00180345762055
[32m[0315 21:00:23 @network.py:203][0m step: 110200, current TD loss: 0.00267274584621
[32m[0315 21:00:24 @network.py:203][0m step: 110300, current TD loss: 0.00265872105956
[32m[0315 21:00:25 @network.py:203][0m step: 110400, current TD loss: 0.0010014398722
[32m[0315 21:00:26 @network.py:203][0m step: 110500, current TD loss: 0.000971798843239
[32m[0315 21:00:28 @network.py:203][0m step: 110600, current TD loss: 0.00291519239545
[32m[0315 21:00:29 @network.py:203][0m step: 110700, current TD loss: 0.016438184306
[32m[0315 21:00:30 @network.py:203][0m step: 110800, current TD loss: 0.000870660936926
[32m[0315 21:00:31 @network.py:203][0m step: 110900, current TD loss: 0.00324768503197
[32m[0315 21:00:32 @dqn_agent.py:203][0m episode: 7179, total game step: 161000, epsilon: 0.89011099
[32m[0315 21:00:32 @network.py:203][0m step: 111000, current TD loss: 0.0159506443888
[32m[0315 21:00:33 @network.py:203][0m step: 111100, current TD loss: 0.00186729780398
[32m[0315 21:00:34 @network.py:203][0m step: 111200, current TD loss: 0.00185644254088
[32m[0315 21:00:36 @network.py:203][0m step: 111300, current TD loss: 0.00413956306875
[32m[0315 21:00:37 @summary_handler.py:101][0m At episode: 161383, Reward: 0.14 (over 100 episodes)
[32m[0315 21:00:37 @summary_handler.py:102][0m Length: 21.56
[32m[0315 21:00:37 @network.py:203][0m step: 111400, current TD loss: 0.00356159848161
[32m[0315 21:00:38 @network.py:203][0m step: 111500, current TD loss: 9.72253765212e-05
[32m[0315 21:00:39 @network.py:203][0m step: 111600, current TD loss: 0.00465375557542
[32m[0315 21:00:40 @network.py:203][0m step: 111700, current TD loss: 5.21342590218e-05
[32m[0315 21:00:41 @network.py:203][0m step: 111800, current TD loss: 0.00125675345771
[32m[0315 21:00:42 @network.py:203][0m step: 111900, current TD loss: 0.00299604726024
[32m[0315 21:00:44 @dqn_agent.py:203][0m episode: 7229, total game step: 162000, epsilon: 0.88912099
[32m[0315 21:00:44 @network.py:203][0m step: 112000, current TD loss: 0.000980350072496
[32m[0315 21:00:45 @network.py:203][0m step: 112100, current TD loss: 0.00193355570082
[32m[0315 21:00:46 @network.py:203][0m step: 112200, current TD loss: 0.0025633382611
[32m[0315 21:00:47 @network.py:203][0m step: 112300, current TD loss: 0.00352503615431
[32m[0315 21:00:48 @network.py:203][0m step: 112400, current TD loss: 0.00103644898627
[32m[0315 21:00:49 @network.py:203][0m step: 112500, current TD loss: 0.00274518039078
[32m[0315 21:00:49 @dqn_agent.py:216][0m At time step 112500, the target_network is updated
[32m[0315 21:00:50 @network.py:203][0m step: 112600, current TD loss: 0.0038548707962
[32m[0315 21:00:52 @network.py:203][0m step: 112700, current TD loss: 0.0017610299401
[32m[0315 21:00:53 @network.py:203][0m step: 112800, current TD loss: 0.00401636539027
[32m[0315 21:00:54 @network.py:203][0m step: 112900, current TD loss: 0.000944414758123
[32m[0315 21:00:55 @dqn_agent.py:203][0m episode: 7273, total game step: 163000, epsilon: 0.88813099
[32m[0315 21:00:55 @network.py:203][0m step: 113000, current TD loss: 0.000890365510713
[32m[0315 21:00:56 @network.py:203][0m step: 113100, current TD loss: 2.90776170004e-05
[32m[0315 21:00:57 @network.py:203][0m step: 113200, current TD loss: 0.000865844776854
[32m[0315 21:00:58 @network.py:203][0m step: 113300, current TD loss: 0.0175018180162
[32m[0315 21:01:00 @network.py:203][0m step: 113400, current TD loss: 0.017932638526
[32m[0315 21:01:01 @network.py:203][0m step: 113500, current TD loss: 0.0010304787429
[32m[0315 21:01:01 @summary_handler.py:101][0m At episode: 163557, Reward: 0.09 (over 100 episodes)
[32m[0315 21:01:01 @summary_handler.py:102][0m Length: 21.74
[32m[0315 21:01:02 @network.py:203][0m step: 113600, current TD loss: 0.0019660689868
[32m[0315 21:01:03 @network.py:203][0m step: 113700, current TD loss: 0.0020088988822
[32m[0315 21:01:04 @network.py:203][0m step: 113800, current TD loss: 0.00097887776792
[32m[0315 21:01:05 @network.py:203][0m step: 113900, current TD loss: 0.00091006438015
[32m[0315 21:01:06 @dqn_agent.py:203][0m episode: 7319, total game step: 164000, epsilon: 0.88714099
[32m[0315 21:01:06 @network.py:203][0m step: 114000, current TD loss: 0.0176708959043
[32m[0315 21:01:07 @network.py:203][0m step: 114100, current TD loss: 0.0508066527545
[32m[0315 21:01:09 @network.py:203][0m step: 114200, current TD loss: 0.00269629061222
[32m[0315 21:01:10 @network.py:203][0m step: 114300, current TD loss: 0.00356397870928
[32m[0315 21:01:11 @network.py:203][0m step: 114400, current TD loss: 0.000958115851972
[32m[0315 21:01:12 @network.py:203][0m step: 114500, current TD loss: 1.72530126292e-05
[32m[0315 21:01:13 @network.py:203][0m step: 114600, current TD loss: 0.0179685354233
[32m[0315 21:01:14 @network.py:203][0m step: 114700, current TD loss: 0.00350501108915
[32m[0315 21:01:15 @network.py:203][0m step: 114800, current TD loss: 0.00102210300975
[32m[0315 21:01:17 @network.py:203][0m step: 114900, current TD loss: 0.0184206087142
[32m[0315 21:01:18 @dqn_agent.py:203][0m episode: 7366, total game step: 165000, epsilon: 0.88615099
[32m[0315 21:01:18 @network.py:203][0m step: 115000, current TD loss: 3.01576619677e-05
[32m[0315 21:01:18 @dqn_agent.py:216][0m At time step 115000, the target_network is updated
[32m[0315 21:01:19 @network.py:203][0m step: 115100, current TD loss: 0.0320605263114
[32m[0315 21:01:20 @network.py:203][0m step: 115200, current TD loss: 0.00355634791777
[32m[0315 21:01:21 @network.py:203][0m step: 115300, current TD loss: 0.0179325584322
[32m[0315 21:01:22 @network.py:203][0m step: 115400, current TD loss: 0.0012816155795
[32m[0315 21:01:24 @network.py:203][0m step: 115500, current TD loss: 8.49273928907e-05
[32m[0315 21:01:25 @network.py:203][0m step: 115600, current TD loss: 0.00190915516578
[32m[0315 21:01:25 @summary_handler.py:101][0m At episode: 165607, Reward: 0.1 (over 100 episodes)
[32m[0315 21:01:25 @summary_handler.py:102][0m Length: 20.5
[32m[0315 21:01:26 @network.py:203][0m step: 115700, current TD loss: 0.00402712356299
[32m[0315 21:01:27 @network.py:203][0m step: 115800, current TD loss: 0.0176975857466
[32m[0315 21:01:28 @network.py:203][0m step: 115900, current TD loss: 0.00193103600759
[32m[0315 21:01:29 @dqn_agent.py:203][0m episode: 7416, total game step: 166000, epsilon: 0.88516099
[32m[0315 21:01:29 @network.py:203][0m step: 116000, current TD loss: 0.0158941149712
[32m[0315 21:01:30 @network.py:203][0m step: 116100, current TD loss: 0.00293281511404
[32m[0315 21:01:31 @network.py:203][0m step: 116200, current TD loss: 0.0158935524523
[32m[0315 21:01:33 @network.py:203][0m step: 116300, current TD loss: 0.0174279697239
[32m[0315 21:01:34 @network.py:203][0m step: 116400, current TD loss: 0.00294844992459
[32m[0315 21:01:35 @network.py:203][0m step: 116500, current TD loss: 0.0176812782884
[32m[0315 21:01:36 @network.py:203][0m step: 116600, current TD loss: 0.000988983199932
[32m[0315 21:01:37 @network.py:203][0m step: 116700, current TD loss: 0.0169840473682
[32m[0315 21:01:38 @network.py:203][0m step: 116800, current TD loss: 0.0009701877716
[32m[0315 21:01:39 @network.py:203][0m step: 116900, current TD loss: 3.31838637067e-05
[32m[0315 21:01:41 @dqn_agent.py:203][0m episode: 7454, total game step: 167000, epsilon: 0.88417099
[32m[0315 21:01:41 @network.py:203][0m step: 117000, current TD loss: 0.000924426014535
[32m[0315 21:01:42 @network.py:203][0m step: 117100, current TD loss: 0.00186839874368
[32m[0315 21:01:43 @network.py:203][0m step: 117200, current TD loss: 0.00103860697709
[32m[0315 21:01:44 @network.py:203][0m step: 117300, current TD loss: 0.000977827003226
[32m[0315 21:01:45 @network.py:203][0m step: 117400, current TD loss: 0.00100023974665
[32m[0315 21:01:46 @network.py:203][0m step: 117500, current TD loss: 0.017883811146
[32m[0315 21:01:46 @dqn_agent.py:216][0m At time step 117500, the target_network is updated
[32m[0315 21:01:47 @network.py:203][0m step: 117600, current TD loss: 0.00215505063534
[32m[0315 21:01:48 @network.py:203][0m step: 117700, current TD loss: 0.000948635570239
[32m[0315 21:01:50 @network.py:203][0m step: 117800, current TD loss: 0.00229577347636
[32m[0315 21:01:51 @network.py:203][0m step: 117900, current TD loss: 0.000980099313892
[32m[0315 21:01:52 @dqn_agent.py:203][0m episode: 7491, total game step: 168000, epsilon: 0.88318099
[32m[0315 21:01:52 @network.py:203][0m step: 118000, current TD loss: 3.34279648087e-05
[32m[0315 21:01:53 @network.py:203][0m step: 118100, current TD loss: 0.00187578483019
[32m[0315 21:01:54 @summary_handler.py:101][0m At episode: 168144, Reward: 0.26 (over 100 episodes)
[32m[0315 21:01:54 @summary_handler.py:102][0m Length: 25.37
[32m[0315 21:01:54 @network.py:203][0m step: 118200, current TD loss: 0.00187756528612
[32m[0315 21:01:55 @network.py:203][0m step: 118300, current TD loss: 0.00371704553254
[32m[0315 21:01:56 @network.py:203][0m step: 118400, current TD loss: 0.00126134429593
[32m[0315 21:01:58 @network.py:203][0m step: 118500, current TD loss: 0.00493066757917
[32m[0315 21:01:59 @network.py:203][0m step: 118600, current TD loss: 0.000969363900367
[32m[0315 21:02:00 @network.py:203][0m step: 118700, current TD loss: 0.00266249524429
[32m[0315 21:02:01 @network.py:203][0m step: 118800, current TD loss: 0.00201474386267
[32m[0315 21:02:02 @network.py:203][0m step: 118900, current TD loss: 0.00097240897594
[32m[0315 21:02:03 @dqn_agent.py:203][0m episode: 7539, total game step: 169000, epsilon: 0.88219099
[32m[0315 21:02:03 @network.py:203][0m step: 119000, current TD loss: 0.00185959774535
[32m[0315 21:02:04 @network.py:203][0m step: 119100, current TD loss: 0.00283161387779
[32m[0315 21:02:05 @network.py:203][0m step: 119200, current TD loss: 0.00352862570435
[32m[0315 21:02:07 @network.py:203][0m step: 119300, current TD loss: 0.00272239884362
[32m[0315 21:02:08 @network.py:203][0m step: 119400, current TD loss: 0.00123060925398
[32m[0315 21:02:09 @network.py:203][0m step: 119500, current TD loss: 0.00221622455865
[32m[0315 21:02:10 @network.py:203][0m step: 119600, current TD loss: 0.0174519531429
[32m[0315 21:02:11 @network.py:203][0m step: 119700, current TD loss: 0.00240010768175
[32m[0315 21:02:12 @network.py:203][0m step: 119800, current TD loss: 0.000898519996554
[32m[0315 21:02:13 @network.py:203][0m step: 119900, current TD loss: 0.0185556150973
[32m[0315 21:02:14 @dqn_agent.py:203][0m episode: 7582, total game step: 170000, epsilon: 0.88120099
[32m[0315 21:02:14 @network.py:203][0m step: 120000, current TD loss: 0.01614080742
[32m[0315 21:02:14 @dqn_agent.py:216][0m At time step 120000, the target_network is updated
[32m[0315 21:02:16 @network.py:203][0m step: 120100, current TD loss: 0.00207825074904
[32m[0315 21:02:17 @network.py:203][0m step: 120200, current TD loss: 0.0164831485599
[32m[0315 21:02:18 @network.py:203][0m step: 120300, current TD loss: 0.000913668482099
[32m[0315 21:02:19 @summary_handler.py:101][0m At episode: 170379, Reward: 0.12 (over 100 episodes)
[32m[0315 21:02:19 @summary_handler.py:102][0m Length: 22.35
[32m[0315 21:02:19 @network.py:203][0m step: 120400, current TD loss: 0.0180453527719
[32m[0315 21:02:20 @network.py:203][0m step: 120500, current TD loss: 0.0171652566642
[32m[0315 21:02:21 @network.py:203][0m step: 120600, current TD loss: 0.000996308168396
[32m[0315 21:02:22 @network.py:203][0m step: 120700, current TD loss: 0.0167768727988
[32m[0315 21:02:23 @network.py:203][0m step: 120800, current TD loss: 0.00178286712617
[32m[0315 21:02:24 @network.py:203][0m step: 120900, current TD loss: 3.44273648807e-05
[32m[0315 21:02:26 @dqn_agent.py:203][0m episode: 7623, total game step: 171000, epsilon: 0.88021099
[32m[0315 21:02:26 @network.py:203][0m step: 121000, current TD loss: 0.0169935319573
[32m[0315 21:02:27 @network.py:203][0m step: 121100, current TD loss: 0.0175878629088
[32m[0315 21:02:28 @network.py:203][0m step: 121200, current TD loss: 0.00203820038587
[32m[0315 21:02:29 @network.py:203][0m step: 121300, current TD loss: 4.25698890467e-05
[32m[0315 21:02:30 @network.py:203][0m step: 121400, current TD loss: 5.75829981244e-05
[32m[0315 21:02:31 @network.py:203][0m step: 121500, current TD loss: 0.00209059566259
[32m[0315 21:02:32 @network.py:203][0m step: 121600, current TD loss: 0.00195230089594
[32m[0315 21:02:33 @network.py:203][0m step: 121700, current TD loss: 0.00347934477031
[32m[0315 21:02:34 @network.py:203][0m step: 121800, current TD loss: 2.3517617592e-05
[32m[0315 21:02:36 @network.py:203][0m step: 121900, current TD loss: 0.00105907814577
[32m[0315 21:02:37 @dqn_agent.py:203][0m episode: 7666, total game step: 172000, epsilon: 0.87922099
[32m[0315 21:02:37 @network.py:203][0m step: 122000, current TD loss: 0.00328949885443
[32m[0315 21:02:38 @network.py:203][0m step: 122100, current TD loss: 0.00193968764506
[32m[0315 21:02:39 @network.py:203][0m step: 122200, current TD loss: 0.0173718314618
[32m[0315 21:02:40 @network.py:203][0m step: 122300, current TD loss: 0.00273145944811
[32m[0315 21:02:41 @network.py:203][0m step: 122400, current TD loss: 0.00275061558932
[32m[0315 21:02:42 @network.py:203][0m step: 122500, current TD loss: 0.000960441597272
[32m[0315 21:02:42 @dqn_agent.py:216][0m At time step 122500, the target_network is updated
[32m[0315 21:02:43 @network.py:203][0m step: 122600, current TD loss: 0.00102305575274
[32m[0315 21:02:45 @network.py:203][0m step: 122700, current TD loss: 0.00111079507042
[32m[0315 21:02:46 @network.py:203][0m step: 122800, current TD loss: 0.00185963779222
[32m[0315 21:02:46 @summary_handler.py:101][0m At episode: 172858, Reward: 0.15 (over 100 episodes)
[32m[0315 21:02:46 @summary_handler.py:102][0m Length: 24.79
[32m[0315 21:02:47 @network.py:203][0m step: 122900, current TD loss: 0.00264869816601
[32m[0315 21:02:48 @dqn_agent.py:203][0m episode: 7704, total game step: 173000, epsilon: 0.87823099
[32m[0315 21:02:48 @network.py:203][0m step: 123000, current TD loss: 0.0162493847311
[32m[0315 21:02:49 @network.py:203][0m step: 123100, current TD loss: 0.0025107099209
[32m[0315 21:02:50 @network.py:203][0m step: 123200, current TD loss: 4.52772001154e-05
[32m[0315 21:02:51 @network.py:203][0m step: 123300, current TD loss: 0.00180190661922
[32m[0315 21:02:52 @network.py:203][0m step: 123400, current TD loss: 2.70396194537e-05
[32m[0315 21:02:54 @network.py:203][0m step: 123500, current TD loss: 0.00423792935908
[32m[0315 21:02:55 @network.py:203][0m step: 123600, current TD loss: 0.00098314252682
[32m[0315 21:02:56 @network.py:203][0m step: 123700, current TD loss: 0.00271692476235
[32m[0315 21:02:57 @network.py:203][0m step: 123800, current TD loss: 0.00218013953418
[32m[0315 21:02:58 @network.py:203][0m step: 123900, current TD loss: 0.0185878686607
[32m[0315 21:02:59 @dqn_agent.py:203][0m episode: 7742, total game step: 174000, epsilon: 0.87724099
[32m[0315 21:02:59 @network.py:203][0m step: 124000, current TD loss: 0.0043975757435
[32m[0315 21:03:00 @network.py:203][0m step: 124100, current TD loss: 0.00268204580061
[32m[0315 21:03:01 @network.py:203][0m step: 124200, current TD loss: 0.00222884165123
[32m[0315 21:03:03 @network.py:203][0m step: 124300, current TD loss: 0.00255108694546
[32m[0315 21:03:04 @network.py:203][0m step: 124400, current TD loss: 0.0192862600088
[32m[0315 21:03:05 @network.py:203][0m step: 124500, current TD loss: 0.00272294040769
[32m[0315 21:03:06 @network.py:203][0m step: 124600, current TD loss: 0.00120653735939
[32m[0315 21:03:07 @network.py:203][0m step: 124700, current TD loss: 7.65707809478e-05
[32m[0315 21:03:08 @network.py:203][0m step: 124800, current TD loss: 0.000922870240174
[32m[0315 21:03:09 @network.py:203][0m step: 124900, current TD loss: 0.00100808520801
[32m[0315 21:03:10 @dqn_agent.py:203][0m episode: 7795, total game step: 175000, epsilon: 0.87625099
[32m[0315 21:03:11 @network.py:203][0m step: 125000, current TD loss: 0.0161266867071
[32m[0315 21:03:11 @dqn_agent.py:216][0m At time step 125000, the target_network is updated
[32m[0315 21:03:11 @summary_handler.py:101][0m At episode: 175073, Reward: 0.11 (over 100 episodes)
[32m[0315 21:03:11 @summary_handler.py:102][0m Length: 22.15
[32m[0315 21:03:12 @network.py:203][0m step: 125100, current TD loss: 0.0169574934989
[32m[0315 21:03:13 @network.py:203][0m step: 125200, current TD loss: 0.0001226128079
[32m[0315 21:03:14 @network.py:203][0m step: 125300, current TD loss: 0.0170346535742
[32m[0315 21:03:15 @network.py:203][0m step: 125400, current TD loss: 0.0177623219788
[32m[0315 21:03:16 @network.py:203][0m step: 125500, current TD loss: 0.00215791258961
[32m[0315 21:03:17 @network.py:203][0m step: 125600, current TD loss: 0.00193450797815
[32m[0315 21:03:18 @network.py:203][0m step: 125700, current TD loss: 0.000892060401384
[32m[0315 21:03:20 @network.py:203][0m step: 125800, current TD loss: 0.00144983397331
[32m[0315 21:03:21 @network.py:203][0m step: 125900, current TD loss: 0.0188533719629
[32m[0315 21:03:22 @dqn_agent.py:203][0m episode: 7839, total game step: 176000, epsilon: 0.87526099
[32m[0315 21:03:22 @network.py:203][0m step: 126000, current TD loss: 8.17779291538e-05
[32m[0315 21:03:23 @network.py:203][0m step: 126100, current TD loss: 0.000896601006389
[32m[0315 21:03:24 @network.py:203][0m step: 126200, current TD loss: 0.0167886894196
[32m[0315 21:03:25 @network.py:203][0m step: 126300, current TD loss: 0.0154666062444
[32m[0315 21:03:26 @network.py:203][0m step: 126400, current TD loss: 0.00370329082943
[32m[0315 21:03:27 @network.py:203][0m step: 126500, current TD loss: 0.0324985422194
[32m[0315 21:03:29 @network.py:203][0m step: 126600, current TD loss: 0.0172219052911
[32m[0315 21:03:30 @network.py:203][0m step: 126700, current TD loss: 0.00182878260966
[32m[0315 21:03:31 @network.py:203][0m step: 126800, current TD loss: 0.00140927557368
[32m[0315 21:03:32 @network.py:203][0m step: 126900, current TD loss: 0.00227603618987
[32m[0315 21:03:33 @dqn_agent.py:203][0m episode: 7886, total game step: 177000, epsilon: 0.87427099
[32m[0315 21:03:33 @network.py:203][0m step: 127000, current TD loss: 0.00602413062006
[32m[0315 21:03:34 @network.py:203][0m step: 127100, current TD loss: 0.00107761239633
[32m[0315 21:03:35 @network.py:203][0m step: 127200, current TD loss: 0.00186137645505
[32m[0315 21:03:36 @network.py:203][0m step: 127300, current TD loss: 0.00104939448647
[32m[0315 21:03:37 @summary_handler.py:101][0m At episode: 177365, Reward: 0.16 (over 100 episodes)
[32m[0315 21:03:37 @summary_handler.py:102][0m Length: 22.92
[32m[0315 21:03:38 @network.py:203][0m step: 127400, current TD loss: 0.00202196184546
[32m[0315 21:03:39 @network.py:203][0m step: 127500, current TD loss: 0.00215558614582
[32m[0315 21:03:39 @dqn_agent.py:216][0m At time step 127500, the target_network is updated
[32m[0315 21:03:40 @network.py:203][0m step: 127600, current TD loss: 0.017532216385
[32m[0315 21:03:41 @network.py:203][0m step: 127700, current TD loss: 0.00226343958639
[32m[0315 21:03:42 @network.py:203][0m step: 127800, current TD loss: 0.0162259098142
[32m[0315 21:03:43 @network.py:203][0m step: 127900, current TD loss: 0.0039668912068
[32m[0315 21:03:44 @dqn_agent.py:203][0m episode: 7922, total game step: 178000, epsilon: 0.87328099
[32m[0315 21:03:44 @network.py:203][0m step: 128000, current TD loss: 0.0184911265969
[32m[0315 21:03:46 @network.py:203][0m step: 128100, current TD loss: 0.00192775879987
[32m[0315 21:03:47 @network.py:203][0m step: 128200, current TD loss: 0.00102108868305
[32m[0315 21:03:48 @network.py:203][0m step: 128300, current TD loss: 0.00193902128376
[32m[0315 21:03:49 @network.py:203][0m step: 128400, current TD loss: 0.00427607866004
[32m[0315 21:03:50 @network.py:203][0m step: 128500, current TD loss: 0.0324224159122
[32m[0315 21:03:51 @network.py:203][0m step: 128600, current TD loss: 0.00201307423413
[32m[0315 21:03:52 @network.py:203][0m step: 128700, current TD loss: 0.00207650405355
[32m[0315 21:03:53 @network.py:203][0m step: 128800, current TD loss: 0.00386434001848
[32m[0315 21:03:54 @network.py:203][0m step: 128900, current TD loss: 0.00280843907967
[32m[0315 21:03:56 @dqn_agent.py:203][0m episode: 7957, total game step: 179000, epsilon: 0.87229099
[32m[0315 21:03:56 @network.py:203][0m step: 129000, current TD loss: 0.0195201095194
[32m[0315 21:03:57 @network.py:203][0m step: 129100, current TD loss: 7.61929841246e-05
[32m[0315 21:03:58 @network.py:203][0m step: 129200, current TD loss: 0.0197636410594
[32m[0315 21:03:59 @network.py:203][0m step: 129300, current TD loss: 0.00100356724579
[32m[0315 21:04:00 @network.py:203][0m step: 129400, current TD loss: 0.00325465970673
[32m[0315 21:04:01 @network.py:203][0m step: 129500, current TD loss: 0.0163132026792
[32m[0315 21:04:02 @network.py:203][0m step: 129600, current TD loss: 0.0194809027016
[32m[0315 21:04:03 @network.py:203][0m step: 129700, current TD loss: 6.81284291204e-05
[32m[0315 21:04:05 @network.py:203][0m step: 129800, current TD loss: 0.00103014451452
[32m[0315 21:04:06 @network.py:203][0m step: 129900, current TD loss: 0.00261588115245
[32m[0315 21:04:07 @dqn_agent.py:203][0m episode: 7997, total game step: 180000, epsilon: 0.87130099
[32m[0315 21:04:07 @network.py:203][0m step: 130000, current TD loss: 0.0154269691557
[32m[0315 21:04:07 @dqn_agent.py:216][0m At time step 130000, the target_network is updated
[32m[0315 21:04:08 @summary_handler.py:101][0m At episode: 180090, Reward: 0.22 (over 100 episodes)
[32m[0315 21:04:08 @summary_handler.py:102][0m Length: 27.25
[32m[0315 21:04:08 @network.py:203][0m step: 130100, current TD loss: 0.00295713846572
[32m[0315 21:04:09 @network.py:203][0m step: 130200, current TD loss: 0.00184503220953
[32m[0315 21:04:10 @network.py:203][0m step: 130300, current TD loss: 0.0010661627166
[32m[0315 21:04:11 @network.py:203][0m step: 130400, current TD loss: 5.67233801121e-05
[32m[0315 21:04:13 @network.py:203][0m step: 130500, current TD loss: 0.000971733301412
[32m[0315 21:04:14 @network.py:203][0m step: 130600, current TD loss: 0.00182603194844
[32m[0315 21:04:15 @network.py:203][0m step: 130700, current TD loss: 0.000952584552579
[32m[0315 21:04:16 @network.py:203][0m step: 130800, current TD loss: 1.85891512956e-05
[32m[0315 21:04:17 @network.py:203][0m step: 130900, current TD loss: 0.00198022718541
[32m[0315 21:04:18 @dqn_agent.py:203][0m episode: 8041, total game step: 181000, epsilon: 0.87031099
[32m[0315 21:04:18 @network.py:203][0m step: 131000, current TD loss: 0.00105113023892
[32m[0315 21:04:19 @network.py:203][0m step: 131100, current TD loss: 0.00104230630677
[32m[0315 21:04:20 @network.py:203][0m step: 131200, current TD loss: 0.016836963594
[32m[0315 21:04:21 @network.py:203][0m step: 131300, current TD loss: 3.87020809285e-05
[32m[0315 21:04:22 @network.py:203][0m step: 131400, current TD loss: 4.6458291763e-05
[32m[0315 21:04:24 @network.py:203][0m step: 131500, current TD loss: 3.19144164678e-05
[32m[0315 21:04:25 @network.py:203][0m step: 131600, current TD loss: 0.00323449261487
[32m[0315 21:04:26 @network.py:203][0m step: 131700, current TD loss: 0.00304794823751
[32m[0315 21:04:27 @network.py:203][0m step: 131800, current TD loss: 0.00139670772478
[32m[0315 21:04:28 @network.py:203][0m step: 131900, current TD loss: 0.0184840578586
[32m[0315 21:04:29 @dqn_agent.py:203][0m episode: 8083, total game step: 182000, epsilon: 0.86932099
[32m[0315 21:04:29 @network.py:203][0m step: 132000, current TD loss: 0.0171447042376
[32m[0315 21:04:30 @network.py:203][0m step: 132100, current TD loss: 0.00181887450162
[32m[0315 21:04:31 @network.py:203][0m step: 132200, current TD loss: 0.00284820888191
[32m[0315 21:04:33 @network.py:203][0m step: 132300, current TD loss: 0.00201149052009
[32m[0315 21:04:33 @summary_handler.py:101][0m At episode: 182367, Reward: 0.14 (over 100 episodes)
[32m[0315 21:04:33 @summary_handler.py:102][0m Length: 22.77
[32m[0315 21:04:34 @network.py:203][0m step: 132400, current TD loss: 0.0163598526269
[32m[0315 21:04:35 @network.py:203][0m step: 132500, current TD loss: 0.00100982643198
[32m[0315 21:04:35 @dqn_agent.py:216][0m At time step 132500, the target_network is updated
[32m[0315 21:04:36 @network.py:203][0m step: 132600, current TD loss: 0.00190660054795
[32m[0315 21:04:37 @network.py:203][0m step: 132700, current TD loss: 0.00101825827733
[32m[0315 21:04:38 @network.py:203][0m step: 132800, current TD loss: 0.00193346780725
[32m[0315 21:04:40 @network.py:203][0m step: 132900, current TD loss: 0.00335529656149
[32m[0315 21:04:41 @dqn_agent.py:203][0m episode: 8132, total game step: 183000, epsilon: 0.86833099
[32m[0315 21:04:41 @network.py:203][0m step: 133000, current TD loss: 0.0181999802589
[32m[0315 21:04:42 @network.py:203][0m step: 133100, current TD loss: 1.26416907733e-05
[32m[0315 21:04:43 @network.py:203][0m step: 133200, current TD loss: 0.00203648814932
[32m[0315 21:04:44 @network.py:203][0m step: 133300, current TD loss: 0.0150481406599
[32m[0315 21:04:45 @network.py:203][0m step: 133400, current TD loss: 0.000931695918553
[32m[0315 21:04:46 @network.py:203][0m step: 133500, current TD loss: 0.00107431772631
[32m[0315 21:04:47 @network.py:203][0m step: 133600, current TD loss: 0.000106242106995
[32m[0315 21:04:48 @network.py:203][0m step: 133700, current TD loss: 0.0179749578238
[32m[0315 21:04:50 @network.py:203][0m step: 133800, current TD loss: 0.00154284341261
[32m[0315 21:04:51 @network.py:203][0m step: 133900, current TD loss: 0.000989758176729
[32m[0315 21:04:52 @dqn_agent.py:203][0m episode: 8167, total game step: 184000, epsilon: 0.86734099
[32m[0315 21:04:52 @network.py:203][0m step: 134000, current TD loss: 0.0048399977386
[32m[0315 21:04:53 @network.py:203][0m step: 134100, current TD loss: 5.96898680669e-05
[32m[0315 21:04:54 @network.py:203][0m step: 134200, current TD loss: 0.00105089729186
[32m[0315 21:04:55 @network.py:203][0m step: 134300, current TD loss: 0.00258360151201
[32m[0315 21:04:56 @network.py:203][0m step: 134400, current TD loss: 0.0206542499363
[32m[0315 21:04:57 @network.py:203][0m step: 134500, current TD loss: 0.00340520567261
[32m[0315 21:04:59 @network.py:203][0m step: 134600, current TD loss: 0.00217833835632
[32m[0315 21:05:00 @network.py:203][0m step: 134700, current TD loss: 0.0010042876238
[32m[0315 21:05:01 @network.py:203][0m step: 134800, current TD loss: 0.00192237761803
[32m[0315 21:05:01 @summary_handler.py:101][0m At episode: 184859, Reward: 0.16 (over 100 episodes)
[32m[0315 21:05:01 @summary_handler.py:102][0m Length: 24.92
[32m[0315 21:05:02 @network.py:203][0m step: 134900, current TD loss: 0.0169981326908
[32m[0315 21:05:03 @dqn_agent.py:203][0m episode: 8207, total game step: 185000, epsilon: 0.86635099
[32m[0315 21:05:03 @network.py:203][0m step: 135000, current TD loss: 0.00106822932139
[32m[0315 21:05:03 @dqn_agent.py:216][0m At time step 135000, the target_network is updated
[32m[0315 21:05:04 @network.py:203][0m step: 135100, current TD loss: 0.00314042018726
[32m[0315 21:05:05 @network.py:203][0m step: 135200, current TD loss: 8.41551373014e-05
[32m[0315 21:05:06 @network.py:203][0m step: 135300, current TD loss: 0.00303893419914
[32m[0315 21:05:08 @network.py:203][0m step: 135400, current TD loss: 8.52911325637e-05
[32m[0315 21:05:09 @network.py:203][0m step: 135500, current TD loss: 0.00323300226592
[32m[0315 21:05:10 @network.py:203][0m step: 135600, current TD loss: 0.0170785449445
[32m[0315 21:05:11 @network.py:203][0m step: 135700, current TD loss: 0.0198797099292
[32m[0315 21:05:12 @network.py:203][0m step: 135800, current TD loss: 0.00320585072041
[32m[0315 21:05:13 @network.py:203][0m step: 135900, current TD loss: 0.0021065948531
[32m[0315 21:05:14 @dqn_agent.py:203][0m episode: 8257, total game step: 186000, epsilon: 0.86536099
[32m[0315 21:05:14 @network.py:203][0m step: 136000, current TD loss: 0.00423192186281
[32m[0315 21:05:16 @network.py:203][0m step: 136100, current TD loss: 0.00213468004949
[32m[0315 21:05:17 @network.py:203][0m step: 136200, current TD loss: 0.00409858999774
[32m[0315 21:05:18 @network.py:203][0m step: 136300, current TD loss: 0.00200482271612
[32m[0315 21:05:19 @network.py:203][0m step: 136400, current TD loss: 0.0189315434545
[32m[0315 21:05:20 @network.py:203][0m step: 136500, current TD loss: 3.99965065299e-05
[32m[0315 21:05:21 @network.py:203][0m step: 136600, current TD loss: 0.0172133930027
[32m[0315 21:05:22 @network.py:203][0m step: 136700, current TD loss: 0.0176848899573
[32m[0315 21:05:23 @network.py:203][0m step: 136800, current TD loss: 0.00206165527925
[32m[0315 21:05:24 @network.py:203][0m step: 136900, current TD loss: 0.000104015605757
[32m[0315 21:05:25 @summary_handler.py:101][0m At episode: 186956, Reward: 0.13 (over 100 episodes)
[32m[0315 21:05:25 @summary_handler.py:102][0m Length: 20.97
[32m[0315 21:05:26 @dqn_agent.py:203][0m episode: 8302, total game step: 187000, epsilon: 0.86437099
[32m[0315 21:05:26 @network.py:203][0m step: 137000, current TD loss: 0.00218495447189
[32m[0315 21:05:27 @network.py:203][0m step: 137100, current TD loss: 0.0179504677653
[32m[0315 21:05:28 @network.py:203][0m step: 137200, current TD loss: 0.00215799943544
[32m[0315 21:05:29 @network.py:203][0m step: 137300, current TD loss: 7.60171242291e-05
[32m[0315 21:05:30 @network.py:203][0m step: 137400, current TD loss: 0.00116371526383
[32m[0315 21:05:31 @network.py:203][0m step: 137500, current TD loss: 0.0172361340374
[32m[0315 21:05:31 @dqn_agent.py:216][0m At time step 137500, the target_network is updated
[32m[0315 21:05:32 @network.py:203][0m step: 137600, current TD loss: 0.00342156225815
[32m[0315 21:05:34 @network.py:203][0m step: 137700, current TD loss: 0.0182514376938
[32m[0315 21:05:35 @network.py:203][0m step: 137800, current TD loss: 0.0165825579315
[32m[0315 21:05:36 @network.py:203][0m step: 137900, current TD loss: 0.00101679132786
[32m[0315 21:05:37 @dqn_agent.py:203][0m episode: 8352, total game step: 188000, epsilon: 0.86338099
[32m[0315 21:05:37 @network.py:203][0m step: 138000, current TD loss: 7.33368069632e-05
[32m[0315 21:05:38 @network.py:203][0m step: 138100, current TD loss: 0.00102298520505
[32m[0315 21:05:39 @network.py:203][0m step: 138200, current TD loss: 0.00347805861384
[32m[0315 21:05:40 @network.py:203][0m step: 138300, current TD loss: 0.00467036059126
[32m[0315 21:05:41 @network.py:203][0m step: 138400, current TD loss: 0.00194790703245
[32m[0315 21:05:43 @network.py:203][0m step: 138500, current TD loss: 5.09322926519e-05
[32m[0315 21:05:44 @network.py:203][0m step: 138600, current TD loss: 0.00306639401242
[32m[0315 21:05:45 @network.py:203][0m step: 138700, current TD loss: 0.00199594162405
[32m[0315 21:05:46 @network.py:203][0m step: 138800, current TD loss: 0.0188330858946
[32m[0315 21:05:47 @network.py:203][0m step: 138900, current TD loss: 6.606617535e-05
[32m[0315 21:05:48 @dqn_agent.py:203][0m episode: 8392, total game step: 189000, epsilon: 0.86239099
[32m[0315 21:05:48 @network.py:203][0m step: 139000, current TD loss: 0.00263293879107
[32m[0315 21:05:49 @network.py:203][0m step: 139100, current TD loss: 0.00304793054238
[32m[0315 21:05:51 @network.py:203][0m step: 139200, current TD loss: 0.0169489346445
[32m[0315 21:05:51 @summary_handler.py:101][0m At episode: 189254, Reward: 0.12 (over 100 episodes)
[32m[0315 21:05:51 @summary_handler.py:102][0m Length: 22.98
[32m[0315 21:05:52 @network.py:203][0m step: 139300, current TD loss: 0.00101670180447
[32m[0315 21:05:53 @network.py:203][0m step: 139400, current TD loss: 0.00131589861121
[32m[0315 21:05:54 @network.py:203][0m step: 139500, current TD loss: 0.00213640835136
[32m[0315 21:05:55 @network.py:203][0m step: 139600, current TD loss: 5.93134609517e-05
[32m[0315 21:05:56 @network.py:203][0m step: 139700, current TD loss: 4.74941589346e-05
[32m[0315 21:05:57 @network.py:203][0m step: 139800, current TD loss: 0.00268626306206
[32m[0315 21:05:59 @network.py:203][0m step: 139900, current TD loss: 0.0217870157212
[32m[0315 21:06:00 @dqn_agent.py:203][0m episode: 8437, total game step: 190000, epsilon: 0.86140099
[32m[0315 21:06:00 @network.py:203][0m step: 140000, current TD loss: 0.00226937420666
[32m[0315 21:06:00 @dqn_agent.py:216][0m At time step 140000, the target_network is updated
[32m[0315 21:06:01 @network.py:203][0m step: 140100, current TD loss: 0.00196289760061
[32m[0315 21:06:02 @network.py:203][0m step: 140200, current TD loss: 0.00183177832514
[32m[0315 21:06:03 @network.py:203][0m step: 140300, current TD loss: 0.00173755874857
[32m[0315 21:06:04 @network.py:203][0m step: 140400, current TD loss: 0.0171123407781
[32m[0315 21:06:05 @network.py:203][0m step: 140500, current TD loss: 0.00102762505412
[32m[0315 21:06:07 @network.py:203][0m step: 140600, current TD loss: 0.00254484452307
[32m[0315 21:06:08 @network.py:203][0m step: 140700, current TD loss: 4.42944110546e-05
[32m[0315 21:06:09 @network.py:203][0m step: 140800, current TD loss: 0.000121951379697
[32m[0315 21:06:10 @network.py:203][0m step: 140900, current TD loss: 0.00184058351442
[32m[0315 21:06:11 @dqn_agent.py:203][0m episode: 8482, total game step: 191000, epsilon: 0.86041099
[32m[0315 21:06:11 @network.py:203][0m step: 141000, current TD loss: 0.00196763384156
[32m[0315 21:06:12 @network.py:203][0m step: 141100, current TD loss: 0.00253986869939
[32m[0315 21:06:13 @network.py:203][0m step: 141200, current TD loss: 0.00153060117736
[32m[0315 21:06:15 @summary_handler.py:101][0m At episode: 191298, Reward: 0.1 (over 100 episodes)
[32m[0315 21:06:15 @summary_handler.py:102][0m Length: 20.44
[32m[0315 21:06:15 @network.py:203][0m step: 141300, current TD loss: 0.00104400387499
[32m[0315 21:06:16 @network.py:203][0m step: 141400, current TD loss: 0.00103368645068
[32m[0315 21:06:17 @network.py:203][0m step: 141500, current TD loss: 0.00175138493069
[32m[0315 21:06:18 @network.py:203][0m step: 141600, current TD loss: 0.0177614036947
[32m[0315 21:06:19 @network.py:203][0m step: 141700, current TD loss: 0.000955366587732
[32m[0315 21:06:20 @network.py:203][0m step: 141800, current TD loss: 0.00242743548006
[32m[0315 21:06:21 @network.py:203][0m step: 141900, current TD loss: 0.0158363580704
[32m[0315 21:06:22 @dqn_agent.py:203][0m episode: 8529, total game step: 192000, epsilon: 0.85942099
[32m[0315 21:06:22 @network.py:203][0m step: 142000, current TD loss: 0.00385567988269
[32m[0315 21:06:24 @network.py:203][0m step: 142100, current TD loss: 0.00111286074389
[32m[0315 21:06:25 @network.py:203][0m step: 142200, current TD loss: 0.00189991854131
[32m[0315 21:06:26 @network.py:203][0m step: 142300, current TD loss: 0.00101036496926
[32m[0315 21:06:27 @network.py:203][0m step: 142400, current TD loss: 0.00189208332449
[32m[0315 21:06:28 @network.py:203][0m step: 142500, current TD loss: 0.00289594545029
[32m[0315 21:06:28 @dqn_agent.py:216][0m At time step 142500, the target_network is updated
[32m[0315 21:06:29 @network.py:203][0m step: 142600, current TD loss: 0.0182465426624
[32m[0315 21:06:30 @network.py:203][0m step: 142700, current TD loss: 0.00252214656211
[32m[0315 21:06:32 @network.py:203][0m step: 142800, current TD loss: 0.00159331597388
[32m[0315 21:06:33 @network.py:203][0m step: 142900, current TD loss: 0.00126627169084
[32m[0315 21:06:34 @dqn_agent.py:203][0m episode: 8578, total game step: 193000, epsilon: 0.85843099
[32m[0315 21:06:34 @network.py:203][0m step: 143000, current TD loss: 0.000893837481271
[32m[0315 21:06:35 @network.py:203][0m step: 143100, current TD loss: 0.00169932865538
[32m[0315 21:06:36 @network.py:203][0m step: 143200, current TD loss: 0.000921991362702
[32m[0315 21:06:37 @network.py:203][0m step: 143300, current TD loss: 0.0178250763565
[32m[0315 21:06:38 @summary_handler.py:101][0m At episode: 193372, Reward: 0.08 (over 100 episodes)
[32m[0315 21:06:38 @summary_handler.py:102][0m Length: 20.74
[32m[0315 21:06:38 @network.py:203][0m step: 143400, current TD loss: 0.00166575191543
[32m[0315 21:06:40 @network.py:203][0m step: 143500, current TD loss: 0.0166752263904
[32m[0315 21:06:41 @network.py:203][0m step: 143600, current TD loss: 0.00258396472782
[32m[0315 21:06:42 @network.py:203][0m step: 143700, current TD loss: 0.00243777944706
[32m[0315 21:06:43 @network.py:203][0m step: 143800, current TD loss: 0.00177922914736
[32m[0315 21:06:44 @network.py:203][0m step: 143900, current TD loss: 0.0185081921518
[32m[0315 21:06:45 @dqn_agent.py:203][0m episode: 8621, total game step: 194000, epsilon: 0.85744099
[32m[0315 21:06:45 @network.py:203][0m step: 144000, current TD loss: 0.000860549916979
[32m[0315 21:06:46 @network.py:203][0m step: 144100, current TD loss: 0.0022322491277
[32m[0315 21:06:47 @network.py:203][0m step: 144200, current TD loss: 0.000101314311905
[32m[0315 21:06:49 @network.py:203][0m step: 144300, current TD loss: 0.00254924339242
[32m[0315 21:06:50 @network.py:203][0m step: 144400, current TD loss: 0.00170002132654
[32m[0315 21:06:51 @network.py:203][0m step: 144500, current TD loss: 0.00238779745996
[32m[0315 21:06:52 @network.py:203][0m step: 144600, current TD loss: 0.000938721059356
[32m[0315 21:06:53 @network.py:203][0m step: 144700, current TD loss: 0.000888490874786
[32m[0315 21:06:54 @network.py:203][0m step: 144800, current TD loss: 0.018437769264
[32m[0315 21:06:56 @network.py:203][0m step: 144900, current TD loss: 8.53376259329e-05
[32m[0315 21:06:57 @dqn_agent.py:203][0m episode: 8671, total game step: 195000, epsilon: 0.85645099
[32m[0315 21:06:57 @network.py:203][0m step: 145000, current TD loss: 7.87846656749e-05
[32m[0315 21:06:57 @dqn_agent.py:216][0m At time step 145000, the target_network is updated
[32m[0315 21:06:58 @network.py:203][0m step: 145100, current TD loss: 0.0170875284821
[32m[0315 21:06:59 @network.py:203][0m step: 145200, current TD loss: 0.000893953605555
[32m[0315 21:07:00 @network.py:203][0m step: 145300, current TD loss: 0.0339065417647
[32m[0315 21:07:01 @network.py:203][0m step: 145400, current TD loss: 0.00126213114709
[32m[0315 21:07:02 @network.py:203][0m step: 145500, current TD loss: 0.000913858530112
[32m[0315 21:07:04 @network.py:203][0m step: 145600, current TD loss: 0.00168936362024
[32m[0315 21:07:05 @summary_handler.py:101][0m At episode: 195684, Reward: 0.12 (over 100 episodes)
[32m[0315 21:07:05 @summary_handler.py:102][0m Length: 23.12
[32m[0315 21:07:05 @network.py:203][0m step: 145700, current TD loss: 4.00780918426e-05
[32m[0315 21:07:06 @network.py:203][0m step: 145800, current TD loss: 0.000789744663052
[32m[0315 21:07:07 @network.py:203][0m step: 145900, current TD loss: 0.00148979574442
[32m[0315 21:07:08 @dqn_agent.py:203][0m episode: 8717, total game step: 196000, epsilon: 0.85546099
[32m[0315 21:07:08 @network.py:203][0m step: 146000, current TD loss: 0.000763230666053
[32m[0315 21:07:09 @network.py:203][0m step: 146100, current TD loss: 0.0184452813119
[32m[0315 21:07:10 @network.py:203][0m step: 146200, current TD loss: 0.00278104189783
[32m[0315 21:07:12 @network.py:203][0m step: 146300, current TD loss: 0.00155775190797
[32m[0315 21:07:13 @network.py:203][0m step: 146400, current TD loss: 0.0186004396528
[32m[0315 21:07:14 @network.py:203][0m step: 146500, current TD loss: 0.00241737323813
[32m[0315 21:07:15 @network.py:203][0m step: 146600, current TD loss: 0.0020315607544
[32m[0315 21:07:16 @network.py:203][0m step: 146700, current TD loss: 0.000840188236907
[32m[0315 21:07:17 @network.py:203][0m step: 146800, current TD loss: 0.0179910454899
[32m[0315 21:07:18 @network.py:203][0m step: 146900, current TD loss: 0.000843023648486
[32m[0315 21:07:20 @dqn_agent.py:203][0m episode: 8761, total game step: 197000, epsilon: 0.85447099
[32m[0315 21:07:20 @network.py:203][0m step: 147000, current TD loss: 0.00353882345371
[32m[0315 21:07:21 @network.py:203][0m step: 147100, current TD loss: 0.00167436001357
[32m[0315 21:07:22 @network.py:203][0m step: 147200, current TD loss: 0.0179971661419
[32m[0315 21:07:23 @network.py:203][0m step: 147300, current TD loss: 0.0175248328596
[32m[0315 21:07:24 @network.py:203][0m step: 147400, current TD loss: 4.01100442105e-05
[32m[0315 21:07:25 @network.py:203][0m step: 147500, current TD loss: 0.00452870689332
[32m[0315 21:07:25 @dqn_agent.py:216][0m At time step 147500, the target_network is updated
[32m[0315 21:07:26 @network.py:203][0m step: 147600, current TD loss: 3.67818611267e-05
[32m[0315 21:07:27 @network.py:203][0m step: 147700, current TD loss: 3.21669322147e-05
[32m[0315 21:07:29 @network.py:203][0m step: 147800, current TD loss: 0.0158864445984
[32m[0315 21:07:29 @summary_handler.py:101][0m At episode: 197800, Reward: 0.07 (over 100 episodes)
[32m[0315 21:07:29 @summary_handler.py:102][0m Length: 21.16
[32m[0315 21:07:30 @network.py:203][0m step: 147900, current TD loss: 0.0177474860102
[32m[0315 21:07:31 @dqn_agent.py:203][0m episode: 8805, total game step: 198000, epsilon: 0.85348099
[32m[0315 21:07:31 @network.py:203][0m step: 148000, current TD loss: 0.00171410385519
[32m[0315 21:07:32 @network.py:203][0m step: 148100, current TD loss: 0.0175154693425
[32m[0315 21:07:33 @network.py:203][0m step: 148200, current TD loss: 0.000921063998248
[32m[0315 21:07:34 @network.py:203][0m step: 148300, current TD loss: 0.00131813122425
[32m[0315 21:07:35 @network.py:203][0m step: 148400, current TD loss: 0.0172394253314
[32m[0315 21:07:36 @network.py:203][0m step: 148500, current TD loss: 0.000870213261805
[32m[0315 21:07:37 @network.py:203][0m step: 148600, current TD loss: 0.0202881861478
[32m[0315 21:07:39 @network.py:203][0m step: 148700, current TD loss: 0.00239193346351
[32m[0315 21:07:40 @network.py:203][0m step: 148800, current TD loss: 0.00354894157499
[32m[0315 21:07:41 @network.py:203][0m step: 148900, current TD loss: 0.000878099468537
[32m[0315 21:07:42 @dqn_agent.py:203][0m episode: 8845, total game step: 199000, epsilon: 0.85249099
[32m[0315 21:07:42 @network.py:203][0m step: 149000, current TD loss: 0.0175037328154
[32m[0315 21:07:43 @network.py:203][0m step: 149100, current TD loss: 0.00271111447364
[32m[0315 21:07:44 @network.py:203][0m step: 149200, current TD loss: 0.00168345216662
[32m[0315 21:07:45 @network.py:203][0m step: 149300, current TD loss: 0.0174389574677
[32m[0315 21:07:47 @network.py:203][0m step: 149400, current TD loss: 0.0171550940722
[32m[0315 21:07:48 @network.py:203][0m step: 149500, current TD loss: 0.0180154908448
[32m[0315 21:07:49 @network.py:203][0m step: 149600, current TD loss: 0.016678981483
[32m[0315 21:07:50 @network.py:203][0m step: 149700, current TD loss: 0.00369097595103
[32m[0315 21:07:51 @network.py:203][0m step: 149800, current TD loss: 0.00313961436041
[32m[0315 21:07:52 @network.py:203][0m step: 149900, current TD loss: 4.84505981149e-05
[32m[0315 21:07:53 @dqn_agent.py:203][0m episode: 8886, total game step: 200000, epsilon: 0.85150099
[32m[0315 21:07:53 @network.py:203][0m step: 150000, current TD loss: 0.000818134751171
[32m[0315 21:07:53 @dqn_agent.py:216][0m At time step 150000, the target_network is updated
[32m[0315 21:07:54 @network.py:203][0m step: 150100, current TD loss: 0.00312719726935
[32m[0315 21:07:56 @network.py:203][0m step: 150200, current TD loss: 0.00351704610512
[32m[0315 21:07:56 @summary_handler.py:101][0m At episode: 200263, Reward: 0.16 (over 100 episodes)
[32m[0315 21:07:56 @summary_handler.py:102][0m Length: 24.63
[32m[0315 21:07:57 @network.py:203][0m step: 150300, current TD loss: 0.00177823007107
[32m[0315 21:07:58 @network.py:203][0m step: 150400, current TD loss: 0.0208222679794
[32m[0315 21:07:59 @network.py:203][0m step: 150500, current TD loss: 0.00201867101714
[32m[0315 21:08:00 @network.py:203][0m step: 150600, current TD loss: 0.00328057724983
[32m[0315 21:08:01 @network.py:203][0m step: 150700, current TD loss: 0.00198687240481
[32m[0315 21:08:02 @network.py:203][0m step: 150800, current TD loss: 0.00155644095503
[32m[0315 21:08:03 @network.py:203][0m step: 150900, current TD loss: 4.07162842748e-05
[32m[0315 21:08:05 @dqn_agent.py:203][0m episode: 8931, total game step: 201000, epsilon: 0.85051099
[32m[0315 21:08:05 @network.py:203][0m step: 151000, current TD loss: 0.0165278427303
[32m[0315 21:08:06 @network.py:203][0m step: 151100, current TD loss: 0.0350693576038
[32m[0315 21:08:07 @network.py:203][0m step: 151200, current TD loss: 5.0697948609e-05
[32m[0315 21:08:08 @network.py:203][0m step: 151300, current TD loss: 0.0032132177148
[32m[0315 21:08:09 @network.py:203][0m step: 151400, current TD loss: 0.0157835036516
[32m[0315 21:08:10 @network.py:203][0m step: 151500, current TD loss: 0.000764943077229
[32m[0315 21:08:11 @network.py:203][0m step: 151600, current TD loss: 0.0196271594614
[32m[0315 21:08:12 @network.py:203][0m step: 151700, current TD loss: 0.00212638173252
[32m[0315 21:08:14 @network.py:203][0m step: 151800, current TD loss: 0.000811678823084
[32m[0315 21:08:15 @network.py:203][0m step: 151900, current TD loss: 0.00222232332453
[32m[0315 21:08:16 @dqn_agent.py:203][0m episode: 8972, total game step: 202000, epsilon: 0.84952099
[32m[0315 21:08:16 @network.py:203][0m step: 152000, current TD loss: 0.0177325140685
[32m[0315 21:08:17 @network.py:203][0m step: 152100, current TD loss: 0.017411114648
[32m[0315 21:08:18 @network.py:203][0m step: 152200, current TD loss: 0.00160446483642
[32m[0315 21:08:19 @network.py:203][0m step: 152300, current TD loss: 0.00184494338464
[32m[0315 21:08:20 @network.py:203][0m step: 152400, current TD loss: 0.000790540012531
[32m[0315 21:08:21 @network.py:203][0m step: 152500, current TD loss: 0.00183355493937
[32m[0315 21:08:21 @dqn_agent.py:216][0m At time step 152500, the target_network is updated
[32m[0315 21:08:22 @network.py:203][0m step: 152600, current TD loss: 4.28907806054e-05
[32m[0315 21:08:23 @summary_handler.py:101][0m At episode: 202632, Reward: 0.18 (over 100 episodes)
[32m[0315 21:08:23 @summary_handler.py:102][0m Length: 23.69
[32m[0315 21:08:23 @network.py:203][0m step: 152700, current TD loss: 0.0180210787803
[32m[0315 21:08:25 @network.py:203][0m step: 152800, current TD loss: 0.00259791547433
[32m[0315 21:08:26 @network.py:203][0m step: 152900, current TD loss: 0.016553927213
[32m[0315 21:08:27 @dqn_agent.py:203][0m episode: 9013, total game step: 203000, epsilon: 0.84853099
[32m[0315 21:08:27 @network.py:203][0m step: 153000, current TD loss: 0.0334385186434
[32m[0315 21:08:28 @network.py:203][0m step: 153100, current TD loss: 4.0276805521e-05
[32m[0315 21:08:29 @network.py:203][0m step: 153200, current TD loss: 0.000780329923145
[32m[0315 21:08:30 @network.py:203][0m step: 153300, current TD loss: 0.000703330268152
[32m[0315 21:08:32 @network.py:203][0m step: 153400, current TD loss: 0.00149491999764
[32m[0315 21:08:33 @network.py:203][0m step: 153500, current TD loss: 0.00247834646143
[32m[0315 21:08:34 @network.py:203][0m step: 153600, current TD loss: 0.00158286630176
[32m[0315 21:08:35 @network.py:203][0m step: 153700, current TD loss: 0.00153974420391
[32m[0315 21:08:37 @network.py:203][0m step: 153800, current TD loss: 0.0173478517681
[32m[0315 21:08:38 @network.py:203][0m step: 153900, current TD loss: 0.000834768172354
[32m[0315 21:08:39 @dqn_agent.py:203][0m episode: 9053, total game step: 204000, epsilon: 0.84754099
[32m[0315 21:08:39 @network.py:203][0m step: 154000, current TD loss: 0.000737973372452
[32m[0315 21:08:41 @network.py:203][0m step: 154100, current TD loss: 0.00157213560306
[32m[0315 21:08:42 @network.py:203][0m step: 154200, current TD loss: 0.00386656168848
[32m[0315 21:08:43 @network.py:203][0m step: 154300, current TD loss: 0.00426056934521
[32m[0315 21:08:45 @network.py:203][0m step: 154400, current TD loss: 0.00161383720115
[32m[0315 21:08:46 @network.py:203][0m step: 154500, current TD loss: 0.000136352537083
[32m[0315 21:08:48 @network.py:203][0m step: 154600, current TD loss: 0.00137627939694
[32m[0315 21:08:49 @network.py:203][0m step: 154700, current TD loss: 0.00239625875838
[32m[0315 21:08:51 @network.py:203][0m step: 154800, current TD loss: 0.00079179398017
[32m[0315 21:08:52 @network.py:203][0m step: 154900, current TD loss: 0.0174215752631
[32m[0315 21:08:53 @dqn_agent.py:203][0m episode: 9098, total game step: 205000, epsilon: 0.84655099
[32m[0315 21:08:53 @network.py:203][0m step: 155000, current TD loss: 0.0163165535778
[32m[0315 21:08:53 @dqn_agent.py:216][0m At time step 155000, the target_network is updated
[32m[0315 21:08:54 @summary_handler.py:101][0m At episode: 205030, Reward: 0.16 (over 100 episodes)
[32m[0315 21:08:54 @summary_handler.py:102][0m Length: 23.98
[32m[0315 21:08:55 @network.py:203][0m step: 155100, current TD loss: 0.0166577268392
[32m[0315 21:08:56 @network.py:203][0m step: 155200, current TD loss: 0.000936166557949
[32m[0315 21:08:57 @network.py:203][0m step: 155300, current TD loss: 0.00415109517053
[32m[0315 21:08:59 @network.py:203][0m step: 155400, current TD loss: 0.000802318565547
[32m[0315 21:09:00 @network.py:203][0m step: 155500, current TD loss: 0.00156105565839
[32m[0315 21:09:01 @network.py:203][0m step: 155600, current TD loss: 8.75242985785e-05
[32m[0315 21:09:02 @network.py:203][0m step: 155700, current TD loss: 2.64425616479e-05
[32m[0315 21:09:04 @network.py:203][0m step: 155800, current TD loss: 0.0155686046928
[32m[0315 21:09:05 @network.py:203][0m step: 155900, current TD loss: 0.00275240908377
[32m[0315 21:09:06 @dqn_agent.py:203][0m episode: 9143, total game step: 206000, epsilon: 0.84556099
[32m[0315 21:09:06 @network.py:203][0m step: 156000, current TD loss: 0.0191184673458
[32m[0315 21:09:08 @network.py:203][0m step: 156100, current TD loss: 0.00179718225263
[32m[0315 21:09:09 @network.py:203][0m step: 156200, current TD loss: 0.00170959893148
[32m[0315 21:09:10 @network.py:203][0m step: 156300, current TD loss: 0.0179183389992
[32m[0315 21:09:12 @network.py:203][0m step: 156400, current TD loss: 0.00154849444516
[32m[0315 21:09:13 @network.py:203][0m step: 156500, current TD loss: 0.000133322188049
[32m[0315 21:09:14 @network.py:203][0m step: 156600, current TD loss: 0.00328786671162
[32m[0315 21:09:16 @network.py:203][0m step: 156700, current TD loss: 0.00165634125005
[32m[0315 21:09:17 @network.py:203][0m step: 156800, current TD loss: 0.018668923527
[32m[0315 21:09:18 @network.py:203][0m step: 156900, current TD loss: 0.00285850604996
[32m[0315 21:09:20 @dqn_agent.py:203][0m episode: 9184, total game step: 207000, epsilon: 0.84457099
[32m[0315 21:09:20 @network.py:203][0m step: 157000, current TD loss: 0.00084397289902
[32m[0315 21:09:21 @network.py:203][0m step: 157100, current TD loss: 0.00373174110427
[32m[0315 21:09:22 @network.py:203][0m step: 157200, current TD loss: 0.0480076819658
[32m[0315 21:09:24 @summary_handler.py:101][0m At episode: 207296, Reward: 0.14 (over 100 episodes)
[32m[0315 21:09:24 @summary_handler.py:102][0m Length: 22.66
[32m[0315 21:09:24 @network.py:203][0m step: 157300, current TD loss: 0.00165798480157
[32m[0315 21:09:25 @network.py:203][0m step: 157400, current TD loss: 0.00160887406673
[32m[0315 21:09:26 @network.py:203][0m step: 157500, current TD loss: 0.00157814007252
[32m[0315 21:09:26 @dqn_agent.py:216][0m At time step 157500, the target_network is updated
[32m[0315 21:09:28 @network.py:203][0m step: 157600, current TD loss: 0.00201961421408
[32m[0315 21:09:29 @network.py:203][0m step: 157700, current TD loss: 1.91154394997e-05
[32m[0315 21:09:30 @network.py:203][0m step: 157800, current TD loss: 0.000765507749747
[32m[0315 21:09:32 @network.py:203][0m step: 157900, current TD loss: 0.00225045438856
[32m[0315 21:09:33 @dqn_agent.py:203][0m episode: 9229, total game step: 208000, epsilon: 0.84358099
[32m[0315 21:09:33 @network.py:203][0m step: 158000, current TD loss: 0.00157067435794
[32m[0315 21:09:34 @network.py:203][0m step: 158100, current TD loss: 0.0165359787643
[32m[0315 21:09:36 @network.py:203][0m step: 158200, current TD loss: 2.97106253129e-05
[32m[0315 21:09:37 @network.py:203][0m step: 158300, current TD loss: 0.000817316933535
[32m[0315 21:09:38 @network.py:203][0m step: 158400, current TD loss: 6.85380437062e-05
[32m[0315 21:09:40 @network.py:203][0m step: 158500, current TD loss: 0.0164716187865
[32m[0315 21:09:41 @network.py:203][0m step: 158600, current TD loss: 0.000738527509384
[32m[0315 21:09:42 @network.py:203][0m step: 158700, current TD loss: 0.00293566193432
[32m[0315 21:09:44 @network.py:203][0m step: 158800, current TD loss: 0.00187831895892
[32m[0315 21:09:45 @network.py:203][0m step: 158900, current TD loss: 0.00402168883011
[32m[0315 21:09:46 @dqn_agent.py:203][0m episode: 9271, total game step: 209000, epsilon: 0.84259099
[32m[0315 21:09:46 @network.py:203][0m step: 159000, current TD loss: 0.00196226406842
[32m[0315 21:09:48 @network.py:203][0m step: 159100, current TD loss: 0.0181533806026
[32m[0315 21:09:49 @network.py:203][0m step: 159200, current TD loss: 0.00245357025415
[32m[0315 21:09:50 @network.py:203][0m step: 159300, current TD loss: 0.034382969141
[32m[0315 21:09:52 @network.py:203][0m step: 159400, current TD loss: 0.00162386638112
[32m[0315 21:09:53 @network.py:203][0m step: 159500, current TD loss: 0.000731107546017
[32m[0315 21:09:54 @network.py:203][0m step: 159600, current TD loss: 0.000720867770724
[32m[0315 21:09:56 @network.py:203][0m step: 159700, current TD loss: 0.00143208052032
[32m[0315 21:09:56 @summary_handler.py:101][0m At episode: 209720, Reward: 0.14 (over 100 episodes)
[32m[0315 21:09:56 @summary_handler.py:102][0m Length: 24.24
[32m[0315 21:09:57 @network.py:203][0m step: 159800, current TD loss: 0.00260708481073
[32m[0315 21:09:58 @network.py:203][0m step: 159900, current TD loss: 4.30554900959e-05
[32m[0315 21:10:00 @dqn_agent.py:203][0m episode: 9311, total game step: 210000, epsilon: 0.84160099
[32m[0315 21:10:00 @network.py:203][0m step: 160000, current TD loss: 0.0154089359567
[32m[0315 21:10:00 @dqn_agent.py:216][0m At time step 160000, the target_network is updated
[32m[0315 21:10:01 @network.py:203][0m step: 160100, current TD loss: 0.0015413579531
[32m[0315 21:10:02 @network.py:203][0m step: 160200, current TD loss: 0.00083797168918
[32m[0315 21:10:04 @network.py:203][0m step: 160300, current TD loss: 7.17997609172e-05
[32m[0315 21:10:05 @network.py:203][0m step: 160400, current TD loss: 0.000844214053359
[32m[0315 21:10:06 @network.py:203][0m step: 160500, current TD loss: 0.00286435615271
[32m[0315 21:10:08 @network.py:203][0m step: 160600, current TD loss: 0.000859963940457
[32m[0315 21:10:09 @network.py:203][0m step: 160700, current TD loss: 0.00230419100262
[32m[0315 21:10:10 @network.py:203][0m step: 160800, current TD loss: 0.002199689392
[32m[0315 21:10:11 @network.py:203][0m step: 160900, current TD loss: 9.44009516388e-05
[32m[0315 21:10:13 @dqn_agent.py:203][0m episode: 9343, total game step: 211000, epsilon: 0.84061099
[32m[0315 21:10:13 @network.py:203][0m step: 161000, current TD loss: 0.0319388359785
[32m[0315 21:10:14 @network.py:203][0m step: 161100, current TD loss: 0.00189012114424
[32m[0315 21:10:15 @network.py:203][0m step: 161200, current TD loss: 0.0184484440833
[32m[0315 21:10:17 @network.py:203][0m step: 161300, current TD loss: 0.0176634695381
[32m[0315 21:10:18 @network.py:203][0m step: 161400, current TD loss: 0.000791513477452
[32m[0315 21:10:19 @network.py:203][0m step: 161500, current TD loss: 0.00482662022114
[32m[0315 21:10:21 @network.py:203][0m step: 161600, current TD loss: 0.00230904156342
[32m[0315 21:10:22 @network.py:203][0m step: 161700, current TD loss: 0.000146266451338
[32m[0315 21:10:23 @network.py:203][0m step: 161800, current TD loss: 0.00171832845081
[32m[0315 21:10:25 @network.py:203][0m step: 161900, current TD loss: 0.00157871854026
[32m[0315 21:10:26 @dqn_agent.py:203][0m episode: 9386, total game step: 212000, epsilon: 0.83962099
[32m[0315 21:10:26 @network.py:203][0m step: 162000, current TD loss: 0.00332269654609
[32m[0315 21:10:27 @network.py:203][0m step: 162100, current TD loss: 0.000758938025683
[32m[0315 21:10:29 @network.py:203][0m step: 162200, current TD loss: 0.00229360931553
[32m[0315 21:10:30 @summary_handler.py:101][0m At episode: 212278, Reward: 0.18 (over 100 episodes)
[32m[0315 21:10:30 @summary_handler.py:102][0m Length: 25.58
[32m[0315 21:10:30 @network.py:203][0m step: 162300, current TD loss: 0.00235040625557
[32m[0315 21:10:31 @network.py:203][0m step: 162400, current TD loss: 0.00172740698326
[32m[0315 21:10:33 @network.py:203][0m step: 162500, current TD loss: 0.00226304121315
[32m[0315 21:10:33 @dqn_agent.py:216][0m At time step 162500, the target_network is updated
[32m[0315 21:10:34 @network.py:203][0m step: 162600, current TD loss: 0.000826322648209
[32m[0315 21:10:35 @network.py:203][0m step: 162700, current TD loss: 0.0172957144678
[32m[0315 21:10:37 @network.py:203][0m step: 162800, current TD loss: 0.00161730614491
[32m[0315 21:10:38 @network.py:203][0m step: 162900, current TD loss: 0.0016274524387
[32m[0315 21:10:39 @dqn_agent.py:203][0m episode: 9434, total game step: 213000, epsilon: 0.83863099
[32m[0315 21:10:39 @network.py:203][0m step: 163000, current TD loss: 0.00175814400427
[32m[0315 21:10:41 @network.py:203][0m step: 163100, current TD loss: 4.24065656262e-05
[32m[0315 21:10:42 @network.py:203][0m step: 163200, current TD loss: 0.0038959258236
[32m[0315 21:10:44 @network.py:203][0m step: 163300, current TD loss: 0.0153318336233
[32m[0315 21:10:45 @network.py:203][0m step: 163400, current TD loss: 8.6551583081e-05
[32m[0315 21:10:46 @network.py:203][0m step: 163500, current TD loss: 0.0330670960248
[32m[0315 21:10:48 @network.py:203][0m step: 163600, current TD loss: 0.00287413876504
[32m[0315 21:10:49 @network.py:203][0m step: 163700, current TD loss: 0.00290382956155
[32m[0315 21:10:50 @network.py:203][0m step: 163800, current TD loss: 0.00217293435708
[32m[0315 21:10:52 @network.py:203][0m step: 163900, current TD loss: 0.000104157224996
[32m[0315 21:10:53 @dqn_agent.py:203][0m episode: 9488, total game step: 214000, epsilon: 0.83764099
[32m[0315 21:10:53 @network.py:203][0m step: 164000, current TD loss: 0.00168032443617
[32m[0315 21:10:54 @network.py:203][0m step: 164100, current TD loss: 0.000747519778088
[32m[0315 21:10:56 @network.py:203][0m step: 164200, current TD loss: 0.00158412742894
[32m[0315 21:10:57 @network.py:203][0m step: 164300, current TD loss: 0.000754575128667
[32m[0315 21:10:57 @summary_handler.py:101][0m At episode: 214313, Reward: 0.11 (over 100 episodes)
[32m[0315 21:10:57 @summary_handler.py:102][0m Length: 20.35
[32m[0315 21:10:58 @network.py:203][0m step: 164400, current TD loss: 0.00162388233002
[32m[0315 21:11:00 @network.py:203][0m step: 164500, current TD loss: 0.0190119482577
[32m[0315 21:11:01 @network.py:203][0m step: 164600, current TD loss: 0.00183685356751
[32m[0315 21:11:02 @network.py:203][0m step: 164700, current TD loss: 0.0168164502829
[32m[0315 21:11:04 @network.py:203][0m step: 164800, current TD loss: 0.0157893300056
[32m[0315 21:11:05 @network.py:203][0m step: 164900, current TD loss: 0.000139762938488
[32m[0315 21:11:06 @dqn_agent.py:203][0m episode: 9532, total game step: 215000, epsilon: 0.83665099
[32m[0315 21:11:06 @network.py:203][0m step: 165000, current TD loss: 0.00075916282367
[32m[0315 21:11:06 @dqn_agent.py:216][0m At time step 165000, the target_network is updated
[32m[0315 21:11:08 @network.py:203][0m step: 165100, current TD loss: 0.00238161627203
[32m[0315 21:11:09 @network.py:203][0m step: 165200, current TD loss: 4.51143932878e-05
[32m[0315 21:11:10 @network.py:203][0m step: 165300, current TD loss: 0.0354585386813
[32m[0315 21:11:12 @network.py:203][0m step: 165400, current TD loss: 0.00166738557164
[32m[0315 21:11:13 @network.py:203][0m step: 165500, current TD loss: 0.0036519614514
[32m[0315 21:11:14 @network.py:203][0m step: 165600, current TD loss: 0.00168008939363
[32m[0315 21:11:16 @network.py:203][0m step: 165700, current TD loss: 0.00252179801464
[32m[0315 21:11:17 @network.py:203][0m step: 165800, current TD loss: 0.0192715972662
[32m[0315 21:11:18 @network.py:203][0m step: 165900, current TD loss: 0.000130757922307
[32m[0315 21:11:19 @dqn_agent.py:203][0m episode: 9572, total game step: 216000, epsilon: 0.83566099
[32m[0315 21:11:19 @network.py:203][0m step: 166000, current TD loss: 0.0163898598403
[32m[0315 21:11:21 @network.py:203][0m step: 166100, current TD loss: 0.000845261500217
[32m[0315 21:11:22 @network.py:203][0m step: 166200, current TD loss: 0.000888847280294
[32m[0315 21:11:23 @network.py:203][0m step: 166300, current TD loss: 1.62285050465e-05
[32m[0315 21:11:25 @network.py:203][0m step: 166400, current TD loss: 0.017404936254
[32m[0315 21:11:26 @network.py:203][0m step: 166500, current TD loss: 0.0157484747469
[32m[0315 21:11:27 @summary_handler.py:101][0m At episode: 216538, Reward: 0.13 (over 100 episodes)
[32m[0315 21:11:27 @summary_handler.py:102][0m Length: 22.25
[32m[0315 21:11:27 @network.py:203][0m step: 166600, current TD loss: 0.00168302911334
[32m[0315 21:11:29 @network.py:203][0m step: 166700, current TD loss: 0.00163668906316
[32m[0315 21:11:30 @network.py:203][0m step: 166800, current TD loss: 0.00101173040457
[32m[0315 21:11:31 @network.py:203][0m step: 166900, current TD loss: 0.000813989026938
[32m[0315 21:11:33 @dqn_agent.py:203][0m episode: 9621, total game step: 217000, epsilon: 0.83467099
[32m[0315 21:11:33 @network.py:203][0m step: 167000, current TD loss: 0.000822001311462
[32m[0315 21:11:34 @network.py:203][0m step: 167100, current TD loss: 0.0037702457048
[32m[0315 21:11:36 @network.py:203][0m step: 167200, current TD loss: 0.00231696292758
[32m[0315 21:11:37 @network.py:203][0m step: 167300, current TD loss: 0.00157333048992
[32m[0315 21:11:38 @network.py:203][0m step: 167400, current TD loss: 0.000826324976515
[32m[0315 21:11:40 @network.py:203][0m step: 167500, current TD loss: 0.000738954986446
[32m[0315 21:11:40 @dqn_agent.py:216][0m At time step 167500, the target_network is updated
[32m[0315 21:11:41 @network.py:203][0m step: 167600, current TD loss: 0.00328084547073
[32m[0315 21:11:42 @network.py:203][0m step: 167700, current TD loss: 0.00186888186727
[32m[0315 21:11:43 @network.py:203][0m step: 167800, current TD loss: 0.00234028464183
[32m[0315 21:11:45 @network.py:203][0m step: 167900, current TD loss: 0.000805142743047
[32m[0315 21:11:46 @dqn_agent.py:203][0m episode: 9660, total game step: 218000, epsilon: 0.83368099
[32m[0315 21:11:46 @network.py:203][0m step: 168000, current TD loss: 0.00494749704376
[32m[0315 21:11:47 @network.py:203][0m step: 168100, current TD loss: 0.00206421362236
[32m[0315 21:11:49 @network.py:203][0m step: 168200, current TD loss: 0.00154110509902
[32m[0315 21:11:50 @network.py:203][0m step: 168300, current TD loss: 0.00173424812965
[32m[0315 21:11:51 @network.py:203][0m step: 168400, current TD loss: 0.00167285173666
[32m[0315 21:11:53 @network.py:203][0m step: 168500, current TD loss: 0.00217902264558
[32m[0315 21:11:54 @network.py:203][0m step: 168600, current TD loss: 0.000868495728355
[32m[0315 21:11:55 @network.py:203][0m step: 168700, current TD loss: 0.00077032239642
[32m[0315 21:11:57 @network.py:203][0m step: 168800, current TD loss: 0.00101792719215
[32m[0315 21:11:58 @network.py:203][0m step: 168900, current TD loss: 0.0168660674244
[32m[0315 21:11:59 @summary_handler.py:101][0m At episode: 218945, Reward: 0.17 (over 100 episodes)
[32m[0315 21:11:59 @summary_handler.py:102][0m Length: 24.07
[32m[0315 21:11:59 @dqn_agent.py:203][0m episode: 9703, total game step: 219000, epsilon: 0.83269099
[32m[0315 21:11:59 @network.py:203][0m step: 169000, current TD loss: 4.53535394627e-05
[32m[0315 21:12:01 @network.py:203][0m step: 169100, current TD loss: 0.00318297394551
[32m[0315 21:12:02 @network.py:203][0m step: 169200, current TD loss: 0.00158152694348
[32m[0315 21:12:03 @network.py:203][0m step: 169300, current TD loss: 3.80217970815e-05
[32m[0315 21:12:05 @network.py:203][0m step: 169400, current TD loss: 0.00082472077338
[32m[0315 21:12:06 @network.py:203][0m step: 169500, current TD loss: 0.00310645485297
[32m[0315 21:12:07 @network.py:203][0m step: 169600, current TD loss: 0.00325508438982
[32m[0315 21:12:09 @network.py:203][0m step: 169700, current TD loss: 0.00122213654686
[32m[0315 21:12:10 @network.py:203][0m step: 169800, current TD loss: 0.000785611802712
[32m[0315 21:12:11 @network.py:203][0m step: 169900, current TD loss: 0.0202500689775
[32m[0315 21:12:13 @dqn_agent.py:203][0m episode: 9751, total game step: 220000, epsilon: 0.83170099
[32m[0315 21:12:13 @network.py:203][0m step: 170000, current TD loss: 0.000789508630987
[32m[0315 21:12:13 @dqn_agent.py:216][0m At time step 170000, the target_network is updated
[32m[0315 21:12:14 @network.py:203][0m step: 170100, current TD loss: 0.00159676803742
[32m[0315 21:12:15 @network.py:203][0m step: 170200, current TD loss: 0.00149267958477
[32m[0315 21:12:17 @network.py:203][0m step: 170300, current TD loss: 0.0184705797583
[32m[0315 21:12:18 @network.py:203][0m step: 170400, current TD loss: 0.00169240008108
[32m[0315 21:12:20 @network.py:203][0m step: 170500, current TD loss: 0.00072135287337
[32m[0315 21:12:21 @network.py:203][0m step: 170600, current TD loss: 2.68331023108e-05
[32m[0315 21:12:22 @network.py:203][0m step: 170700, current TD loss: 0.00434602424502
[32m[0315 21:12:24 @network.py:203][0m step: 170800, current TD loss: 0.00322655076161
[32m[0315 21:12:25 @network.py:203][0m step: 170900, current TD loss: 0.018246030435
[32m[0315 21:12:26 @dqn_agent.py:203][0m episode: 9798, total game step: 221000, epsilon: 0.83071099
[32m[0315 21:12:26 @network.py:203][0m step: 171000, current TD loss: 0.000783309864346
[32m[0315 21:12:27 @summary_handler.py:101][0m At episode: 221025, Reward: 0.1 (over 100 episodes)
[32m[0315 21:12:27 @summary_handler.py:102][0m Length: 20.8
[32m[0315 21:12:28 @network.py:203][0m step: 171100, current TD loss: 0.000897770398296
[32m[0315 21:12:29 @network.py:203][0m step: 171200, current TD loss: 0.000866646121722
[32m[0315 21:12:30 @network.py:203][0m step: 171300, current TD loss: 0.00293807499111
[32m[0315 21:12:32 @network.py:203][0m step: 171400, current TD loss: 3.75130948669e-05
[32m[0315 21:12:33 @network.py:203][0m step: 171500, current TD loss: 4.13586931245e-05
[32m[0315 21:12:34 @network.py:203][0m step: 171600, current TD loss: 0.033646941185
[32m[0315 21:12:36 @network.py:203][0m step: 171700, current TD loss: 0.00160529837012
[32m[0315 21:12:37 @network.py:203][0m step: 171800, current TD loss: 0.00220281048678
[32m[0315 21:12:38 @network.py:203][0m step: 171900, current TD loss: 0.000742560252547
[32m[0315 21:12:40 @dqn_agent.py:203][0m episode: 9840, total game step: 222000, epsilon: 0.82972099
[32m[0315 21:12:40 @network.py:203][0m step: 172000, current TD loss: 0.0176747422665
[32m[0315 21:12:41 @network.py:203][0m step: 172100, current TD loss: 0.000802440743428
[32m[0315 21:12:42 @network.py:203][0m step: 172200, current TD loss: 4.90413258376e-05
[32m[0315 21:12:44 @network.py:203][0m step: 172300, current TD loss: 0.000801286252681
[32m[0315 21:12:45 @network.py:203][0m step: 172400, current TD loss: 0.01723700203
[32m[0315 21:12:46 @network.py:203][0m step: 172500, current TD loss: 0.00200692983344
[32m[0315 21:12:46 @dqn_agent.py:216][0m At time step 172500, the target_network is updated
[32m[0315 21:12:48 @network.py:203][0m step: 172600, current TD loss: 0.00164929148741
[32m[0315 21:12:49 @network.py:203][0m step: 172700, current TD loss: 0.00083048682427
[32m[0315 21:12:50 @network.py:203][0m step: 172800, current TD loss: 0.000843708403409
[32m[0315 21:12:52 @network.py:203][0m step: 172900, current TD loss: 0.000823109468911
[32m[0315 21:12:53 @dqn_agent.py:203][0m episode: 9889, total game step: 223000, epsilon: 0.82873099
[32m[0315 21:12:53 @network.py:203][0m step: 173000, current TD loss: 9.72045891103e-05
[32m[0315 21:12:54 @network.py:203][0m step: 173100, current TD loss: 0.000853427511174
[32m[0315 21:12:56 @network.py:203][0m step: 173200, current TD loss: 0.0173904467374
[32m[0315 21:12:56 @summary_handler.py:101][0m At episode: 223257, Reward: 0.14 (over 100 episodes)
[32m[0315 21:12:56 @summary_handler.py:102][0m Length: 22.32
[32m[0315 21:12:57 @network.py:203][0m step: 173300, current TD loss: 0.0019915967714
[32m[0315 21:12:58 @network.py:203][0m step: 173400, current TD loss: 0.00507030636072
[32m[0315 21:13:00 @network.py:203][0m step: 173500, current TD loss: 7.40772738936e-05
[32m[0315 21:13:01 @network.py:203][0m step: 173600, current TD loss: 0.000806200958323
[32m[0315 21:13:02 @network.py:203][0m step: 173700, current TD loss: 0.000782963878009
[32m[0315 21:13:04 @network.py:203][0m step: 173800, current TD loss: 3.54521616828e-05
[32m[0315 21:13:05 @network.py:203][0m step: 173900, current TD loss: 0.00278657488525
[32m[0315 21:13:06 @dqn_agent.py:203][0m episode: 9931, total game step: 224000, epsilon: 0.82774099
[32m[0315 21:13:06 @network.py:203][0m step: 174000, current TD loss: 0.0202997848392
[32m[0315 21:13:08 @network.py:203][0m step: 174100, current TD loss: 0.0015068303328
[32m[0315 21:13:09 @network.py:203][0m step: 174200, current TD loss: 0.0198957584798
[32m[0315 21:13:10 @network.py:203][0m step: 174300, current TD loss: 0.000902011001017
[32m[0315 21:13:12 @network.py:203][0m step: 174400, current TD loss: 0.0157127473503
[32m[0315 21:13:13 @network.py:203][0m step: 174500, current TD loss: 0.00243099825457
[32m[0315 21:13:14 @network.py:203][0m step: 174600, current TD loss: 0.000842474109959
[32m[0315 21:13:16 @network.py:203][0m step: 174700, current TD loss: 8.47490009619e-05
[32m[0315 21:13:17 @network.py:203][0m step: 174800, current TD loss: 0.0171522088349
[32m[0315 21:13:18 @network.py:203][0m step: 174900, current TD loss: 0.00330640352331
[32m[0315 21:13:20 @dqn_agent.py:203][0m episode: 9980, total game step: 225000, epsilon: 0.82675099
[32m[0315 21:13:20 @network.py:203][0m step: 175000, current TD loss: 0.00182722636964
[32m[0315 21:13:20 @dqn_agent.py:216][0m At time step 175000, the target_network is updated
[32m[0315 21:13:21 @network.py:203][0m step: 175100, current TD loss: 0.00210158783011
[32m[0315 21:13:22 @network.py:203][0m step: 175200, current TD loss: 0.00205145264044
[32m[0315 21:13:24 @network.py:203][0m step: 175300, current TD loss: 0.00211711996235
[32m[0315 21:13:24 @summary_handler.py:101][0m At episode: 225315, Reward: 0.12 (over 100 episodes)
[32m[0315 21:13:24 @summary_handler.py:102][0m Length: 20.58
[32m[0315 21:13:25 @network.py:203][0m step: 175400, current TD loss: 0.00170093728229
[32m[0315 21:13:27 @network.py:203][0m step: 175500, current TD loss: 0.0371658615768
[32m[0315 21:13:28 @network.py:203][0m step: 175600, current TD loss: 0.00157851725817
[32m[0315 21:13:29 @network.py:203][0m step: 175700, current TD loss: 2.76388927887e-05
[32m[0315 21:13:31 @network.py:203][0m step: 175800, current TD loss: 0.000846388167702
[32m[0315 21:13:32 @network.py:203][0m step: 175900, current TD loss: 0.000783975294326
[32m[0315 21:13:33 @dqn_agent.py:203][0m episode: 10024, total game step: 226000, epsilon: 0.82576099
[32m[0315 21:13:33 @network.py:203][0m step: 176000, current TD loss: 0.00128731038421
[32m[0315 21:13:35 @network.py:203][0m step: 176100, current TD loss: 0.00157560070511
[32m[0315 21:13:36 @network.py:203][0m step: 176200, current TD loss: 0.0014688159572
[32m[0315 21:13:37 @network.py:203][0m step: 176300, current TD loss: 0.0185145903379
[32m[0315 21:13:39 @network.py:203][0m step: 176400, current TD loss: 0.00112570368219
[32m[0315 21:13:40 @network.py:203][0m step: 176500, current TD loss: 6.55423064018e-05
[32m[0315 21:13:41 @network.py:203][0m step: 176600, current TD loss: 0.00013402813056
[32m[0315 21:13:43 @network.py:203][0m step: 176700, current TD loss: 0.00217576231807
[32m[0315 21:13:44 @network.py:203][0m step: 176800, current TD loss: 0.00155667983927
[32m[0315 21:13:45 @network.py:203][0m step: 176900, current TD loss: 0.00144854735117
[32m[0315 21:13:47 @dqn_agent.py:203][0m episode: 10073, total game step: 227000, epsilon: 0.82477099
[32m[0315 21:13:47 @network.py:203][0m step: 177000, current TD loss: 0.000888420967385
[32m[0315 21:13:48 @network.py:203][0m step: 177100, current TD loss: 0.00215047574602
[32m[0315 21:13:49 @network.py:203][0m step: 177200, current TD loss: 0.000768687634263
[32m[0315 21:13:51 @network.py:203][0m step: 177300, current TD loss: 0.00475374329835
[32m[0315 21:13:52 @network.py:203][0m step: 177400, current TD loss: 0.000775866559707
[32m[0315 21:13:53 @network.py:203][0m step: 177500, current TD loss: 0.000843701011036
[32m[0315 21:13:53 @dqn_agent.py:216][0m At time step 177500, the target_network is updated
[32m[0315 21:13:55 @summary_handler.py:101][0m At episode: 227593, Reward: 0.14 (over 100 episodes)
[32m[0315 21:13:55 @summary_handler.py:102][0m Length: 22.78
[32m[0315 21:13:55 @network.py:203][0m step: 177600, current TD loss: 8.74801698956e-05
[32m[0315 21:13:56 @network.py:203][0m step: 177700, current TD loss: 0.0015320989769
[32m[0315 21:13:57 @network.py:203][0m step: 177800, current TD loss: 0.0171531513333
[32m[0315 21:13:59 @network.py:203][0m step: 177900, current TD loss: 0.00173014774919
[32m[0315 21:14:00 @dqn_agent.py:203][0m episode: 10119, total game step: 228000, epsilon: 0.82378099
[32m[0315 21:14:00 @network.py:203][0m step: 178000, current TD loss: 0.0181936472654
[32m[0315 21:14:02 @network.py:203][0m step: 178100, current TD loss: 0.00112695642747
[32m[0315 21:14:03 @network.py:203][0m step: 178200, current TD loss: 0.00133595371153
[32m[0315 21:14:04 @network.py:203][0m step: 178300, current TD loss: 0.000847196381073
[32m[0315 21:14:06 @network.py:203][0m step: 178400, current TD loss: 0.00184461311437
[32m[0315 21:14:07 @network.py:203][0m step: 178500, current TD loss: 9.38107914408e-05
[32m[0315 21:14:08 @network.py:203][0m step: 178600, current TD loss: 0.00162144366186
[32m[0315 21:14:10 @network.py:203][0m step: 178700, current TD loss: 0.00161746353842
[32m[0315 21:14:11 @network.py:203][0m step: 178800, current TD loss: 0.00248017534614
[32m[0315 21:14:12 @network.py:203][0m step: 178900, current TD loss: 0.000758379988838
[32m[0315 21:14:14 @dqn_agent.py:203][0m episode: 10168, total game step: 229000, epsilon: 0.82279099
[32m[0315 21:14:14 @network.py:203][0m step: 179000, current TD loss: 0.000873136043083
[32m[0315 21:14:15 @network.py:203][0m step: 179100, current TD loss: 0.000100768258562
[32m[0315 21:14:16 @network.py:203][0m step: 179200, current TD loss: 0.000100413752079
[32m[0315 21:14:18 @network.py:203][0m step: 179300, current TD loss: 0.0221579819918
[32m[0315 21:14:19 @network.py:203][0m step: 179400, current TD loss: 0.0187929179519
[32m[0315 21:14:20 @network.py:203][0m step: 179500, current TD loss: 0.00169612828176
[32m[0315 21:14:22 @network.py:203][0m step: 179600, current TD loss: 0.00260898913257
[32m[0315 21:14:23 @summary_handler.py:101][0m At episode: 229692, Reward: 0.15 (over 100 episodes)
[32m[0315 21:14:23 @summary_handler.py:102][0m Length: 20.99
[32m[0315 21:14:23 @network.py:203][0m step: 179700, current TD loss: 0.000884097535163
[32m[0315 21:14:24 @network.py:203][0m step: 179800, current TD loss: 6.46651460556e-05
[32m[0315 21:14:26 @network.py:203][0m step: 179900, current TD loss: 6.57773780404e-05
[32m[0315 21:14:27 @dqn_agent.py:203][0m episode: 10213, total game step: 230000, epsilon: 0.82180099
[32m[0315 21:14:27 @network.py:203][0m step: 180000, current TD loss: 0.00147647690028
[32m[0315 21:14:27 @dqn_agent.py:216][0m At time step 180000, the target_network is updated
[32m[0315 21:14:29 @network.py:203][0m step: 180100, current TD loss: 0.0027791147586
[32m[0315 21:14:30 @network.py:203][0m step: 180200, current TD loss: 0.00199331180193
[32m[0315 21:14:31 @network.py:203][0m step: 180300, current TD loss: 6.15811295575e-05
[32m[0315 21:14:33 @network.py:203][0m step: 180400, current TD loss: 0.00130723719485
[32m[0315 21:14:34 @network.py:203][0m step: 180500, current TD loss: 9.99337644316e-05
[32m[0315 21:14:35 @network.py:203][0m step: 180600, current TD loss: 0.000948007160332
[32m[0315 21:14:37 @network.py:203][0m step: 180700, current TD loss: 0.0189939718693
[32m[0315 21:14:38 @network.py:203][0m step: 180800, current TD loss: 0.0018792564515
[32m[0315 21:14:39 @network.py:203][0m step: 180900, current TD loss: 0.00258006202057
[32m[0315 21:14:41 @dqn_agent.py:203][0m episode: 10261, total game step: 231000, epsilon: 0.82081099
[32m[0315 21:14:41 @network.py:203][0m step: 181000, current TD loss: 0.00181465921924
[32m[0315 21:14:42 @network.py:203][0m step: 181100, current TD loss: 0.0169664435089
[32m[0315 21:14:43 @network.py:203][0m step: 181200, current TD loss: 0.00313598732464
[32m[0315 21:14:45 @network.py:203][0m step: 181300, current TD loss: 0.00184291112237
[32m[0315 21:14:46 @network.py:203][0m step: 181400, current TD loss: 0.0152097167447
[32m[0315 21:14:47 @network.py:203][0m step: 181500, current TD loss: 0.00278081698343
[32m[0315 21:14:49 @network.py:203][0m step: 181600, current TD loss: 0.000864322297275
[32m[0315 21:14:50 @network.py:203][0m step: 181700, current TD loss: 0.00172807159834
[32m[0315 21:14:51 @network.py:203][0m step: 181800, current TD loss: 4.34775538452e-05
[32m[0315 21:14:53 @network.py:203][0m step: 181900, current TD loss: 0.00346731999889
[32m[0315 21:14:53 @summary_handler.py:101][0m At episode: 231906, Reward: 0.18 (over 100 episodes)
[32m[0315 21:14:53 @summary_handler.py:102][0m Length: 22.14
[32m[0315 21:14:54 @dqn_agent.py:203][0m episode: 10304, total game step: 232000, epsilon: 0.81982099
[32m[0315 21:14:54 @network.py:203][0m step: 182000, current TD loss: 0.00195846357383
[32m[0315 21:14:55 @network.py:203][0m step: 182100, current TD loss: 0.0185326077044
[32m[0315 21:14:57 @network.py:203][0m step: 182200, current TD loss: 0.000875068362802
[32m[0315 21:14:58 @network.py:203][0m step: 182300, current TD loss: 0.0169809106737
[32m[0315 21:14:59 @network.py:203][0m step: 182400, current TD loss: 0.000836589722894
[32m[0315 21:15:01 @network.py:203][0m step: 182500, current TD loss: 0.00199340516701
[32m[0315 21:15:01 @dqn_agent.py:216][0m At time step 182500, the target_network is updated
[32m[0315 21:15:02 @network.py:203][0m step: 182600, current TD loss: 0.000954433984589
[32m[0315 21:15:03 @network.py:203][0m step: 182700, current TD loss: 0.000865447451361
[32m[0315 21:15:05 @network.py:203][0m step: 182800, current TD loss: 0.00397988595068
[32m[0315 21:15:06 @network.py:203][0m step: 182900, current TD loss: 0.000133107256261
[32m[0315 21:15:07 @dqn_agent.py:203][0m episode: 10348, total game step: 233000, epsilon: 0.81883099
[32m[0315 21:15:07 @network.py:203][0m step: 183000, current TD loss: 0.000142496821354
[32m[0315 21:15:09 @network.py:203][0m step: 183100, current TD loss: 0.00166459509637
[32m[0315 21:15:10 @network.py:203][0m step: 183200, current TD loss: 0.0149894412607
[32m[0315 21:15:11 @network.py:203][0m step: 183300, current TD loss: 0.000911233422812
[32m[0315 21:15:13 @network.py:203][0m step: 183400, current TD loss: 0.00318398885429
[32m[0315 21:15:14 @network.py:203][0m step: 183500, current TD loss: 0.00262684747577
[32m[0315 21:15:15 @network.py:203][0m step: 183600, current TD loss: 0.000771137245465
[32m[0315 21:15:17 @network.py:203][0m step: 183700, current TD loss: 0.000863790977746
[32m[0315 21:15:18 @network.py:203][0m step: 183800, current TD loss: 0.01612614654
[32m[0315 21:15:19 @network.py:203][0m step: 183900, current TD loss: 8.05107993074e-05
[32m[0315 21:15:21 @dqn_agent.py:203][0m episode: 10393, total game step: 234000, epsilon: 0.81784099
[32m[0315 21:15:21 @network.py:203][0m step: 184000, current TD loss: 0.00074252136983
[32m[0315 21:15:22 @network.py:203][0m step: 184100, current TD loss: 0.0033481605351
[32m[0315 21:15:23 @network.py:203][0m step: 184200, current TD loss: 0.0166615676135
[32m[0315 21:15:25 @network.py:203][0m step: 184300, current TD loss: 0.00105152651668
[32m[0315 21:15:25 @summary_handler.py:101][0m At episode: 234309, Reward: 0.2 (over 100 episodes)
[32m[0315 21:15:25 @summary_handler.py:102][0m Length: 24.03
[32m[0315 21:15:26 @network.py:203][0m step: 184400, current TD loss: 0.0171470791101
[32m[0315 21:15:27 @network.py:203][0m step: 184500, current TD loss: 0.0024448079057
[32m[0315 21:15:29 @network.py:203][0m step: 184600, current TD loss: 0.00217566499487
[32m[0315 21:15:30 @network.py:203][0m step: 184700, current TD loss: 0.00164731801488
[32m[0315 21:15:31 @network.py:203][0m step: 184800, current TD loss: 0.0179616454989
[32m[0315 21:15:33 @network.py:203][0m step: 184900, current TD loss: 0.000866552116349
[32m[0315 21:15:34 @dqn_agent.py:203][0m episode: 10438, total game step: 235000, epsilon: 0.81685099
[32m[0315 21:15:34 @network.py:203][0m step: 185000, current TD loss: 0.0329730883241
[32m[0315 21:15:34 @dqn_agent.py:216][0m At time step 185000, the target_network is updated
[32m[0315 21:15:35 @network.py:203][0m step: 185100, current TD loss: 0.00241380999796
[32m[0315 21:15:37 @network.py:203][0m step: 185200, current TD loss: 0.00145278288983
[32m[0315 21:15:38 @network.py:203][0m step: 185300, current TD loss: 0.020011825487
[32m[0315 21:15:39 @network.py:203][0m step: 185400, current TD loss: 0.000812813465018
[32m[0315 21:15:41 @network.py:203][0m step: 185500, current TD loss: 0.00222628330812
[32m[0315 21:15:42 @network.py:203][0m step: 185600, current TD loss: 0.00313233910128
[32m[0315 21:15:43 @network.py:203][0m step: 185700, current TD loss: 0.00208098394796
[32m[0315 21:15:45 @network.py:203][0m step: 185800, current TD loss: 0.00279522500932
[32m[0315 21:15:46 @network.py:203][0m step: 185900, current TD loss: 0.00114699557889
[32m[0315 21:15:47 @dqn_agent.py:203][0m episode: 10480, total game step: 236000, epsilon: 0.81586099
[32m[0315 21:15:47 @network.py:203][0m step: 186000, current TD loss: 0.00195368449204
[32m[0315 21:15:49 @network.py:203][0m step: 186100, current TD loss: 0.00182649341878
[32m[0315 21:15:50 @network.py:203][0m step: 186200, current TD loss: 0.000127474340843
[32m[0315 21:15:52 @network.py:203][0m step: 186300, current TD loss: 0.00126561580691
[32m[0315 21:15:53 @network.py:203][0m step: 186400, current TD loss: 0.000988190644421
[32m[0315 21:15:54 @network.py:203][0m step: 186500, current TD loss: 0.00102685310412
[32m[0315 21:15:55 @summary_handler.py:101][0m At episode: 236586, Reward: 0.14 (over 100 episodes)
[32m[0315 21:15:55 @summary_handler.py:102][0m Length: 22.77
[32m[0315 21:15:55 @network.py:203][0m step: 186600, current TD loss: 0.000865215202793
[32m[0315 21:15:57 @network.py:203][0m step: 186700, current TD loss: 0.0192920528352
[32m[0315 21:15:58 @network.py:203][0m step: 186800, current TD loss: 0.000870039919391
[32m[0315 21:15:59 @network.py:203][0m step: 186900, current TD loss: 0.00254318537191
[32m[0315 21:16:01 @dqn_agent.py:203][0m episode: 10518, total game step: 237000, epsilon: 0.81487099
[32m[0315 21:16:01 @network.py:203][0m step: 187000, current TD loss: 0.0166278425604
[32m[0315 21:16:02 @network.py:203][0m step: 187100, current TD loss: 0.00199599657208
[32m[0315 21:16:03 @network.py:203][0m step: 187200, current TD loss: 0.00337235233746
[32m[0315 21:16:05 @network.py:203][0m step: 187300, current TD loss: 0.00291174720041
[32m[0315 21:16:06 @network.py:203][0m step: 187400, current TD loss: 0.0186902135611
[32m[0315 21:16:07 @network.py:203][0m step: 187500, current TD loss: 0.00172814936377
[32m[0315 21:16:07 @dqn_agent.py:216][0m At time step 187500, the target_network is updated
[32m[0315 21:16:09 @network.py:203][0m step: 187600, current TD loss: 0.0013644451974
[32m[0315 21:16:10 @network.py:203][0m step: 187700, current TD loss: 0.000881627318449
[32m[0315 21:16:11 @network.py:203][0m step: 187800, current TD loss: 0.00309375207871
[32m[0315 21:16:13 @network.py:203][0m step: 187900, current TD loss: 0.0168283320963
[32m[0315 21:16:14 @dqn_agent.py:203][0m episode: 10553, total game step: 238000, epsilon: 0.81388099
[32m[0315 21:16:14 @network.py:203][0m step: 188000, current TD loss: 0.00414696661755
[32m[0315 21:16:15 @network.py:203][0m step: 188100, current TD loss: 0.00276457238942
[32m[0315 21:16:17 @network.py:203][0m step: 188200, current TD loss: 0.017028875649
[32m[0315 21:16:18 @network.py:203][0m step: 188300, current TD loss: 0.00255081243813
[32m[0315 21:16:20 @network.py:203][0m step: 188400, current TD loss: 0.0207068677992
[32m[0315 21:16:21 @network.py:203][0m step: 188500, current TD loss: 0.000829877797514
[32m[0315 21:16:22 @network.py:203][0m step: 188600, current TD loss: 0.000777264300268
[32m[0315 21:16:23 @network.py:203][0m step: 188700, current TD loss: 0.00521818781272
[32m[0315 21:16:25 @network.py:203][0m step: 188800, current TD loss: 0.00155986449681
[32m[0315 21:16:26 @network.py:203][0m step: 188900, current TD loss: 0.00166618393268
[32m[0315 21:16:28 @dqn_agent.py:203][0m episode: 10599, total game step: 239000, epsilon: 0.81289099
[32m[0315 21:16:28 @network.py:203][0m step: 189000, current TD loss: 0.000115682116302
[32m[0315 21:16:29 @summary_handler.py:101][0m At episode: 239092, Reward: 0.18 (over 100 episodes)
[32m[0315 21:16:29 @summary_handler.py:102][0m Length: 25.06
[32m[0315 21:16:29 @network.py:203][0m step: 189100, current TD loss: 0.00174360245001
[32m[0315 21:16:30 @network.py:203][0m step: 189200, current TD loss: 2.99975727103e-05
[32m[0315 21:16:32 @network.py:203][0m step: 189300, current TD loss: 0.00181004323531
[32m[0315 21:16:33 @network.py:203][0m step: 189400, current TD loss: 0.0176296755672
[32m[0315 21:16:34 @network.py:203][0m step: 189500, current TD loss: 0.0043252450414
[32m[0315 21:16:35 @network.py:203][0m step: 189600, current TD loss: 0.00143112416845
[32m[0315 21:16:37 @network.py:203][0m step: 189700, current TD loss: 0.00367023027502
[32m[0315 21:16:38 @network.py:203][0m step: 189800, current TD loss: 0.00140172336251
[32m[0315 21:16:39 @network.py:203][0m step: 189900, current TD loss: 0.00222421949729
[32m[0315 21:16:41 @dqn_agent.py:203][0m episode: 10637, total game step: 240000, epsilon: 0.81190099
[32m[0315 21:16:41 @network.py:203][0m step: 190000, current TD loss: 6.35913820588e-05
[32m[0315 21:16:41 @dqn_agent.py:216][0m At time step 190000, the target_network is updated
[32m[0315 21:16:42 @network.py:203][0m step: 190100, current TD loss: 0.0183035787195
[32m[0315 21:16:43 @network.py:203][0m step: 190200, current TD loss: 0.00115557480603
[32m[0315 21:16:45 @network.py:203][0m step: 190300, current TD loss: 0.00159327522852
[32m[0315 21:16:46 @network.py:203][0m step: 190400, current TD loss: 0.00118589063641
[32m[0315 21:16:47 @network.py:203][0m step: 190500, current TD loss: 0.0023970939219
[32m[0315 21:16:49 @network.py:203][0m step: 190600, current TD loss: 0.0211097896099
[32m[0315 21:16:50 @network.py:203][0m step: 190700, current TD loss: 0.0192536953837
[32m[0315 21:16:52 @network.py:203][0m step: 190800, current TD loss: 0.000805853924248
[32m[0315 21:16:53 @network.py:203][0m step: 190900, current TD loss: 0.00123516959138
[32m[0315 21:16:54 @dqn_agent.py:203][0m episode: 10682, total game step: 241000, epsilon: 0.81091099
[32m[0315 21:16:54 @network.py:203][0m step: 191000, current TD loss: 0.0182244777679
[32m[0315 21:16:56 @network.py:203][0m step: 191100, current TD loss: 0.0155333504081
[32m[0315 21:16:57 @network.py:203][0m step: 191200, current TD loss: 0.0175011120737
[32m[0315 21:16:58 @network.py:203][0m step: 191300, current TD loss: 0.00176902906969
[32m[0315 21:16:59 @summary_handler.py:101][0m At episode: 241325, Reward: 0.1 (over 100 episodes)
[32m[0315 21:16:59 @summary_handler.py:102][0m Length: 22.33
[32m[0315 21:17:00 @network.py:203][0m step: 191400, current TD loss: 0.000843014742713
[32m[0315 21:17:01 @network.py:203][0m step: 191500, current TD loss: 4.69526385132e-05
[32m[0315 21:17:02 @network.py:203][0m step: 191600, current TD loss: 5.95776509726e-05
[32m[0315 21:17:04 @network.py:203][0m step: 191700, current TD loss: 0.0023440932855
[32m[0315 21:17:05 @network.py:203][0m step: 191800, current TD loss: 0.0182290580124
[32m[0315 21:17:06 @network.py:203][0m step: 191900, current TD loss: 0.0029745453503
[32m[0315 21:17:08 @dqn_agent.py:203][0m episode: 10732, total game step: 242000, epsilon: 0.80992099
[32m[0315 21:17:08 @network.py:203][0m step: 192000, current TD loss: 0.000919760554098
[32m[0315 21:17:09 @network.py:203][0m step: 192100, current TD loss: 0.00225748633966
[32m[0315 21:17:10 @network.py:203][0m step: 192200, current TD loss: 0.00185426475946
[32m[0315 21:17:12 @network.py:203][0m step: 192300, current TD loss: 0.0173809695989
[32m[0315 21:17:13 @network.py:203][0m step: 192400, current TD loss: 0.00177370617166
[32m[0315 21:17:14 @network.py:203][0m step: 192500, current TD loss: 0.0152680873871
[32m[0315 21:17:14 @dqn_agent.py:216][0m At time step 192500, the target_network is updated
[32m[0315 21:17:16 @network.py:203][0m step: 192600, current TD loss: 0.00301004317589
[32m[0315 21:17:17 @network.py:203][0m step: 192700, current TD loss: 3.90381319448e-05
[32m[0315 21:17:18 @network.py:203][0m step: 192800, current TD loss: 0.000982732977718
[32m[0315 21:17:20 @network.py:203][0m step: 192900, current TD loss: 0.0016859540483
[32m[0315 21:17:21 @dqn_agent.py:203][0m episode: 10772, total game step: 243000, epsilon: 0.80893099
[32m[0315 21:17:21 @network.py:203][0m step: 193000, current TD loss: 0.0163083635271
[32m[0315 21:17:22 @network.py:203][0m step: 193100, current TD loss: 0.0173347536474
[32m[0315 21:17:24 @network.py:203][0m step: 193200, current TD loss: 7.20107927918e-05
[32m[0315 21:17:25 @network.py:203][0m step: 193300, current TD loss: 0.000117368530482
[32m[0315 21:17:26 @network.py:203][0m step: 193400, current TD loss: 0.0201758146286
[32m[0315 21:17:27 @network.py:203][0m step: 193500, current TD loss: 0.00398316746578
[32m[0315 21:17:29 @network.py:203][0m step: 193600, current TD loss: 0.0177194047719
[32m[0315 21:17:30 @network.py:203][0m step: 193700, current TD loss: 0.000858775631059
[32m[0315 21:17:31 @summary_handler.py:101][0m At episode: 243739, Reward: 0.15 (over 100 episodes)
[32m[0315 21:17:31 @summary_handler.py:102][0m Length: 24.14
[32m[0315 21:17:31 @network.py:203][0m step: 193800, current TD loss: 0.0185250695795
[32m[0315 21:17:33 @network.py:203][0m step: 193900, current TD loss: 0.0014836685732
[32m[0315 21:17:34 @dqn_agent.py:203][0m episode: 10811, total game step: 244000, epsilon: 0.80794099
[32m[0315 21:17:34 @network.py:203][0m step: 194000, current TD loss: 0.00169936113525
[32m[0315 21:17:35 @network.py:203][0m step: 194100, current TD loss: 0.00088527915068
[32m[0315 21:17:37 @network.py:203][0m step: 194200, current TD loss: 0.00368898082525
[32m[0315 21:17:38 @network.py:203][0m step: 194300, current TD loss: 0.0179010983557
[32m[0315 21:17:39 @network.py:203][0m step: 194400, current TD loss: 4.95780222991e-05
[32m[0315 21:17:41 @network.py:203][0m step: 194500, current TD loss: 0.00308837532066
[32m[0315 21:17:42 @network.py:203][0m step: 194600, current TD loss: 0.00223961123265
[32m[0315 21:17:43 @network.py:203][0m step: 194700, current TD loss: 0.0175198912621
[32m[0315 21:17:45 @network.py:203][0m step: 194800, current TD loss: 0.00632674526423
[32m[0315 21:17:46 @network.py:203][0m step: 194900, current TD loss: 0.000913520983886
[32m[0315 21:17:47 @dqn_agent.py:203][0m episode: 10851, total game step: 245000, epsilon: 0.80695099
[32m[0315 21:17:47 @network.py:203][0m step: 195000, current TD loss: 0.000908765010536
[32m[0315 21:17:47 @dqn_agent.py:216][0m At time step 195000, the target_network is updated
[32m[0315 21:17:49 @network.py:203][0m step: 195100, current TD loss: 0.00589212169871
[32m[0315 21:17:50 @network.py:203][0m step: 195200, current TD loss: 0.000973997404799
[32m[0315 21:17:51 @network.py:203][0m step: 195300, current TD loss: 0.00190638087224
[32m[0315 21:17:53 @network.py:203][0m step: 195400, current TD loss: 0.0164783410728
[32m[0315 21:17:54 @network.py:203][0m step: 195500, current TD loss: 0.000158540249686
[32m[0315 21:17:55 @network.py:203][0m step: 195600, current TD loss: 0.00184216932394
[32m[0315 21:17:57 @network.py:203][0m step: 195700, current TD loss: 0.00260569737293
[32m[0315 21:17:58 @network.py:203][0m step: 195800, current TD loss: 0.0198133327067
[32m[0315 21:17:59 @network.py:203][0m step: 195900, current TD loss: 0.0024902347941
[32m[0315 21:18:01 @dqn_agent.py:203][0m episode: 10892, total game step: 246000, epsilon: 0.80596099
[32m[0315 21:18:01 @network.py:203][0m step: 196000, current TD loss: 0.0177778881043
[32m[0315 21:18:02 @network.py:203][0m step: 196100, current TD loss: 0.0180176552385
[32m[0315 21:18:03 @summary_handler.py:101][0m At episode: 246186, Reward: 0.16 (over 100 episodes)
[32m[0315 21:18:03 @summary_handler.py:102][0m Length: 24.47
[32m[0315 21:18:03 @network.py:203][0m step: 196200, current TD loss: 0.00343584874645
[32m[0315 21:18:05 @network.py:203][0m step: 196300, current TD loss: 0.00167344219517
[32m[0315 21:18:06 @network.py:203][0m step: 196400, current TD loss: 0.0150819905102
[32m[0315 21:18:08 @network.py:203][0m step: 196500, current TD loss: 0.000985571066849
[32m[0315 21:18:09 @network.py:203][0m step: 196600, current TD loss: 0.0027857394889
[32m[0315 21:18:10 @network.py:203][0m step: 196700, current TD loss: 0.000799140951131
[32m[0315 21:18:12 @network.py:203][0m step: 196800, current TD loss: 0.00410704640672
[32m[0315 21:18:13 @network.py:203][0m step: 196900, current TD loss: 0.00192323955707
[32m[0315 21:18:14 @dqn_agent.py:203][0m episode: 10937, total game step: 247000, epsilon: 0.80497099
[32m[0315 21:18:14 @network.py:203][0m step: 197000, current TD loss: 0.00211860449053
[32m[0315 21:18:16 @network.py:203][0m step: 197100, current TD loss: 0.0163712073117
[32m[0315 21:18:17 @network.py:203][0m step: 197200, current TD loss: 0.00158042495605
[32m[0315 21:18:18 @network.py:203][0m step: 197300, current TD loss: 0.00156441726722
[32m[0315 21:18:20 @network.py:203][0m step: 197400, current TD loss: 0.000950972025748
[32m[0315 21:18:21 @network.py:203][0m step: 197500, current TD loss: 0.00278448150493
[32m[0315 21:18:21 @dqn_agent.py:216][0m At time step 197500, the target_network is updated
[32m[0315 21:18:22 @network.py:203][0m step: 197600, current TD loss: 0.0050964388065
[32m[0315 21:18:24 @network.py:203][0m step: 197700, current TD loss: 0.00025457146694
[32m[0315 21:18:25 @network.py:203][0m step: 197800, current TD loss: 0.000887583533768
[32m[0315 21:18:26 @network.py:203][0m step: 197900, current TD loss: 0.000949416309595
[32m[0315 21:18:27 @dqn_agent.py:203][0m episode: 10981, total game step: 248000, epsilon: 0.80398099
[32m[0315 21:18:27 @network.py:203][0m step: 198000, current TD loss: 5.30385950697e-05
[32m[0315 21:18:29 @network.py:203][0m step: 198100, current TD loss: 0.00340401590802
[32m[0315 21:18:30 @network.py:203][0m step: 198200, current TD loss: 0.002035736572
[32m[0315 21:18:32 @network.py:203][0m step: 198300, current TD loss: 0.00186451699119
[32m[0315 21:18:33 @network.py:203][0m step: 198400, current TD loss: 0.0201117713004
[32m[0315 21:18:33 @summary_handler.py:101][0m At episode: 248400, Reward: 0.1 (over 100 episodes)
[32m[0315 21:18:33 @summary_handler.py:102][0m Length: 22.14
[32m[0315 21:18:34 @network.py:203][0m step: 198500, current TD loss: 0.0168653652072
[32m[0315 21:18:36 @network.py:203][0m step: 198600, current TD loss: 0.00191532820463
[32m[0315 21:18:37 @network.py:203][0m step: 198700, current TD loss: 0.00172968930565
[32m[0315 21:18:38 @network.py:203][0m step: 198800, current TD loss: 0.00176531344187
[32m[0315 21:18:39 @network.py:203][0m step: 198900, current TD loss: 0.00276539986953
[32m[0315 21:18:41 @dqn_agent.py:203][0m episode: 11022, total game step: 249000, epsilon: 0.80299099
[32m[0315 21:18:41 @network.py:203][0m step: 199000, current TD loss: 0.000982956727967
[32m[0315 21:18:42 @network.py:203][0m step: 199100, current TD loss: 0.00100850954186
[32m[0315 21:18:44 @network.py:203][0m step: 199200, current TD loss: 7.90935882833e-05
[32m[0315 21:18:45 @network.py:203][0m step: 199300, current TD loss: 0.00288432883099
[32m[0315 21:18:46 @network.py:203][0m step: 199400, current TD loss: 0.0165806431323
[32m[0315 21:18:48 @network.py:203][0m step: 199500, current TD loss: 0.00166233803611
[32m[0315 21:18:49 @network.py:203][0m step: 199600, current TD loss: 0.00184004171751
[32m[0315 21:18:50 @network.py:203][0m step: 199700, current TD loss: 0.00207354128361
[32m[0315 21:18:51 @network.py:203][0m step: 199800, current TD loss: 0.0170042440295
[32m[0315 21:18:53 @network.py:203][0m step: 199900, current TD loss: 0.00383783085272
[32m[0315 21:18:54 @dqn_agent.py:203][0m episode: 11065, total game step: 250000, epsilon: 0.80200099
[32m[0315 21:18:54 @network.py:203][0m step: 200000, current TD loss: 0.00119324307889
[32m[0315 21:18:54 @dqn_agent.py:216][0m At time step 200000, the target_network is updated
[32m[0315 21:18:56 @network.py:203][0m step: 200100, current TD loss: 0.00399080105126
[32m[0315 21:18:57 @network.py:203][0m step: 200200, current TD loss: 3.15697761835e-05
[32m[0315 21:18:58 @network.py:203][0m step: 200300, current TD loss: 3.33317657351e-05
[32m[0315 21:18:59 @network.py:203][0m step: 200400, current TD loss: 0.00266040163115
[32m[0315 21:19:01 @network.py:203][0m step: 200500, current TD loss: 0.000921282393392
[32m[0315 21:19:02 @network.py:203][0m step: 200600, current TD loss: 0.0160721503198
[32m[0315 21:19:04 @network.py:203][0m step: 200700, current TD loss: 4.67096324428e-05
[32m[0315 21:19:05 @network.py:203][0m step: 200800, current TD loss: 0.0156233925372
[32m[0315 21:19:05 @summary_handler.py:101][0m At episode: 250859, Reward: 0.14 (over 100 episodes)
[32m[0315 21:19:05 @summary_handler.py:102][0m Length: 24.59
[32m[0315 21:19:06 @network.py:203][0m step: 200900, current TD loss: 0.0168166682124
[32m[0315 21:19:07 @dqn_agent.py:203][0m episode: 11104, total game step: 251000, epsilon: 0.80101099
[32m[0315 21:19:07 @network.py:203][0m step: 201000, current TD loss: 6.909941294e-05
[32m[0315 21:19:09 @network.py:203][0m step: 201100, current TD loss: 0.00231077987701
[32m[0315 21:19:10 @network.py:203][0m step: 201200, current TD loss: 0.00090268230997
[32m[0315 21:19:11 @network.py:203][0m step: 201300, current TD loss: 0.00264212093316
[32m[0315 21:19:13 @network.py:203][0m step: 201400, current TD loss: 0.00279696541838
[32m[0315 21:19:14 @network.py:203][0m step: 201500, current TD loss: 0.00333249079995
[32m[0315 21:19:15 @network.py:203][0m step: 201600, current TD loss: 0.0168160274625
[32m[0315 21:19:17 @network.py:203][0m step: 201700, current TD loss: 0.00172980246134
[32m[0315 21:19:18 @network.py:203][0m step: 201800, current TD loss: 0.00164829660207
[32m[0315 21:19:19 @network.py:203][0m step: 201900, current TD loss: 0.00198776600882
[32m[0315 21:19:20 @dqn_agent.py:203][0m episode: 11138, total game step: 252000, epsilon: 0.80002099
[32m[0315 21:19:20 @network.py:203][0m step: 202000, current TD loss: 0.000232346734265
[32m[0315 21:19:22 @network.py:203][0m step: 202100, current TD loss: 0.0192359983921
[32m[0315 21:19:23 @network.py:203][0m step: 202200, current TD loss: 0.00180591340177
[32m[0315 21:19:24 @network.py:203][0m step: 202300, current TD loss: 0.00184800208081
[32m[0315 21:19:26 @network.py:203][0m step: 202400, current TD loss: 0.00495653599501
[32m[0315 21:19:27 @network.py:203][0m step: 202500, current TD loss: 0.0149048147723
[32m[0315 21:19:27 @dqn_agent.py:216][0m At time step 202500, the target_network is updated
[32m[0315 21:19:28 @network.py:203][0m step: 202600, current TD loss: 0.000948013097513
[32m[0315 21:19:30 @network.py:203][0m step: 202700, current TD loss: 0.000129547697725
[32m[0315 21:19:31 @network.py:203][0m step: 202800, current TD loss: 0.00244251615368
[32m[0315 21:19:32 @network.py:203][0m step: 202900, current TD loss: 0.00184303114656
[32m[0315 21:19:34 @dqn_agent.py:203][0m episode: 11183, total game step: 253000, epsilon: 0.79903099
[32m[0315 21:19:34 @network.py:203][0m step: 203000, current TD loss: 0.0010367546929
[32m[0315 21:19:35 @network.py:203][0m step: 203100, current TD loss: 0.0019789240323
[32m[0315 21:19:36 @network.py:203][0m step: 203200, current TD loss: 0.00302164582536
[32m[0315 21:19:38 @network.py:203][0m step: 203300, current TD loss: 0.000430416374002
[32m[0315 21:19:39 @network.py:203][0m step: 203400, current TD loss: 0.000135694615892
[32m[0315 21:19:39 @summary_handler.py:101][0m At episode: 253426, Reward: 0.21 (over 100 episodes)
[32m[0315 21:19:39 @summary_handler.py:102][0m Length: 25.67
[32m[0315 21:19:40 @network.py:203][0m step: 203500, current TD loss: 0.000817079562694
[32m[0315 21:19:42 @network.py:203][0m step: 203600, current TD loss: 0.00141473521944
[32m[0315 21:19:43 @network.py:203][0m step: 203700, current TD loss: 0.029104616493
[32m[0315 21:19:44 @network.py:203][0m step: 203800, current TD loss: 0.00261258939281
[32m[0315 21:19:46 @network.py:203][0m step: 203900, current TD loss: 0.00268224417232
[32m[0315 21:19:47 @dqn_agent.py:203][0m episode: 11226, total game step: 254000, epsilon: 0.79804099
[32m[0315 21:19:47 @network.py:203][0m step: 204000, current TD loss: 0.00096119788941
[32m[0315 21:19:48 @network.py:203][0m step: 204100, current TD loss: 0.00280988588929
[32m[0315 21:19:50 @network.py:203][0m step: 204200, current TD loss: 0.00101027323399
[32m[0315 21:19:51 @network.py:203][0m step: 204300, current TD loss: 0.00226650456898
[32m[0315 21:19:52 @network.py:203][0m step: 204400, current TD loss: 0.00108906405512
[32m[0315 21:19:53 @network.py:203][0m step: 204500, current TD loss: 0.000944865983911
[32m[0315 21:19:55 @network.py:203][0m step: 204600, current TD loss: 0.000872188073117
[32m[0315 21:19:56 @network.py:203][0m step: 204700, current TD loss: 0.0022280884441
[32m[0315 21:19:58 @network.py:203][0m step: 204800, current TD loss: 0.00311591173522
[32m[0315 21:19:59 @network.py:203][0m step: 204900, current TD loss: 0.00173219258431
[32m[0315 21:20:00 @dqn_agent.py:203][0m episode: 11256, total game step: 255000, epsilon: 0.79705099
[32m[0315 21:20:00 @network.py:203][0m step: 205000, current TD loss: 0.00178476865403
[32m[0315 21:20:00 @dqn_agent.py:216][0m At time step 205000, the target_network is updated
[32m[0315 21:20:01 @network.py:203][0m step: 205100, current TD loss: 0.00267185992561
[32m[0315 21:20:03 @network.py:203][0m step: 205200, current TD loss: 0.00345505098812
[32m[0315 21:20:04 @network.py:203][0m step: 205300, current TD loss: 0.000161279662279
[32m[0315 21:20:05 @network.py:203][0m step: 205400, current TD loss: 0.000853250036016
[32m[0315 21:20:07 @network.py:203][0m step: 205500, current TD loss: 0.0345591194928
[32m[0315 21:20:08 @network.py:203][0m step: 205600, current TD loss: 0.0023647272028
[32m[0315 21:20:09 @network.py:203][0m step: 205700, current TD loss: 0.00316459382884
[32m[0315 21:20:11 @network.py:203][0m step: 205800, current TD loss: 0.00131756230257
[32m[0315 21:20:12 @network.py:203][0m step: 205900, current TD loss: 8.59012725414e-05
[32m[0315 21:20:14 @dqn_agent.py:203][0m episode: 11297, total game step: 256000, epsilon: 0.79606099
[32m[0315 21:20:14 @network.py:203][0m step: 206000, current TD loss: 0.00278640375473
[32m[0315 21:20:15 @summary_handler.py:101][0m At episode: 256097, Reward: 0.25 (over 100 episodes)
[32m[0315 21:20:15 @summary_handler.py:102][0m Length: 26.71
[32m[0315 21:20:15 @network.py:203][0m step: 206100, current TD loss: 0.0220761206001
[32m[0315 21:20:16 @network.py:203][0m step: 206200, current TD loss: 0.000134316025651
[32m[0315 21:20:18 @network.py:203][0m step: 206300, current TD loss: 0.000945501378737
[32m[0315 21:20:19 @network.py:203][0m step: 206400, current TD loss: 0.0015237829648
[32m[0315 21:20:20 @network.py:203][0m step: 206500, current TD loss: 0.0012650473509
[32m[0315 21:20:22 @network.py:203][0m step: 206600, current TD loss: 0.00299868430011
[32m[0315 21:20:23 @network.py:203][0m step: 206700, current TD loss: 0.0180805623531
[32m[0315 21:20:24 @network.py:203][0m step: 206800, current TD loss: 0.000893943069968
[32m[0315 21:20:26 @network.py:203][0m step: 206900, current TD loss: 0.00206436309963
[32m[0315 21:20:27 @dqn_agent.py:203][0m episode: 11343, total game step: 257000, epsilon: 0.79507099
[32m[0315 21:20:27 @network.py:203][0m step: 207000, current TD loss: 0.0136977406219
[32m[0315 21:20:28 @network.py:203][0m step: 207100, current TD loss: 0.00404097419232
[32m[0315 21:20:29 @network.py:203][0m step: 207200, current TD loss: 0.015484505333
[32m[0315 21:20:31 @network.py:203][0m step: 207300, current TD loss: 0.0326455011964
[32m[0315 21:20:32 @network.py:203][0m step: 207400, current TD loss: 0.00192282232456
[32m[0315 21:20:34 @network.py:203][0m step: 207500, current TD loss: 0.00409849174321
[32m[0315 21:20:34 @dqn_agent.py:216][0m At time step 207500, the target_network is updated
[32m[0315 21:20:35 @network.py:203][0m step: 207600, current TD loss: 0.0030522774905
[32m[0315 21:20:36 @network.py:203][0m step: 207700, current TD loss: 0.00102108309511
[32m[0315 21:20:38 @network.py:203][0m step: 207800, current TD loss: 0.0041560032405
[32m[0315 21:20:39 @network.py:203][0m step: 207900, current TD loss: 0.00144803151488
[32m[0315 21:20:40 @dqn_agent.py:203][0m episode: 11387, total game step: 258000, epsilon: 0.79408099
[32m[0315 21:20:40 @network.py:203][0m step: 208000, current TD loss: 6.80075172568e-05
[32m[0315 21:20:42 @network.py:203][0m step: 208100, current TD loss: 0.0161377284676
[32m[0315 21:20:43 @network.py:203][0m step: 208200, current TD loss: 0.00298051466234
[32m[0315 21:20:44 @network.py:203][0m step: 208300, current TD loss: 0.00421950453892
[32m[0315 21:20:45 @summary_handler.py:101][0m At episode: 258330, Reward: 0.13 (over 100 episodes)
[32m[0315 21:20:45 @summary_handler.py:102][0m Length: 22.33
[32m[0315 21:20:45 @network.py:203][0m step: 208400, current TD loss: 0.00145195482764
[32m[0315 21:20:47 @network.py:203][0m step: 208500, current TD loss: 0.00100107525941
[32m[0315 21:20:48 @network.py:203][0m step: 208600, current TD loss: 0.000115917275252
[32m[0315 21:20:49 @network.py:203][0m step: 208700, current TD loss: 0.00154177984223
[32m[0315 21:20:51 @network.py:203][0m step: 208800, current TD loss: 0.00247599300928
[32m[0315 21:20:52 @network.py:203][0m step: 208900, current TD loss: 0.00249074609019
[32m[0315 21:20:53 @dqn_agent.py:203][0m episode: 11424, total game step: 259000, epsilon: 0.79309099
[32m[0315 21:20:53 @network.py:203][0m step: 209000, current TD loss: 0.000662846781779
[32m[0315 21:20:55 @network.py:203][0m step: 209100, current TD loss: 0.00225009070709
[32m[0315 21:20:56 @network.py:203][0m step: 209200, current TD loss: 0.00103555293754
[32m[0315 21:20:57 @network.py:203][0m step: 209300, current TD loss: 0.000776252709329
[32m[0315 21:20:59 @network.py:203][0m step: 209400, current TD loss: 0.00106332602445
[32m[0315 21:21:00 @network.py:203][0m step: 209500, current TD loss: 0.0324558652937
[32m[0315 21:21:01 @network.py:203][0m step: 209600, current TD loss: 0.00259047560394
[32m[0315 21:21:03 @network.py:203][0m step: 209700, current TD loss: 0.0166164245456
[32m[0315 21:21:04 @network.py:203][0m step: 209800, current TD loss: 0.00159710180014
[32m[0315 21:21:05 @network.py:203][0m step: 209900, current TD loss: 0.000737819413189
[32m[0315 21:21:07 @dqn_agent.py:203][0m episode: 11474, total game step: 260000, epsilon: 0.79210099
[32m[0315 21:21:07 @network.py:203][0m step: 210000, current TD loss: 0.00235416321084
[32m[0315 21:21:07 @dqn_agent.py:216][0m At time step 210000, the target_network is updated
[32m[0315 21:21:08 @network.py:203][0m step: 210100, current TD loss: 0.00204398250207
[32m[0315 21:21:09 @network.py:203][0m step: 210200, current TD loss: 0.000129261010443
[32m[0315 21:21:11 @network.py:203][0m step: 210300, current TD loss: 0.0173285249621
[32m[0315 21:21:12 @network.py:203][0m step: 210400, current TD loss: 0.0167977120727
[32m[0315 21:21:13 @network.py:203][0m step: 210500, current TD loss: 4.01821926062e-05
[32m[0315 21:21:14 @summary_handler.py:101][0m At episode: 260564, Reward: 0.12 (over 100 episodes)
[32m[0315 21:21:14 @summary_handler.py:102][0m Length: 22.34
[32m[0315 21:21:15 @network.py:203][0m step: 210600, current TD loss: 0.00178888766095
[32m[0315 21:21:16 @network.py:203][0m step: 210700, current TD loss: 0.00170188408811
[32m[0315 21:21:17 @network.py:203][0m step: 210800, current TD loss: 0.00110192061402
[32m[0315 21:21:19 @network.py:203][0m step: 210900, current TD loss: 0.00391149520874
[32m[0315 21:21:20 @dqn_agent.py:203][0m episode: 11513, total game step: 261000, epsilon: 0.79111099
[32m[0315 21:21:20 @network.py:203][0m step: 211000, current TD loss: 0.0150007270277
[32m[0315 21:21:21 @network.py:203][0m step: 211100, current TD loss: 0.0024646287784
[32m[0315 21:21:23 @network.py:203][0m step: 211200, current TD loss: 0.0170641988516
[32m[0315 21:21:24 @network.py:203][0m step: 211300, current TD loss: 0.00230759452097
[32m[0315 21:21:25 @network.py:203][0m step: 211400, current TD loss: 0.000891009054612
[32m[0315 21:21:27 @network.py:203][0m step: 211500, current TD loss: 0.0132099231705
[32m[0315 21:21:28 @network.py:203][0m step: 211600, current TD loss: 0.0216599144042
[32m[0315 21:21:30 @network.py:203][0m step: 211700, current TD loss: 0.00175484223291
[32m[0315 21:21:31 @network.py:203][0m step: 211800, current TD loss: 0.00236050435342
[32m[0315 21:21:32 @network.py:203][0m step: 211900, current TD loss: 0.000925356638618
[32m[0315 21:21:33 @dqn_agent.py:203][0m episode: 11552, total game step: 262000, epsilon: 0.79012099
[32m[0315 21:21:33 @network.py:203][0m step: 212000, current TD loss: 0.0155243352056
[32m[0315 21:21:35 @network.py:203][0m step: 212100, current TD loss: 0.00472955964506
[32m[0315 21:21:36 @network.py:203][0m step: 212200, current TD loss: 0.00154445855878
[32m[0315 21:21:37 @network.py:203][0m step: 212300, current TD loss: 0.00102815113496
[32m[0315 21:21:39 @network.py:203][0m step: 212400, current TD loss: 0.00192521256395
[32m[0315 21:21:40 @network.py:203][0m step: 212500, current TD loss: 9.99938783934e-05
[32m[0315 21:21:40 @dqn_agent.py:216][0m At time step 212500, the target_network is updated
[32m[0315 21:21:41 @network.py:203][0m step: 212600, current TD loss: 0.00248578796163
[32m[0315 21:21:43 @network.py:203][0m step: 212700, current TD loss: 0.00499468436465
[32m[0315 21:21:44 @network.py:203][0m step: 212800, current TD loss: 0.00136716722045
[32m[0315 21:21:45 @network.py:203][0m step: 212900, current TD loss: 0.00112379260827
[32m[0315 21:21:47 @dqn_agent.py:203][0m episode: 11593, total game step: 263000, epsilon: 0.78913099
[32m[0315 21:21:47 @network.py:203][0m step: 213000, current TD loss: 0.00087002129294
[32m[0315 21:21:48 @network.py:203][0m step: 213100, current TD loss: 0.00101354660001
[32m[0315 21:21:49 @summary_handler.py:101][0m At episode: 263183, Reward: 0.17 (over 100 episodes)
[32m[0315 21:21:49 @summary_handler.py:102][0m Length: 26.19
[32m[0315 21:21:49 @network.py:203][0m step: 213200, current TD loss: 0.00100209540688
[32m[0315 21:21:51 @network.py:203][0m step: 213300, current TD loss: 4.33218738181e-05
[32m[0315 21:21:52 @network.py:203][0m step: 213400, current TD loss: 0.000142792981933
[32m[0315 21:21:53 @network.py:203][0m step: 213500, current TD loss: 0.015382738784
[32m[0315 21:21:55 @network.py:203][0m step: 213600, current TD loss: 0.0159016810358
[32m[0315 21:21:56 @network.py:203][0m step: 213700, current TD loss: 0.00279128691182
[32m[0315 21:21:57 @network.py:203][0m step: 213800, current TD loss: 0.00124492158648
[32m[0315 21:21:59 @network.py:203][0m step: 213900, current TD loss: 0.0185107495636
[32m[0315 21:22:00 @dqn_agent.py:203][0m episode: 11636, total game step: 264000, epsilon: 0.78814099
[32m[0315 21:22:00 @network.py:203][0m step: 214000, current TD loss: 0.0255639366806
[32m[0315 21:22:01 @network.py:203][0m step: 214100, current TD loss: 0.0155252544209
[32m[0315 21:22:03 @network.py:203][0m step: 214200, current TD loss: 0.0166972931474
[32m[0315 21:22:04 @network.py:203][0m step: 214300, current TD loss: 0.0180392153561
[32m[0315 21:22:05 @network.py:203][0m step: 214400, current TD loss: 0.0197010170668
[32m[0315 21:22:07 @network.py:203][0m step: 214500, current TD loss: 0.00182190653868
[32m[0315 21:22:08 @network.py:203][0m step: 214600, current TD loss: 0.000369962188415
[32m[0315 21:22:09 @network.py:203][0m step: 214700, current TD loss: 0.00176335545257
[32m[0315 21:22:11 @network.py:203][0m step: 214800, current TD loss: 0.000979747390375
[32m[0315 21:22:12 @network.py:203][0m step: 214900, current TD loss: 0.00273806927726
[32m[0315 21:22:13 @dqn_agent.py:203][0m episode: 11678, total game step: 265000, epsilon: 0.78715099
[32m[0315 21:22:13 @network.py:203][0m step: 215000, current TD loss: 0.00102791481186
[32m[0315 21:22:13 @dqn_agent.py:216][0m At time step 215000, the target_network is updated
[32m[0315 21:22:15 @network.py:203][0m step: 215100, current TD loss: 0.0153355197981
[32m[0315 21:22:16 @network.py:203][0m step: 215200, current TD loss: 0.00207056012005
[32m[0315 21:22:17 @network.py:203][0m step: 215300, current TD loss: 0.0162878967822
[32m[0315 21:22:18 @summary_handler.py:101][0m At episode: 265378, Reward: 0.11 (over 100 episodes)
[32m[0315 21:22:18 @summary_handler.py:102][0m Length: 21.95
[32m[0315 21:22:19 @network.py:203][0m step: 215400, current TD loss: 0.0144293364137
[32m[0315 21:22:20 @network.py:203][0m step: 215500, current TD loss: 0.00324760191143
[32m[0315 21:22:22 @network.py:203][0m step: 215600, current TD loss: 0.00586619600654
[32m[0315 21:22:23 @network.py:203][0m step: 215700, current TD loss: 0.00344978598878
[32m[0315 21:22:24 @network.py:203][0m step: 215800, current TD loss: 0.000582498381846
[32m[0315 21:22:26 @network.py:203][0m step: 215900, current TD loss: 0.0156843848526
[32m[0315 21:22:27 @dqn_agent.py:203][0m episode: 11728, total game step: 266000, epsilon: 0.78616099
[32m[0315 21:22:27 @network.py:203][0m step: 216000, current TD loss: 0.00389087153599
[32m[0315 21:22:28 @network.py:203][0m step: 216100, current TD loss: 0.00528957974166
[32m[0315 21:22:30 @network.py:203][0m step: 216200, current TD loss: 0.000923285377212
[32m[0315 21:22:31 @network.py:203][0m step: 216300, current TD loss: 0.00181096268352
[32m[0315 21:22:32 @network.py:203][0m step: 216400, current TD loss: 0.00202497234568
[32m[0315 21:22:34 @network.py:203][0m step: 216500, current TD loss: 0.00332816783339
[32m[0315 21:22:35 @network.py:203][0m step: 216600, current TD loss: 0.0178253017366
[32m[0315 21:22:36 @network.py:203][0m step: 216700, current TD loss: 0.00150940427557
[32m[0315 21:22:38 @network.py:203][0m step: 216800, current TD loss: 0.00119721947704
[32m[0315 21:22:39 @network.py:203][0m step: 216900, current TD loss: 0.0018335187342
[32m[0315 21:22:40 @dqn_agent.py:203][0m episode: 11775, total game step: 267000, epsilon: 0.78517099
[32m[0315 21:22:40 @network.py:203][0m step: 217000, current TD loss: 0.00115787854884
[32m[0315 21:22:42 @network.py:203][0m step: 217100, current TD loss: 0.00201366050169
[32m[0315 21:22:43 @network.py:203][0m step: 217200, current TD loss: 0.00101244286634
[32m[0315 21:22:44 @network.py:203][0m step: 217300, current TD loss: 0.000145518773934
[32m[0315 21:22:46 @network.py:203][0m step: 217400, current TD loss: 0.0181435160339
[32m[0315 21:22:47 @network.py:203][0m step: 217500, current TD loss: 0.00291717262007
[32m[0315 21:22:47 @dqn_agent.py:216][0m At time step 217500, the target_network is updated
[32m[0315 21:22:47 @summary_handler.py:101][0m At episode: 267527, Reward: 0.15 (over 100 episodes)
[32m[0315 21:22:47 @summary_handler.py:102][0m Length: 21.49
[32m[0315 21:22:48 @network.py:203][0m step: 217600, current TD loss: 0.00106691161636
[32m[0315 21:22:50 @network.py:203][0m step: 217700, current TD loss: 0.00186141335871
[32m[0315 21:22:51 @network.py:203][0m step: 217800, current TD loss: 0.00435313675553
[32m[0315 21:22:53 @network.py:203][0m step: 217900, current TD loss: 0.0028522007633
[32m[0315 21:22:54 @dqn_agent.py:203][0m episode: 11824, total game step: 268000, epsilon: 0.78418099
[32m[0315 21:22:54 @network.py:203][0m step: 218000, current TD loss: 0.0184902995825
[32m[0315 21:22:55 @network.py:203][0m step: 218100, current TD loss: 0.00320260040462
[32m[0315 21:22:57 @network.py:203][0m step: 218200, current TD loss: 0.0032540014945
[32m[0315 21:22:58 @network.py:203][0m step: 218300, current TD loss: 0.00290308473632
[32m[0315 21:22:59 @network.py:203][0m step: 218400, current TD loss: 0.000879870785866
[32m[0315 21:23:01 @network.py:203][0m step: 218500, current TD loss: 0.00170555594377
[32m[0315 21:23:02 @network.py:203][0m step: 218600, current TD loss: 0.00221182359383
[32m[0315 21:23:03 @network.py:203][0m step: 218700, current TD loss: 0.00450177351013
[32m[0315 21:23:05 @network.py:203][0m step: 218800, current TD loss: 0.000822724658065
[32m[0315 21:23:06 @network.py:203][0m step: 218900, current TD loss: 8.20067725726e-05
[32m[0315 21:23:08 @dqn_agent.py:203][0m episode: 11872, total game step: 269000, epsilon: 0.78319099
[32m[0315 21:23:08 @network.py:203][0m step: 219000, current TD loss: 0.0050052171573
[32m[0315 21:23:09 @network.py:203][0m step: 219100, current TD loss: 0.00114549626596
[32m[0315 21:23:10 @network.py:203][0m step: 219200, current TD loss: 0.000310263974825
[32m[0315 21:23:12 @network.py:203][0m step: 219300, current TD loss: 0.019170878455
[32m[0315 21:23:13 @network.py:203][0m step: 219400, current TD loss: 0.00529457209632
[32m[0315 21:23:14 @network.py:203][0m step: 219500, current TD loss: 0.0179721657187
[32m[0315 21:23:16 @network.py:203][0m step: 219600, current TD loss: 0.00426747277379
[32m[0315 21:23:17 @summary_handler.py:101][0m At episode: 269693, Reward: 0.15 (over 100 episodes)
[32m[0315 21:23:17 @summary_handler.py:102][0m Length: 21.66
[32m[0315 21:23:17 @network.py:203][0m step: 219700, current TD loss: 8.06001480669e-05
[32m[0315 21:23:18 @network.py:203][0m step: 219800, current TD loss: 0.00365392584354
[32m[0315 21:23:20 @network.py:203][0m step: 219900, current TD loss: 0.00159923592582
[32m[0315 21:23:21 @dqn_agent.py:203][0m episode: 11910, total game step: 270000, epsilon: 0.78220099
[32m[0315 21:23:21 @network.py:203][0m step: 220000, current TD loss: 0.00164994876832
[32m[0315 21:23:21 @dqn_agent.py:216][0m At time step 220000, the target_network is updated
[32m[0315 21:23:22 @network.py:203][0m step: 220100, current TD loss: 0.00225012516603
[32m[0315 21:23:24 @network.py:203][0m step: 220200, current TD loss: 0.0165168885142
[32m[0315 21:23:25 @network.py:203][0m step: 220300, current TD loss: 0.00319590233266
[32m[0315 21:23:26 @network.py:203][0m step: 220400, current TD loss: 0.0117654129863
[32m[0315 21:23:28 @network.py:203][0m step: 220500, current TD loss: 0.0171332210302
[32m[0315 21:23:29 @network.py:203][0m step: 220600, current TD loss: 0.000158807612024
[32m[0315 21:23:30 @network.py:203][0m step: 220700, current TD loss: 0.0163737274706
[32m[0315 21:23:32 @network.py:203][0m step: 220800, current TD loss: 0.00125953438692
[32m[0315 21:23:33 @network.py:203][0m step: 220900, current TD loss: 0.000260530039668
[32m[0315 21:23:34 @dqn_agent.py:203][0m episode: 11949, total game step: 271000, epsilon: 0.78121099
[32m[0315 21:23:34 @network.py:203][0m step: 221000, current TD loss: 0.000164990357007
[32m[0315 21:23:36 @network.py:203][0m step: 221100, current TD loss: 0.00327002350241
[32m[0315 21:23:37 @network.py:203][0m step: 221200, current TD loss: 0.0030031115748
[32m[0315 21:23:38 @network.py:203][0m step: 221300, current TD loss: 0.0173182487488
[32m[0315 21:23:40 @network.py:203][0m step: 221400, current TD loss: 0.00344990589656
[32m[0315 21:23:41 @network.py:203][0m step: 221500, current TD loss: 0.00142468244303
[32m[0315 21:23:42 @network.py:203][0m step: 221600, current TD loss: 0.00190541858319
[32m[0315 21:23:44 @network.py:203][0m step: 221700, current TD loss: 0.00028051744448
[32m[0315 21:23:45 @network.py:203][0m step: 221800, current TD loss: 0.00171378941741
[32m[0315 21:23:46 @network.py:203][0m step: 221900, current TD loss: 0.0148667050526
[32m[0315 21:23:47 @dqn_agent.py:203][0m episode: 11996, total game step: 272000, epsilon: 0.78022099
[32m[0315 21:23:47 @network.py:203][0m step: 222000, current TD loss: 0.00168802996632
[32m[0315 21:23:49 @network.py:203][0m step: 222100, current TD loss: 0.00112717680167
[32m[0315 21:23:49 @summary_handler.py:101][0m At episode: 272114, Reward: 0.16 (over 100 episodes)
[32m[0315 21:23:49 @summary_handler.py:102][0m Length: 24.21
[32m[0315 21:23:50 @network.py:203][0m step: 222200, current TD loss: 0.00377379124984
[32m[0315 21:23:52 @network.py:203][0m step: 222300, current TD loss: 0.0050210384652
[32m[0315 21:23:53 @network.py:203][0m step: 222400, current TD loss: 0.00234689074568
[32m[0315 21:23:54 @network.py:203][0m step: 222500, current TD loss: 0.00184680265374
[32m[0315 21:23:54 @dqn_agent.py:216][0m At time step 222500, the target_network is updated
[32m[0315 21:23:56 @network.py:203][0m step: 222600, current TD loss: 0.00121121841948
[32m[0315 21:23:57 @network.py:203][0m step: 222700, current TD loss: 0.00303905969486
[32m[0315 21:23:58 @network.py:203][0m step: 222800, current TD loss: 0.00146055384539
[32m[0315 21:24:00 @network.py:203][0m step: 222900, current TD loss: 0.00221816450357
[32m[0315 21:24:01 @dqn_agent.py:203][0m episode: 12048, total game step: 273000, epsilon: 0.77923099
[32m[0315 21:24:01 @network.py:203][0m step: 223000, current TD loss: 0.020596049726
[32m[0315 21:24:03 @network.py:203][0m step: 223100, current TD loss: 0.00247370870784
[32m[0315 21:24:04 @network.py:203][0m step: 223200, current TD loss: 0.00221807556227
[32m[0315 21:24:05 @network.py:203][0m step: 223300, current TD loss: 0.00227070995606
[32m[0315 21:24:07 @network.py:203][0m step: 223400, current TD loss: 0.00216451426968
[32m[0315 21:24:08 @network.py:203][0m step: 223500, current TD loss: 0.00166439509485
[32m[0315 21:24:09 @network.py:203][0m step: 223600, current TD loss: 0.00423632608727
[32m[0315 21:24:11 @network.py:203][0m step: 223700, current TD loss: 0.00297645479441
[32m[0315 21:24:12 @network.py:203][0m step: 223800, current TD loss: 0.0194957517087
[32m[0315 21:24:13 @network.py:203][0m step: 223900, current TD loss: 0.00230162451044
[32m[0315 21:24:14 @dqn_agent.py:203][0m episode: 12091, total game step: 274000, epsilon: 0.77824099
[32m[0315 21:24:14 @network.py:203][0m step: 224000, current TD loss: 0.00967045128345
[32m[0315 21:24:16 @network.py:203][0m step: 224100, current TD loss: 0.0168916340917
[32m[0315 21:24:17 @summary_handler.py:101][0m At episode: 274151, Reward: 0.07 (over 100 episodes)
[32m[0315 21:24:17 @summary_handler.py:102][0m Length: 20.37
[32m[0315 21:24:17 @network.py:203][0m step: 224200, current TD loss: 0.0343763120472
[32m[0315 21:24:19 @network.py:203][0m step: 224300, current TD loss: 0.00312729738653
[32m[0315 21:24:20 @network.py:203][0m step: 224400, current TD loss: 0.0172134004533
[32m[0315 21:24:21 @network.py:203][0m step: 224500, current TD loss: 0.00163264432922
[32m[0315 21:24:23 @network.py:203][0m step: 224600, current TD loss: 0.0021374875214
[32m[0315 21:24:24 @network.py:203][0m step: 224700, current TD loss: 0.0145308747888
[32m[0315 21:24:25 @network.py:203][0m step: 224800, current TD loss: 0.00618022680283
[32m[0315 21:24:27 @network.py:203][0m step: 224900, current TD loss: 0.00414113514125
[32m[0315 21:24:28 @dqn_agent.py:203][0m episode: 12141, total game step: 275000, epsilon: 0.77725099
[32m[0315 21:24:28 @network.py:203][0m step: 225000, current TD loss: 0.00111218774691
[32m[0315 21:24:28 @dqn_agent.py:216][0m At time step 225000, the target_network is updated
[32m[0315 21:24:29 @network.py:203][0m step: 225100, current TD loss: 0.00146002485417
[32m[0315 21:24:31 @network.py:203][0m step: 225200, current TD loss: 0.0091214729473
[32m[0315 21:24:32 @network.py:203][0m step: 225300, current TD loss: 0.0012097931467
[32m[0315 21:24:33 @network.py:203][0m step: 225400, current TD loss: 0.0145365847275
[32m[0315 21:24:35 @network.py:203][0m step: 225500, current TD loss: 0.0028814538382
[32m[0315 21:24:36 @network.py:203][0m step: 225600, current TD loss: 0.00166409404483
[32m[0315 21:24:37 @network.py:203][0m step: 225700, current TD loss: 0.00224381801672
[32m[0315 21:24:39 @network.py:203][0m step: 225800, current TD loss: 0.0186245776713
[32m[0315 21:24:40 @network.py:203][0m step: 225900, current TD loss: 0.0202053561807
[32m[0315 21:24:41 @dqn_agent.py:203][0m episode: 12184, total game step: 276000, epsilon: 0.77626099
[32m[0315 21:24:42 @network.py:203][0m step: 226000, current TD loss: 0.000322584673995
[32m[0315 21:24:43 @network.py:203][0m step: 226100, current TD loss: 0.000977215240709
[32m[0315 21:24:44 @network.py:203][0m step: 226200, current TD loss: 0.0253229402006
[32m[0315 21:24:45 @network.py:203][0m step: 226300, current TD loss: 0.000471650710097
[32m[0315 21:24:46 @summary_handler.py:101][0m At episode: 276331, Reward: 0.11 (over 100 episodes)
[32m[0315 21:24:46 @summary_handler.py:102][0m Length: 21.8
[32m[0315 21:24:47 @network.py:203][0m step: 226400, current TD loss: 0.000852072262205
[32m[0315 21:24:48 @network.py:203][0m step: 226500, current TD loss: 0.00168828933965
[32m[0315 21:24:50 @network.py:203][0m step: 226600, current TD loss: 0.00401522126049
[32m[0315 21:24:51 @network.py:203][0m step: 226700, current TD loss: 0.00142847595271
[32m[0315 21:24:52 @network.py:203][0m step: 226800, current TD loss: 0.0157257542014
[32m[0315 21:24:54 @network.py:203][0m step: 226900, current TD loss: 0.0155425062403
[32m[0315 21:24:55 @dqn_agent.py:203][0m episode: 12229, total game step: 277000, epsilon: 0.77527099
[32m[0315 21:24:55 @network.py:203][0m step: 227000, current TD loss: 0.0100158248097
[32m[0315 21:24:56 @network.py:203][0m step: 227100, current TD loss: 0.00238361954689
[32m[0315 21:24:58 @network.py:203][0m step: 227200, current TD loss: 0.0108509175479
[32m[0315 21:24:59 @network.py:203][0m step: 227300, current TD loss: 0.0172830913216
[32m[0315 21:25:00 @network.py:203][0m step: 227400, current TD loss: 0.00231356942095
[32m[0315 21:25:02 @network.py:203][0m step: 227500, current TD loss: 0.00429958989844
[32m[0315 21:25:02 @dqn_agent.py:216][0m At time step 227500, the target_network is updated
[32m[0315 21:25:03 @network.py:203][0m step: 227600, current TD loss: 0.00250110868365
[32m[0315 21:25:05 @network.py:203][0m step: 227700, current TD loss: 0.00265012402087
[32m[0315 21:25:06 @network.py:203][0m step: 227800, current TD loss: 0.00026777893072
[32m[0315 21:25:07 @network.py:203][0m step: 227900, current TD loss: 0.00213981745765
[32m[0315 21:25:09 @dqn_agent.py:203][0m episode: 12277, total game step: 278000, epsilon: 0.77428099
[32m[0315 21:25:09 @network.py:203][0m step: 228000, current TD loss: 0.0172814857215
[32m[0315 21:25:10 @network.py:203][0m step: 228100, current TD loss: 0.00168333516922
[32m[0315 21:25:11 @network.py:203][0m step: 228200, current TD loss: 0.0037117539905
[32m[0315 21:25:13 @network.py:203][0m step: 228300, current TD loss: 0.000591753050685
[32m[0315 21:25:14 @network.py:203][0m step: 228400, current TD loss: 0.0105773359537
[32m[0315 21:25:14 @summary_handler.py:101][0m At episode: 278408, Reward: 0.1 (over 100 episodes)
[32m[0315 21:25:14 @summary_handler.py:102][0m Length: 20.77
[32m[0315 21:25:15 @network.py:203][0m step: 228500, current TD loss: 0.00159090699162
[32m[0315 21:25:17 @network.py:203][0m step: 228600, current TD loss: 0.000254290760495
[32m[0315 21:25:18 @network.py:203][0m step: 228700, current TD loss: 0.00223305867985
[32m[0315 21:25:19 @network.py:203][0m step: 228800, current TD loss: 0.00178267247975
[32m[0315 21:25:21 @network.py:203][0m step: 228900, current TD loss: 0.000782624236308
[32m[0315 21:25:22 @dqn_agent.py:203][0m episode: 12322, total game step: 279000, epsilon: 0.77329099
[32m[0315 21:25:22 @network.py:203][0m step: 229000, current TD loss: 0.0012311617611
[32m[0315 21:25:23 @network.py:203][0m step: 229100, current TD loss: 0.00167079130188
[32m[0315 21:25:25 @network.py:203][0m step: 229200, current TD loss: 0.00216733524576
[32m[0315 21:25:26 @network.py:203][0m step: 229300, current TD loss: 0.000714598805644
[32m[0315 21:25:27 @network.py:203][0m step: 229400, current TD loss: 0.0016679125838
[32m[0315 21:25:29 @network.py:203][0m step: 229500, current TD loss: 0.0161825679243
[32m[0315 21:25:30 @network.py:203][0m step: 229600, current TD loss: 0.000704583246261
[32m[0315 21:25:32 @network.py:203][0m step: 229700, current TD loss: 0.00286195077933
[32m[0315 21:25:33 @network.py:203][0m step: 229800, current TD loss: 0.0013754714746
[32m[0315 21:25:34 @network.py:203][0m step: 229900, current TD loss: 0.0123057886958
[32m[0315 21:25:35 @dqn_agent.py:203][0m episode: 12372, total game step: 280000, epsilon: 0.77230099
[32m[0315 21:25:35 @network.py:203][0m step: 230000, current TD loss: 0.000420436321292
[32m[0315 21:25:35 @dqn_agent.py:216][0m At time step 230000, the target_network is updated
[32m[0315 21:25:37 @network.py:203][0m step: 230100, current TD loss: 0.00258767511696
[32m[0315 21:25:38 @network.py:203][0m step: 230200, current TD loss: 0.000922933453694
[32m[0315 21:25:40 @network.py:203][0m step: 230300, current TD loss: 0.00390432402492
[32m[0315 21:25:41 @network.py:203][0m step: 230400, current TD loss: 0.0145371928811
[32m[0315 21:25:42 @network.py:203][0m step: 230500, current TD loss: 0.0161366183311
[32m[0315 21:25:43 @summary_handler.py:101][0m At episode: 280543, Reward: 0.14 (over 100 episodes)
[32m[0315 21:25:43 @summary_handler.py:102][0m Length: 21.35
[32m[0315 21:25:44 @network.py:203][0m step: 230600, current TD loss: 0.00168086308986
[32m[0315 21:25:45 @network.py:203][0m step: 230700, current TD loss: 0.00139123282861
[32m[0315 21:25:46 @network.py:203][0m step: 230800, current TD loss: 0.00197388115339
[32m[0315 21:25:48 @network.py:203][0m step: 230900, current TD loss: 0.000133396679303
[32m[0315 21:25:49 @dqn_agent.py:203][0m episode: 12423, total game step: 281000, epsilon: 0.77131099
[32m[0315 21:25:49 @network.py:203][0m step: 231000, current TD loss: 0.000746225530747
[32m[0315 21:25:50 @network.py:203][0m step: 231100, current TD loss: 0.0175358820707
[32m[0315 21:25:52 @network.py:203][0m step: 231200, current TD loss: 0.00083529134281
[32m[0315 21:25:53 @network.py:203][0m step: 231300, current TD loss: 0.000423228077125
[32m[0315 21:25:54 @network.py:203][0m step: 231400, current TD loss: 0.00138795783278
[32m[0315 21:25:56 @network.py:203][0m step: 231500, current TD loss: 0.0114752650261
[32m[0315 21:25:57 @network.py:203][0m step: 231600, current TD loss: 0.00227781408466
[32m[0315 21:25:58 @network.py:203][0m step: 231700, current TD loss: 0.000235826460994
[32m[0315 21:26:00 @network.py:203][0m step: 231800, current TD loss: 0.00120250030886
[32m[0315 21:26:01 @network.py:203][0m step: 231900, current TD loss: 0.00683045573533
[32m[0315 21:26:02 @dqn_agent.py:203][0m episode: 12462, total game step: 282000, epsilon: 0.77032099
[32m[0315 21:26:02 @network.py:203][0m step: 232000, current TD loss: 0.00146937626414
[32m[0315 21:26:04 @network.py:203][0m step: 232100, current TD loss: 0.0180717483163
[32m[0315 21:26:05 @network.py:203][0m step: 232200, current TD loss: 0.00344123784453
[32m[0315 21:26:06 @network.py:203][0m step: 232300, current TD loss: 0.00185730715748
[32m[0315 21:26:08 @network.py:203][0m step: 232400, current TD loss: 0.00237706978805
[32m[0315 21:26:09 @network.py:203][0m step: 232500, current TD loss: 0.0126167470589
[32m[0315 21:26:09 @dqn_agent.py:216][0m At time step 232500, the target_network is updated
[32m[0315 21:26:10 @network.py:203][0m step: 232600, current TD loss: 0.0127585269511
[32m[0315 21:26:12 @network.py:203][0m step: 232700, current TD loss: 0.000789494777564
[32m[0315 21:26:13 @network.py:203][0m step: 232800, current TD loss: 0.0163341388106
[32m[0315 21:26:15 @network.py:203][0m step: 232900, current TD loss: 0.000712101347744
[32m[0315 21:26:16 @summary_handler.py:101][0m At episode: 282993, Reward: 0.14 (over 100 episodes)
[32m[0315 21:26:16 @summary_handler.py:102][0m Length: 24.5
[32m[0315 21:26:16 @dqn_agent.py:203][0m episode: 12500, total game step: 283000, epsilon: 0.76933099
[32m[0315 21:26:16 @network.py:203][0m step: 233000, current TD loss: 0.00355252623558
[32m[0315 21:26:17 @network.py:203][0m step: 233100, current TD loss: 0.00160437170416
[32m[0315 21:26:18 @network.py:203][0m step: 233200, current TD loss: 0.01578393206
[32m[0315 21:26:20 @network.py:203][0m step: 233300, current TD loss: 0.00219096941873
[32m[0315 21:26:21 @network.py:203][0m step: 233400, current TD loss: 0.00104415102396
[32m[0315 21:26:22 @network.py:203][0m step: 233500, current TD loss: 0.00550522981212
[32m[0315 21:26:24 @network.py:203][0m step: 233600, current TD loss: 0.0182544961572
[32m[0315 21:26:25 @network.py:203][0m step: 233700, current TD loss: 0.0113770281896
[32m[0315 21:26:27 @network.py:203][0m step: 233800, current TD loss: 0.00126583036035
[32m[0315 21:26:28 @network.py:203][0m step: 233900, current TD loss: 0.00198995904066
[32m[0315 21:26:29 @dqn_agent.py:203][0m episode: 12539, total game step: 284000, epsilon: 0.76834099
[32m[0315 21:26:29 @network.py:203][0m step: 234000, current TD loss: 0.00098934059497
[32m[0315 21:26:31 @network.py:203][0m step: 234100, current TD loss: 0.00130808772519
[32m[0315 21:26:32 @network.py:203][0m step: 234200, current TD loss: 0.000837149214931
[32m[0315 21:26:33 @network.py:203][0m step: 234300, current TD loss: 0.00143476668745
[32m[0315 21:26:35 @network.py:203][0m step: 234400, current TD loss: 0.00111122278031
[32m[0315 21:26:36 @network.py:203][0m step: 234500, current TD loss: 0.00190497771837
[32m[0315 21:26:37 @network.py:203][0m step: 234600, current TD loss: 0.00344970426522
[32m[0315 21:26:39 @network.py:203][0m step: 234700, current TD loss: 0.0168191883713
[32m[0315 21:26:40 @network.py:203][0m step: 234800, current TD loss: 0.0108497822657
[32m[0315 21:26:41 @network.py:203][0m step: 234900, current TD loss: 0.00159122957848
[32m[0315 21:26:43 @dqn_agent.py:203][0m episode: 12576, total game step: 285000, epsilon: 0.76735099
[32m[0315 21:26:43 @network.py:203][0m step: 235000, current TD loss: 0.00129111658316
[32m[0315 21:26:43 @dqn_agent.py:216][0m At time step 235000, the target_network is updated
[32m[0315 21:26:44 @network.py:203][0m step: 235100, current TD loss: 0.000964316888712
[32m[0315 21:26:45 @network.py:203][0m step: 235200, current TD loss: 0.00111628952436
[32m[0315 21:26:47 @network.py:203][0m step: 235300, current TD loss: 0.0210560243577
[32m[0315 21:26:48 @network.py:203][0m step: 235400, current TD loss: 0.00173982023261
[32m[0315 21:26:48 @summary_handler.py:101][0m At episode: 285412, Reward: 0.18 (over 100 episodes)
[32m[0315 21:26:48 @summary_handler.py:102][0m Length: 24.19
[32m[0315 21:26:50 @network.py:203][0m step: 235500, current TD loss: 0.00343998475
[32m[0315 21:26:51 @network.py:203][0m step: 235600, current TD loss: 0.0156017215922
[32m[0315 21:26:52 @network.py:203][0m step: 235700, current TD loss: 0.000383370002965
[32m[0315 21:26:54 @network.py:203][0m step: 235800, current TD loss: 0.0015919546131
[32m[0315 21:26:55 @network.py:203][0m step: 235900, current TD loss: 0.00747845694423
[32m[0315 21:26:56 @dqn_agent.py:203][0m episode: 12631, total game step: 286000, epsilon: 0.76636099
[32m[0315 21:26:56 @network.py:203][0m step: 236000, current TD loss: 0.000735921377782
[32m[0315 21:26:58 @network.py:203][0m step: 236100, current TD loss: 0.00222816155292
[32m[0315 21:26:59 @network.py:203][0m step: 236200, current TD loss: 0.00252487533726
[32m[0315 21:27:00 @network.py:203][0m step: 236300, current TD loss: 0.0115832416341
[32m[0315 21:27:02 @network.py:203][0m step: 236400, current TD loss: 0.00219739181921
[32m[0315 21:27:03 @network.py:203][0m step: 236500, current TD loss: 0.0132088186219
[32m[0315 21:27:04 @network.py:203][0m step: 236600, current TD loss: 0.00395252648741
[32m[0315 21:27:06 @network.py:203][0m step: 236700, current TD loss: 0.00127268373035
[32m[0315 21:27:07 @network.py:203][0m step: 236800, current TD loss: 0.00507141137496
[32m[0315 21:27:08 @network.py:203][0m step: 236900, current TD loss: 0.00173013331369
[32m[0315 21:27:10 @dqn_agent.py:203][0m episode: 12672, total game step: 287000, epsilon: 0.76537099
[32m[0315 21:27:10 @network.py:203][0m step: 237000, current TD loss: 0.000852741126437
[32m[0315 21:27:11 @network.py:203][0m step: 237100, current TD loss: 0.00103151344229
[32m[0315 21:27:12 @network.py:203][0m step: 237200, current TD loss: 0.00259792781435
[32m[0315 21:27:14 @network.py:203][0m step: 237300, current TD loss: 0.000837402243633
[32m[0315 21:27:15 @network.py:203][0m step: 237400, current TD loss: 0.0164114739746
[32m[0315 21:27:16 @network.py:203][0m step: 237500, current TD loss: 0.000900067272596
[32m[0315 21:27:16 @dqn_agent.py:216][0m At time step 237500, the target_network is updated
[32m[0315 21:27:18 @network.py:203][0m step: 237600, current TD loss: 0.00267502386123
[32m[0315 21:27:18 @summary_handler.py:101][0m At episode: 287636, Reward: 0.08 (over 100 episodes)
[32m[0315 21:27:18 @summary_handler.py:102][0m Length: 22.24
[32m[0315 21:27:19 @network.py:203][0m step: 237700, current TD loss: 0.00391973555088
[32m[0315 21:27:20 @network.py:203][0m step: 237800, current TD loss: 0.0029881412629
[32m[0315 21:27:22 @network.py:203][0m step: 237900, current TD loss: 0.00568998465315
[32m[0315 21:27:23 @dqn_agent.py:203][0m episode: 12719, total game step: 288000, epsilon: 0.76438099
[32m[0315 21:27:23 @network.py:203][0m step: 238000, current TD loss: 0.00588659010828
[32m[0315 21:27:24 @network.py:203][0m step: 238100, current TD loss: 0.00259000132792
[32m[0315 21:27:26 @network.py:203][0m step: 238200, current TD loss: 0.00101792416535
[32m[0315 21:27:27 @network.py:203][0m step: 238300, current TD loss: 0.0234211795032
[32m[0315 21:27:28 @network.py:203][0m step: 238400, current TD loss: 0.00311555806547
[32m[0315 21:27:30 @network.py:203][0m step: 238500, current TD loss: 0.00593786500394
[32m[0315 21:27:31 @network.py:203][0m step: 238600, current TD loss: 0.0004735692346
[32m[0315 21:27:32 @network.py:203][0m step: 238700, current TD loss: 0.000777620007284
[32m[0315 21:27:34 @network.py:203][0m step: 238800, current TD loss: 0.00136852799915
[32m[0315 21:27:35 @network.py:203][0m step: 238900, current TD loss: 0.00182445300743
[32m[0315 21:27:36 @dqn_agent.py:203][0m episode: 12756, total game step: 289000, epsilon: 0.76339099
[32m[0315 21:27:36 @network.py:203][0m step: 239000, current TD loss: 0.00419743452221
[32m[0315 21:27:38 @network.py:203][0m step: 239100, current TD loss: 0.00159784080461
[32m[0315 21:27:39 @network.py:203][0m step: 239200, current TD loss: 0.00191204459406
[32m[0315 21:27:40 @network.py:203][0m step: 239300, current TD loss: 0.00302829686552
[32m[0315 21:27:42 @network.py:203][0m step: 239400, current TD loss: 0.000680787488818
[32m[0315 21:27:43 @network.py:203][0m step: 239500, current TD loss: 0.00317827030085
[32m[0315 21:27:44 @network.py:203][0m step: 239600, current TD loss: 0.00616770703346
[32m[0315 21:27:46 @network.py:203][0m step: 239700, current TD loss: 0.00157782633323
[32m[0315 21:27:47 @network.py:203][0m step: 239800, current TD loss: 0.0167121123523
[32m[0315 21:27:48 @network.py:203][0m step: 239900, current TD loss: 0.00268046976998
[32m[0315 21:27:50 @dqn_agent.py:203][0m episode: 12792, total game step: 290000, epsilon: 0.76240099
[32m[0315 21:27:50 @network.py:203][0m step: 240000, current TD loss: 0.0141881927848
[32m[0315 21:27:50 @dqn_agent.py:216][0m At time step 240000, the target_network is updated
[32m[0315 21:27:51 @network.py:203][0m step: 240100, current TD loss: 0.00479157734662
[32m[0315 21:27:52 @network.py:203][0m step: 240200, current TD loss: 0.00110700796358
[32m[0315 21:27:54 @network.py:203][0m step: 240300, current TD loss: 0.0023346755188
[32m[0315 21:27:54 @summary_handler.py:101][0m At episode: 290302, Reward: 0.21 (over 100 episodes)
[32m[0315 21:27:54 @summary_handler.py:102][0m Length: 26.66
[32m[0315 21:27:55 @network.py:203][0m step: 240400, current TD loss: 0.00260666478425
[32m[0315 21:27:56 @network.py:203][0m step: 240500, current TD loss: 0.00919713079929
[32m[0315 21:27:58 @network.py:203][0m step: 240600, current TD loss: 0.0064026308246
[32m[0315 21:27:59 @network.py:203][0m step: 240700, current TD loss: 0.013459507376
[32m[0315 21:28:00 @network.py:203][0m step: 240800, current TD loss: 0.00113300746307
[32m[0315 21:28:02 @network.py:203][0m step: 240900, current TD loss: 0.00325767416507
[32m[0315 21:28:03 @dqn_agent.py:203][0m episode: 12827, total game step: 291000, epsilon: 0.76141099
[32m[0315 21:28:03 @network.py:203][0m step: 241000, current TD loss: 0.00232421187684
[32m[0315 21:28:04 @network.py:203][0m step: 241100, current TD loss: 0.00101402378641
[32m[0315 21:28:06 @network.py:203][0m step: 241200, current TD loss: 0.00443576509133
[32m[0315 21:28:07 @network.py:203][0m step: 241300, current TD loss: 0.00260778027587
[32m[0315 21:28:08 @network.py:203][0m step: 241400, current TD loss: 0.00225602276623
[32m[0315 21:28:10 @network.py:203][0m step: 241500, current TD loss: 0.000531881523784
[32m[0315 21:28:11 @network.py:203][0m step: 241600, current TD loss: 0.00142604170833
[32m[0315 21:28:12 @network.py:203][0m step: 241700, current TD loss: 0.00157892785501
[32m[0315 21:28:14 @network.py:203][0m step: 241800, current TD loss: 0.00162141956389
[32m[0315 21:28:15 @network.py:203][0m step: 241900, current TD loss: 0.00132099480834
[32m[0315 21:28:16 @dqn_agent.py:203][0m episode: 12873, total game step: 292000, epsilon: 0.76042099
[32m[0315 21:28:16 @network.py:203][0m step: 242000, current TD loss: 0.00963082816452
[32m[0315 21:28:18 @network.py:203][0m step: 242100, current TD loss: 0.00201836461201
[32m[0315 21:28:19 @network.py:203][0m step: 242200, current TD loss: 0.00114523980301
[32m[0315 21:28:20 @network.py:203][0m step: 242300, current TD loss: 0.000124230486108
[32m[0315 21:28:22 @network.py:203][0m step: 242400, current TD loss: 0.00264894333668
[32m[0315 21:28:23 @network.py:203][0m step: 242500, current TD loss: 0.00202470039949
[32m[0315 21:28:23 @dqn_agent.py:216][0m At time step 242500, the target_network is updated
[32m[0315 21:28:24 @network.py:203][0m step: 242600, current TD loss: 0.0018146452494
[32m[0315 21:28:26 @network.py:203][0m step: 242700, current TD loss: 0.0108148017898
[32m[0315 21:28:26 @summary_handler.py:101][0m At episode: 292727, Reward: 0.22 (over 100 episodes)
[32m[0315 21:28:26 @summary_handler.py:102][0m Length: 24.25
[32m[0315 21:28:27 @network.py:203][0m step: 242800, current TD loss: 0.0148228527978
[32m[0315 21:28:28 @network.py:203][0m step: 242900, current TD loss: 0.0151665974408
[32m[0315 21:28:30 @dqn_agent.py:203][0m episode: 12909, total game step: 293000, epsilon: 0.75943099
[32m[0315 21:28:30 @network.py:203][0m step: 243000, current TD loss: 0.00398815562949
[32m[0315 21:28:31 @network.py:203][0m step: 243100, current TD loss: 0.00174873718061
[32m[0315 21:28:32 @network.py:203][0m step: 243200, current TD loss: 0.000997549737804
[32m[0315 21:28:34 @network.py:203][0m step: 243300, current TD loss: 0.00208092690445
[32m[0315 21:28:35 @network.py:203][0m step: 243400, current TD loss: 0.00194865092635
[32m[0315 21:28:36 @network.py:203][0m step: 243500, current TD loss: 0.00107205030508
[32m[0315 21:28:38 @network.py:203][0m step: 243600, current TD loss: 0.00115567364264
[32m[0315 21:28:39 @network.py:203][0m step: 243700, current TD loss: 0.0126066021621
[32m[0315 21:28:40 @network.py:203][0m step: 243800, current TD loss: 0.00291825062595
[32m[0315 21:28:42 @network.py:203][0m step: 243900, current TD loss: 0.00277690798976
[32m[0315 21:28:43 @dqn_agent.py:203][0m episode: 12948, total game step: 294000, epsilon: 0.75844099
[32m[0315 21:28:43 @network.py:203][0m step: 244000, current TD loss: 0.000773953681346
[32m[0315 21:28:44 @network.py:203][0m step: 244100, current TD loss: 0.00091495050583
[32m[0315 21:28:46 @network.py:203][0m step: 244200, current TD loss: 0.000249594973866
[32m[0315 21:28:47 @network.py:203][0m step: 244300, current TD loss: 0.0226499401033
[32m[0315 21:28:48 @network.py:203][0m step: 244400, current TD loss: 0.00148941262159
[32m[0315 21:28:50 @network.py:203][0m step: 244500, current TD loss: 0.000606115965638
[32m[0315 21:28:51 @network.py:203][0m step: 244600, current TD loss: 0.00464487727731
[32m[0315 21:28:52 @network.py:203][0m step: 244700, current TD loss: 0.00146084546577
[32m[0315 21:28:54 @network.py:203][0m step: 244800, current TD loss: 0.00667942548171
[32m[0315 21:28:55 @network.py:203][0m step: 244900, current TD loss: 0.00391751620919
[32m[0315 21:28:56 @dqn_agent.py:203][0m episode: 12989, total game step: 295000, epsilon: 0.75745099
[32m[0315 21:28:56 @network.py:203][0m step: 245000, current TD loss: 0.000902783707716
[32m[0315 21:28:56 @dqn_agent.py:216][0m At time step 245000, the target_network is updated
[32m[0315 21:28:58 @network.py:203][0m step: 245100, current TD loss: 0.000593802658841
[32m[0315 21:28:59 @summary_handler.py:101][0m At episode: 295160, Reward: 0.14 (over 100 episodes)
[32m[0315 21:28:59 @summary_handler.py:102][0m Length: 24.33
[32m[0315 21:28:59 @network.py:203][0m step: 245200, current TD loss: 0.00356734450907
[32m[0315 21:29:01 @network.py:203][0m step: 245300, current TD loss: 0.00746388640255
[32m[0315 21:29:02 @network.py:203][0m step: 245400, current TD loss: 0.00118486804422
[32m[0315 21:29:03 @network.py:203][0m step: 245500, current TD loss: 0.00636680051684
[32m[0315 21:29:05 @network.py:203][0m step: 245600, current TD loss: 0.00232696486637
[32m[0315 21:29:06 @network.py:203][0m step: 245700, current TD loss: 0.00446651224047
[32m[0315 21:29:07 @network.py:203][0m step: 245800, current TD loss: 0.000491802522447
[32m[0315 21:29:09 @network.py:203][0m step: 245900, current TD loss: 0.00150564755313
[32m[0315 21:29:10 @dqn_agent.py:203][0m episode: 13040, total game step: 296000, epsilon: 0.75646099
[32m[0315 21:29:10 @network.py:203][0m step: 246000, current TD loss: 0.0209142379463
[32m[0315 21:29:12 @network.py:203][0m step: 246100, current TD loss: 0.00225466489792
[32m[0315 21:29:13 @network.py:203][0m step: 246200, current TD loss: 0.0150672355667
[32m[0315 21:29:14 @network.py:203][0m step: 246300, current TD loss: 0.00184427946806
[32m[0315 21:29:16 @network.py:203][0m step: 246400, current TD loss: 0.00179877015762
[32m[0315 21:29:17 @network.py:203][0m step: 246500, current TD loss: 0.00873962603509
[32m[0315 21:29:18 @network.py:203][0m step: 246600, current TD loss: 0.00241192500107
[32m[0315 21:29:20 @network.py:203][0m step: 246700, current TD loss: 0.00126948498655
[32m[0315 21:29:21 @network.py:203][0m step: 246800, current TD loss: 0.00443903915584
[32m[0315 21:29:22 @network.py:203][0m step: 246900, current TD loss: 0.000593890552409
[32m[0315 21:29:24 @dqn_agent.py:203][0m episode: 13082, total game step: 297000, epsilon: 0.75547099
[32m[0315 21:29:24 @network.py:203][0m step: 247000, current TD loss: 0.00249209906906
[32m[0315 21:29:25 @network.py:203][0m step: 247100, current TD loss: 0.00389873399399
[32m[0315 21:29:27 @network.py:203][0m step: 247200, current TD loss: 0.00162052048836
[32m[0315 21:29:28 @network.py:203][0m step: 247300, current TD loss: 0.00248851906508
[32m[0315 21:29:29 @network.py:203][0m step: 247400, current TD loss: 0.00217841542326
[32m[0315 21:29:30 @summary_handler.py:101][0m At episode: 297420, Reward: 0.08 (over 100 episodes)
[32m[0315 21:29:30 @summary_handler.py:102][0m Length: 22.6
[32m[0315 21:29:31 @network.py:203][0m step: 247500, current TD loss: 0.00761031918228
[32m[0315 21:29:31 @dqn_agent.py:216][0m At time step 247500, the target_network is updated
[32m[0315 21:29:32 @network.py:203][0m step: 247600, current TD loss: 0.0035149147734
[32m[0315 21:29:33 @network.py:203][0m step: 247700, current TD loss: 0.00230168178678
[32m[0315 21:29:35 @network.py:203][0m step: 247800, current TD loss: 0.00402539828792
[32m[0315 21:29:36 @network.py:203][0m step: 247900, current TD loss: 0.00273715145886
[32m[0315 21:29:37 @dqn_agent.py:203][0m episode: 13127, total game step: 298000, epsilon: 0.75448099
[32m[0315 21:29:37 @network.py:203][0m step: 248000, current TD loss: 0.00176007673144
[32m[0315 21:29:39 @network.py:203][0m step: 248100, current TD loss: 0.000360902631655
[32m[0315 21:29:40 @network.py:203][0m step: 248200, current TD loss: 0.00139784161001
[32m[0315 21:29:41 @network.py:203][0m step: 248300, current TD loss: 0.00117199495435
[32m[0315 21:29:43 @network.py:203][0m step: 248400, current TD loss: 0.00108971819282
[32m[0315 21:29:44 @network.py:203][0m step: 248500, current TD loss: 0.00249697966501
[32m[0315 21:29:45 @network.py:203][0m step: 248600, current TD loss: 0.0177146941423
[32m[0315 21:29:47 @network.py:203][0m step: 248700, current TD loss: 0.0016196668148
[32m[0315 21:29:48 @network.py:203][0m step: 248800, current TD loss: 0.00114296423271
[32m[0315 21:29:50 @network.py:203][0m step: 248900, current TD loss: 0.00602867314592
[32m[0315 21:29:51 @dqn_agent.py:203][0m episode: 13179, total game step: 299000, epsilon: 0.75349099
[32m[0315 21:29:51 @network.py:203][0m step: 249000, current TD loss: 0.0110462764278
[32m[0315 21:29:52 @network.py:203][0m step: 249100, current TD loss: 0.00163382315077
[32m[0315 21:29:54 @network.py:203][0m step: 249200, current TD loss: 0.00312178721651
[32m[0315 21:29:55 @network.py:203][0m step: 249300, current TD loss: 0.00156805559527
[32m[0315 21:29:56 @network.py:203][0m step: 249400, current TD loss: 0.0141306146979
[32m[0315 21:29:56 @summary_handler.py:101][0m At episode: 299422, Reward: 0.07 (over 100 episodes)
[32m[0315 21:29:56 @summary_handler.py:102][0m Length: 20.02
[32m[0315 21:29:57 @network.py:203][0m step: 249500, current TD loss: 0.00401693722233
[32m[0315 21:29:59 @network.py:203][0m step: 249600, current TD loss: 0.00267839990556
[32m[0315 21:30:00 @network.py:203][0m step: 249700, current TD loss: 0.00180579582229
[32m[0315 21:30:01 @network.py:203][0m step: 249800, current TD loss: 0.00183385855053
[32m[0315 21:30:02 @network.py:203][0m step: 249900, current TD loss: 0.00167603569571
[32m[0315 21:30:03 @dqn_agent.py:203][0m episode: 13221, total game step: 300000, epsilon: 0.75250099
[32m[0315 21:30:03 @network.py:203][0m step: 250000, current TD loss: 0.000964871491306
[32m[0315 21:30:03 @dqn_agent.py:216][0m At time step 250000, the target_network is updated
[32m[0315 21:30:04 @network.py:203][0m step: 250100, current TD loss: 0.00791642069817
[32m[0315 21:30:05 @network.py:203][0m step: 250200, current TD loss: 0.00490252906457
[32m[0315 21:30:06 @network.py:203][0m step: 250300, current TD loss: 0.00172665098216
[32m[0315 21:30:07 @network.py:203][0m step: 250400, current TD loss: 0.00427016662434
[32m[0315 21:30:09 @network.py:203][0m step: 250500, current TD loss: 0.00309815630317
[32m[0315 21:30:10 @network.py:203][0m step: 250600, current TD loss: 0.00367875257507
[32m[0315 21:30:11 @network.py:203][0m step: 250700, current TD loss: 0.0139060467482
[32m[0315 21:30:12 @network.py:203][0m step: 250800, current TD loss: 0.000792335951701
[32m[0315 21:30:13 @network.py:203][0m step: 250900, current TD loss: 0.0033803593833
[32m[0315 21:30:14 @dqn_agent.py:203][0m episode: 13260, total game step: 301000, epsilon: 0.75151099
[32m[0315 21:30:14 @network.py:203][0m step: 251000, current TD loss: 0.0016053103609
[32m[0315 21:30:15 @network.py:203][0m step: 251100, current TD loss: 0.0143989026546
[32m[0315 21:30:16 @network.py:203][0m step: 251200, current TD loss: 0.000541792309377
[32m[0315 21:30:18 @network.py:203][0m step: 251300, current TD loss: 0.00263889180496
[32m[0315 21:30:19 @network.py:203][0m step: 251400, current TD loss: 0.00266605056822
[32m[0315 21:30:20 @network.py:203][0m step: 251500, current TD loss: 0.00329809868708
[32m[0315 21:30:21 @network.py:203][0m step: 251600, current TD loss: 0.00299969571643
[32m[0315 21:30:22 @network.py:203][0m step: 251700, current TD loss: 0.00363871175796
[32m[0315 21:30:23 @network.py:203][0m step: 251800, current TD loss: 0.00505744852126
[32m[0315 21:30:24 @network.py:203][0m step: 251900, current TD loss: 0.00770898349583
[32m[0315 21:30:25 @summary_handler.py:101][0m At episode: 301955, Reward: 0.13 (over 100 episodes)
[32m[0315 21:30:25 @summary_handler.py:102][0m Length: 25.33
[32m[0315 21:30:26 @dqn_agent.py:203][0m episode: 13303, total game step: 302000, epsilon: 0.75052099
[32m[0315 21:30:26 @network.py:203][0m step: 252000, current TD loss: 0.00146719452459
[32m[0315 21:30:27 @network.py:203][0m step: 252100, current TD loss: 0.00221905251965
[32m[0315 21:30:28 @network.py:203][0m step: 252200, current TD loss: 0.00203329720534
[32m[0315 21:30:29 @network.py:203][0m step: 252300, current TD loss: 0.00209026690573
[32m[0315 21:30:30 @network.py:203][0m step: 252400, current TD loss: 0.00289041455835
[32m[0315 21:30:31 @network.py:203][0m step: 252500, current TD loss: 0.00277462648228
[32m[0315 21:30:31 @dqn_agent.py:216][0m At time step 252500, the target_network is updated
[32m[0315 21:30:33 @network.py:203][0m step: 252600, current TD loss: 0.00179913220927
[32m[0315 21:30:34 @network.py:203][0m step: 252700, current TD loss: 0.00140714389272
[32m[0315 21:30:35 @network.py:203][0m step: 252800, current TD loss: 0.00181974133011
[32m[0315 21:30:36 @network.py:203][0m step: 252900, current TD loss: 0.00335441343486
[32m[0315 21:30:37 @dqn_agent.py:203][0m episode: 13353, total game step: 303000, epsilon: 0.74953099
[32m[0315 21:30:37 @network.py:203][0m step: 253000, current TD loss: 0.00221361010335
[32m[0315 21:30:38 @network.py:203][0m step: 253100, current TD loss: 0.00159442960285
[32m[0315 21:30:40 @network.py:203][0m step: 253200, current TD loss: 0.00220721727237
[32m[0315 21:30:41 @network.py:203][0m step: 253300, current TD loss: 0.00197681132704
[32m[0315 21:30:42 @network.py:203][0m step: 253400, current TD loss: 0.00164489797316
[32m[0315 21:30:43 @network.py:203][0m step: 253500, current TD loss: 0.00225566793233
[32m[0315 21:30:44 @network.py:203][0m step: 253600, current TD loss: 0.000834797276184
[32m[0315 21:30:45 @network.py:203][0m step: 253700, current TD loss: 0.00569493463263
[32m[0315 21:30:47 @network.py:203][0m step: 253800, current TD loss: 0.00114564830437
[32m[0315 21:30:48 @network.py:203][0m step: 253900, current TD loss: 0.00247316039167
[32m[0315 21:30:49 @dqn_agent.py:203][0m episode: 13398, total game step: 304000, epsilon: 0.74854099
[32m[0315 21:30:49 @network.py:203][0m step: 254000, current TD loss: 0.0029962155968
[32m[0315 21:30:50 @summary_handler.py:101][0m At episode: 304075, Reward: 0.15 (over 100 episodes)
[32m[0315 21:30:50 @summary_handler.py:102][0m Length: 21.2
[32m[0315 21:30:50 @network.py:203][0m step: 254100, current TD loss: 0.0124456249177
[32m[0315 21:30:51 @network.py:203][0m step: 254200, current TD loss: 0.00183245295193
[32m[0315 21:30:52 @network.py:203][0m step: 254300, current TD loss: 0.00113458558917
[32m[0315 21:30:54 @network.py:203][0m step: 254400, current TD loss: 0.00147704628762
[32m[0315 21:30:55 @network.py:203][0m step: 254500, current TD loss: 0.00129122845829
[32m[0315 21:30:56 @network.py:203][0m step: 254600, current TD loss: 0.00237944256514
[32m[0315 21:30:57 @network.py:203][0m step: 254700, current TD loss: 0.002996543888
[32m[0315 21:30:58 @network.py:203][0m step: 254800, current TD loss: 0.00164286443032
[32m[0315 21:30:59 @network.py:203][0m step: 254900, current TD loss: 0.00184032320976
[32m[0315 21:31:01 @dqn_agent.py:203][0m episode: 13453, total game step: 305000, epsilon: 0.74755099
[32m[0315 21:31:01 @network.py:203][0m step: 255000, current TD loss: 0.00274227233604
[32m[0315 21:31:01 @dqn_agent.py:216][0m At time step 255000, the target_network is updated
[32m[0315 21:31:02 @network.py:203][0m step: 255100, current TD loss: 0.00777070177719
[32m[0315 21:31:03 @network.py:203][0m step: 255200, current TD loss: 0.0140457544476
[32m[0315 21:31:04 @network.py:203][0m step: 255300, current TD loss: 0.0152476169169
[32m[0315 21:31:06 @network.py:203][0m step: 255400, current TD loss: 0.00210468564183
[32m[0315 21:31:07 @network.py:203][0m step: 255500, current TD loss: 0.0025646830909
[32m[0315 21:31:08 @network.py:203][0m step: 255600, current TD loss: 0.00201870687306
[32m[0315 21:31:09 @network.py:203][0m step: 255700, current TD loss: 0.00491536175832
[32m[0315 21:31:11 @network.py:203][0m step: 255800, current TD loss: 0.000522161310073
[32m[0315 21:31:12 @network.py:203][0m step: 255900, current TD loss: 0.00207257666625
[32m[0315 21:31:12 @summary_handler.py:101][0m At episode: 305935, Reward: 0.11 (over 100 episodes)
[32m[0315 21:31:12 @summary_handler.py:102][0m Length: 18.6
[32m[0315 21:31:13 @dqn_agent.py:203][0m episode: 13501, total game step: 306000, epsilon: 0.74656099
[32m[0315 21:31:13 @network.py:203][0m step: 256000, current TD loss: 0.00286362227052
[32m[0315 21:31:14 @network.py:203][0m step: 256100, current TD loss: 0.000725894991774
[32m[0315 21:31:15 @network.py:203][0m step: 256200, current TD loss: 0.00424388283864
[32m[0315 21:31:17 @network.py:203][0m step: 256300, current TD loss: 0.00088926817989
[32m[0315 21:31:18 @network.py:203][0m step: 256400, current TD loss: 0.0039068995975
[32m[0315 21:31:19 @network.py:203][0m step: 256500, current TD loss: 0.00184031308163
[32m[0315 21:31:20 @network.py:203][0m step: 256600, current TD loss: 0.0126477247104
[32m[0315 21:31:22 @network.py:203][0m step: 256700, current TD loss: 0.000408409105148
[32m[0315 21:31:23 @network.py:203][0m step: 256800, current TD loss: 0.00352970417589
[32m[0315 21:31:24 @network.py:203][0m step: 256900, current TD loss: 0.000522796122823
[32m[0315 21:31:25 @dqn_agent.py:203][0m episode: 13546, total game step: 307000, epsilon: 0.74557099
[32m[0315 21:31:25 @network.py:203][0m step: 257000, current TD loss: 0.0010940580396
[32m[0315 21:31:26 @network.py:203][0m step: 257100, current TD loss: 0.00618812581524
[32m[0315 21:31:28 @network.py:203][0m step: 257200, current TD loss: 0.00163322675508
[32m[0315 21:31:29 @network.py:203][0m step: 257300, current TD loss: 0.00398906273767
[32m[0315 21:31:30 @network.py:203][0m step: 257400, current TD loss: 0.00167845305987
[32m[0315 21:31:31 @network.py:203][0m step: 257500, current TD loss: 0.00226107123308
[32m[0315 21:31:31 @dqn_agent.py:216][0m At time step 257500, the target_network is updated
[32m[0315 21:31:32 @network.py:203][0m step: 257600, current TD loss: 0.000841052853502
[32m[0315 21:31:34 @network.py:203][0m step: 257700, current TD loss: 0.000472470768727
[32m[0315 21:31:35 @network.py:203][0m step: 257800, current TD loss: 0.00126667809673
[32m[0315 21:31:36 @network.py:203][0m step: 257900, current TD loss: 0.00226972834207
[32m[0315 21:31:37 @dqn_agent.py:203][0m episode: 13587, total game step: 308000, epsilon: 0.74458099
[32m[0315 21:31:37 @network.py:203][0m step: 258000, current TD loss: 0.00654898537323
[32m[0315 21:31:39 @network.py:203][0m step: 258100, current TD loss: 0.00269926525652
[32m[0315 21:31:40 @network.py:203][0m step: 258200, current TD loss: 0.00155272963457
[32m[0315 21:31:41 @summary_handler.py:101][0m At episode: 308283, Reward: 0.15 (over 100 episodes)
[32m[0315 21:31:41 @summary_handler.py:102][0m Length: 23.48
[32m[0315 21:31:41 @network.py:203][0m step: 258300, current TD loss: 0.00206223363057
[32m[0315 21:31:42 @network.py:203][0m step: 258400, current TD loss: 0.000701493700035
[32m[0315 21:31:43 @network.py:203][0m step: 258500, current TD loss: 0.00135781348217
[32m[0315 21:31:45 @network.py:203][0m step: 258600, current TD loss: 0.00155484152492
[32m[0315 21:31:46 @network.py:203][0m step: 258700, current TD loss: 0.00621365057305
[32m[0315 21:31:47 @network.py:203][0m step: 258800, current TD loss: 0.000955630210228
[32m[0315 21:31:48 @network.py:203][0m step: 258900, current TD loss: 0.00246335752308
[32m[0315 21:31:50 @dqn_agent.py:203][0m episode: 13634, total game step: 309000, epsilon: 0.74359099
[32m[0315 21:31:50 @network.py:203][0m step: 259000, current TD loss: 0.000845721224323
[32m[0315 21:31:51 @network.py:203][0m step: 259100, current TD loss: 0.000896688725334
[32m[0315 21:31:52 @network.py:203][0m step: 259200, current TD loss: 0.00198230007663
[32m[0315 21:31:53 @network.py:203][0m step: 259300, current TD loss: 0.00280470540747
[32m[0315 21:31:54 @network.py:203][0m step: 259400, current TD loss: 0.000830575707369
[32m[0315 21:31:56 @network.py:203][0m step: 259500, current TD loss: 0.00155663792975
[32m[0315 21:31:57 @network.py:203][0m step: 259600, current TD loss: 0.00256352662109
[32m[0315 21:31:58 @network.py:203][0m step: 259700, current TD loss: 0.00150200189091
[32m[0315 21:31:59 @network.py:203][0m step: 259800, current TD loss: 0.00357963191345
[32m[0315 21:32:01 @network.py:203][0m step: 259900, current TD loss: 0.00474667968228
[32m[0315 21:32:02 @dqn_agent.py:203][0m episode: 13678, total game step: 310000, epsilon: 0.74260099
[32m[0315 21:32:02 @network.py:203][0m step: 260000, current TD loss: 0.00186244701035
[32m[0315 21:32:02 @dqn_agent.py:216][0m At time step 260000, the target_network is updated
[32m[0315 21:32:03 @network.py:203][0m step: 260100, current TD loss: 0.00182615604717
[32m[0315 21:32:04 @network.py:203][0m step: 260200, current TD loss: 0.00153613835573
[32m[0315 21:32:06 @network.py:203][0m step: 260300, current TD loss: 0.00102345703635
[32m[0315 21:32:07 @summary_handler.py:101][0m At episode: 310392, Reward: 0.11 (over 100 episodes)
[32m[0315 21:32:07 @summary_handler.py:102][0m Length: 21.09
[32m[0315 21:32:07 @network.py:203][0m step: 260400, current TD loss: 0.00155553675722
[32m[0315 21:32:08 @network.py:203][0m step: 260500, current TD loss: 0.00198844424449
[32m[0315 21:32:09 @network.py:203][0m step: 260600, current TD loss: 0.00195993040688
[32m[0315 21:32:10 @network.py:203][0m step: 260700, current TD loss: 0.00166122848168
[32m[0315 21:32:12 @network.py:203][0m step: 260800, current TD loss: 0.00274375174195
[32m[0315 21:32:13 @network.py:203][0m step: 260900, current TD loss: 0.00234265229665
[32m[0315 21:32:14 @dqn_agent.py:203][0m episode: 13729, total game step: 311000, epsilon: 0.74161099
[32m[0315 21:32:14 @network.py:203][0m step: 261000, current TD loss: 0.00129458867013
[32m[0315 21:32:15 @network.py:203][0m step: 261100, current TD loss: 0.00471293041483
[32m[0315 21:32:17 @network.py:203][0m step: 261200, current TD loss: 0.00116174237337
[32m[0315 21:32:18 @network.py:203][0m step: 261300, current TD loss: 0.000195933593204
[32m[0315 21:32:19 @network.py:203][0m step: 261400, current TD loss: 0.00163616519421
[32m[0315 21:32:20 @network.py:203][0m step: 261500, current TD loss: 0.00860654469579
[32m[0315 21:32:22 @network.py:203][0m step: 261600, current TD loss: 0.00169891561382
[32m[0315 21:32:23 @network.py:203][0m step: 261700, current TD loss: 0.00169631023891
[32m[0315 21:32:24 @network.py:203][0m step: 261800, current TD loss: 0.0083085577935
[32m[0315 21:32:25 @network.py:203][0m step: 261900, current TD loss: 0.000848601106554
[32m[0315 21:32:26 @dqn_agent.py:203][0m episode: 13769, total game step: 312000, epsilon: 0.74062099
[32m[0315 21:32:26 @network.py:203][0m step: 262000, current TD loss: 0.00915967207402
[32m[0315 21:32:28 @network.py:203][0m step: 262100, current TD loss: 0.00110465288162
[32m[0315 21:32:29 @network.py:203][0m step: 262200, current TD loss: 0.00241641025059
[32m[0315 21:32:30 @network.py:203][0m step: 262300, current TD loss: 0.00139950704761
[32m[0315 21:32:31 @network.py:203][0m step: 262400, current TD loss: 0.00354946427979
[32m[0315 21:32:33 @network.py:203][0m step: 262500, current TD loss: 0.00319114373997
[32m[0315 21:32:33 @dqn_agent.py:216][0m At time step 262500, the target_network is updated
[32m[0315 21:32:34 @network.py:203][0m step: 262600, current TD loss: 0.00543143646792
[32m[0315 21:32:34 @summary_handler.py:101][0m At episode: 312633, Reward: 0.16 (over 100 episodes)
[32m[0315 21:32:34 @summary_handler.py:102][0m Length: 22.41
[32m[0315 21:32:35 @network.py:203][0m step: 262700, current TD loss: 0.00343698170036
[32m[0315 21:32:36 @network.py:203][0m step: 262800, current TD loss: 0.00357996951789
[32m[0315 21:32:37 @network.py:203][0m step: 262900, current TD loss: 0.00174889853224
[32m[0315 21:32:39 @dqn_agent.py:203][0m episode: 13822, total game step: 313000, epsilon: 0.73963099
[32m[0315 21:32:39 @network.py:203][0m step: 263000, current TD loss: 0.00154347741045
[32m[0315 21:32:40 @network.py:203][0m step: 263100, current TD loss: 0.00629215035588
[32m[0315 21:32:41 @network.py:203][0m step: 263200, current TD loss: 0.00224241963588
[32m[0315 21:32:42 @network.py:203][0m step: 263300, current TD loss: 0.00122580118477
[32m[0315 21:32:43 @network.py:203][0m step: 263400, current TD loss: 0.00453411508352
[32m[0315 21:32:45 @network.py:203][0m step: 263500, current TD loss: 0.00142370047979
[32m[0315 21:32:46 @network.py:203][0m step: 263600, current TD loss: 0.00254963827319
[32m[0315 21:32:47 @network.py:203][0m step: 263700, current TD loss: 0.00139145436697
[32m[0315 21:32:48 @network.py:203][0m step: 263800, current TD loss: 0.00218927231617
[32m[0315 21:32:49 @network.py:203][0m step: 263900, current TD loss: 0.00110580550972
[32m[0315 21:32:51 @dqn_agent.py:203][0m episode: 13860, total game step: 314000, epsilon: 0.73864099
[32m[0315 21:32:51 @network.py:203][0m step: 264000, current TD loss: 0.000926381675526
[32m[0315 21:32:52 @network.py:203][0m step: 264100, current TD loss: 0.00297340145335
[32m[0315 21:32:53 @network.py:203][0m step: 264200, current TD loss: 0.00152630067896
[32m[0315 21:32:54 @network.py:203][0m step: 264300, current TD loss: 0.00118477700744
[32m[0315 21:32:56 @network.py:203][0m step: 264400, current TD loss: 0.00689745275304
[32m[0315 21:32:57 @network.py:203][0m step: 264500, current TD loss: 0.0018162149936
[32m[0315 21:32:58 @network.py:203][0m step: 264600, current TD loss: 0.00177576218266
[32m[0315 21:32:59 @network.py:203][0m step: 264700, current TD loss: 0.00201348634437
[32m[0315 21:33:00 @network.py:203][0m step: 264800, current TD loss: 0.00872172322124
[32m[0315 21:33:02 @network.py:203][0m step: 264900, current TD loss: 0.00175183697138
[32m[0315 21:33:02 @summary_handler.py:101][0m At episode: 314923, Reward: 0.12 (over 100 episodes)
[32m[0315 21:33:02 @summary_handler.py:102][0m Length: 22.9
[32m[0315 21:33:03 @dqn_agent.py:203][0m episode: 13905, total game step: 315000, epsilon: 0.73765099
[32m[0315 21:33:03 @network.py:203][0m step: 265000, current TD loss: 0.00164650077932
[32m[0315 21:33:03 @dqn_agent.py:216][0m At time step 265000, the target_network is updated
[32m[0315 21:33:04 @network.py:203][0m step: 265100, current TD loss: 0.00123601418454
[32m[0315 21:33:05 @network.py:203][0m step: 265200, current TD loss: 0.0012197321048
[32m[0315 21:33:07 @network.py:203][0m step: 265300, current TD loss: 0.00348824798129
[32m[0315 21:33:08 @network.py:203][0m step: 265400, current TD loss: 0.0138649409637
[32m[0315 21:33:09 @network.py:203][0m step: 265500, current TD loss: 0.00818568281829
[32m[0315 21:33:10 @network.py:203][0m step: 265600, current TD loss: 0.0014634327963
[32m[0315 21:33:12 @network.py:203][0m step: 265700, current TD loss: 0.00282026757486
[32m[0315 21:33:13 @network.py:203][0m step: 265800, current TD loss: 0.013122420758
[32m[0315 21:33:14 @network.py:203][0m step: 265900, current TD loss: 0.00104123179335
[32m[0315 21:33:15 @dqn_agent.py:203][0m episode: 13952, total game step: 316000, epsilon: 0.73666099
[32m[0315 21:33:15 @network.py:203][0m step: 266000, current TD loss: 0.00121426745318
[32m[0315 21:33:17 @network.py:203][0m step: 266100, current TD loss: 0.00212176842615
[32m[0315 21:33:18 @network.py:203][0m step: 266200, current TD loss: 0.00230033998378
[32m[0315 21:33:19 @network.py:203][0m step: 266300, current TD loss: 0.00110721308738
[32m[0315 21:33:20 @network.py:203][0m step: 266400, current TD loss: 0.00532909482718
[32m[0315 21:33:21 @network.py:203][0m step: 266500, current TD loss: 0.00305886752903
[32m[0315 21:33:23 @network.py:203][0m step: 266600, current TD loss: 0.0012698834762
[32m[0315 21:33:24 @network.py:203][0m step: 266700, current TD loss: 0.0012156550074
[32m[0315 21:33:25 @network.py:203][0m step: 266800, current TD loss: 0.00628311838955
[32m[0315 21:33:26 @summary_handler.py:101][0m At episode: 316884, Reward: 0.11 (over 100 episodes)
[32m[0315 21:33:26 @summary_handler.py:102][0m Length: 19.61
[32m[0315 21:33:26 @network.py:203][0m step: 266900, current TD loss: 0.00346955657005
[32m[0315 21:33:28 @dqn_agent.py:203][0m episode: 14006, total game step: 317000, epsilon: 0.73567099
[32m[0315 21:33:28 @network.py:203][0m step: 267000, current TD loss: 0.00468852976337
[32m[0315 21:33:29 @network.py:203][0m step: 267100, current TD loss: 0.000998203991912
[32m[0315 21:33:30 @network.py:203][0m step: 267200, current TD loss: 0.00113785266876
[32m[0315 21:33:31 @network.py:203][0m step: 267300, current TD loss: 0.00124649156351
[32m[0315 21:33:33 @network.py:203][0m step: 267400, current TD loss: 0.00297608529218
[32m[0315 21:33:34 @network.py:203][0m step: 267500, current TD loss: 0.00293487822637
[32m[0315 21:33:34 @dqn_agent.py:216][0m At time step 267500, the target_network is updated
[32m[0315 21:33:35 @network.py:203][0m step: 267600, current TD loss: 0.00127435824834
[32m[0315 21:33:36 @network.py:203][0m step: 267700, current TD loss: 0.00131212850101
[32m[0315 21:33:37 @network.py:203][0m step: 267800, current TD loss: 0.00202180515043
[32m[0315 21:33:39 @network.py:203][0m step: 267900, current TD loss: 0.0135957188904
[32m[0315 21:33:40 @dqn_agent.py:203][0m episode: 14039, total game step: 318000, epsilon: 0.73468099
[32m[0315 21:33:40 @network.py:203][0m step: 268000, current TD loss: 0.000863452092744
[32m[0315 21:33:41 @network.py:203][0m step: 268100, current TD loss: 0.00236319564283
[32m[0315 21:33:42 @network.py:203][0m step: 268200, current TD loss: 0.00597250368446
[32m[0315 21:33:43 @network.py:203][0m step: 268300, current TD loss: 0.00116546545178
[32m[0315 21:33:45 @network.py:203][0m step: 268400, current TD loss: 0.00752649828792
[32m[0315 21:33:46 @network.py:203][0m step: 268500, current TD loss: 0.00217026215978
[32m[0315 21:33:47 @network.py:203][0m step: 268600, current TD loss: 0.00662157684565
[32m[0315 21:33:48 @network.py:203][0m step: 268700, current TD loss: 0.00724795972928
[32m[0315 21:33:50 @network.py:203][0m step: 268800, current TD loss: 0.00343025196344
[32m[0315 21:33:51 @network.py:203][0m step: 268900, current TD loss: 0.00137933937367
[32m[0315 21:33:52 @dqn_agent.py:203][0m episode: 14083, total game step: 319000, epsilon: 0.73369099
[32m[0315 21:33:52 @network.py:203][0m step: 269000, current TD loss: 0.00268637528643
[32m[0315 21:33:53 @network.py:203][0m step: 269100, current TD loss: 0.00184641289525
[32m[0315 21:33:54 @network.py:203][0m step: 269200, current TD loss: 0.00298636034131
[32m[0315 21:33:56 @network.py:203][0m step: 269300, current TD loss: 0.00154409464449
[32m[0315 21:33:57 @network.py:203][0m step: 269400, current TD loss: 0.00275947060436
[32m[0315 21:33:58 @network.py:203][0m step: 269500, current TD loss: 0.00694041838869
[32m[0315 21:33:58 @summary_handler.py:101][0m At episode: 319526, Reward: 0.21 (over 100 episodes)
[32m[0315 21:33:58 @summary_handler.py:102][0m Length: 26.42
[32m[0315 21:33:59 @network.py:203][0m step: 269600, current TD loss: 0.00112275220454
[32m[0315 21:34:00 @network.py:203][0m step: 269700, current TD loss: 0.00735627487302
[32m[0315 21:34:02 @network.py:203][0m step: 269800, current TD loss: 0.00368899269961
[32m[0315 21:34:03 @network.py:203][0m step: 269900, current TD loss: 0.000586244859733
[32m[0315 21:34:04 @dqn_agent.py:203][0m episode: 14123, total game step: 320000, epsilon: 0.73270099
[32m[0315 21:34:04 @network.py:203][0m step: 270000, current TD loss: 0.00359121360816
[32m[0315 21:34:04 @dqn_agent.py:216][0m At time step 270000, the target_network is updated
[32m[0315 21:34:05 @network.py:203][0m step: 270100, current TD loss: 0.0139194708318
[32m[0315 21:34:07 @network.py:203][0m step: 270200, current TD loss: 0.00127490691375
[32m[0315 21:34:08 @network.py:203][0m step: 270300, current TD loss: 0.00116425822489
[32m[0315 21:34:09 @network.py:203][0m step: 270400, current TD loss: 0.00296997162513
[32m[0315 21:34:10 @network.py:203][0m step: 270500, current TD loss: 0.0109097789973
[32m[0315 21:34:12 @network.py:203][0m step: 270600, current TD loss: 0.00199421262369
[32m[0315 21:34:13 @network.py:203][0m step: 270700, current TD loss: 0.00388292269781
[32m[0315 21:34:14 @network.py:203][0m step: 270800, current TD loss: 0.00157933752052
[32m[0315 21:34:15 @network.py:203][0m step: 270900, current TD loss: 0.00145702902228
[32m[0315 21:34:17 @dqn_agent.py:203][0m episode: 14174, total game step: 321000, epsilon: 0.73171099
[32m[0315 21:34:17 @network.py:203][0m step: 271000, current TD loss: 0.00151685648598
[32m[0315 21:34:18 @network.py:203][0m step: 271100, current TD loss: 0.00154410628602
[32m[0315 21:34:19 @network.py:203][0m step: 271200, current TD loss: 0.00174416904338
[32m[0315 21:34:20 @network.py:203][0m step: 271300, current TD loss: 0.00368616031483
[32m[0315 21:34:21 @network.py:203][0m step: 271400, current TD loss: 0.00330801634118
[32m[0315 21:34:23 @network.py:203][0m step: 271500, current TD loss: 0.00170069071464
[32m[0315 21:34:23 @summary_handler.py:101][0m At episode: 321511, Reward: 0.12 (over 100 episodes)
[32m[0315 21:34:23 @summary_handler.py:102][0m Length: 19.85
[32m[0315 21:34:24 @network.py:203][0m step: 271600, current TD loss: 0.00609868811443
[32m[0315 21:34:25 @network.py:203][0m step: 271700, current TD loss: 0.00471380306408
[32m[0315 21:34:26 @network.py:203][0m step: 271800, current TD loss: 0.00149640114978
[32m[0315 21:34:28 @network.py:203][0m step: 271900, current TD loss: 0.00281611131504
[32m[0315 21:34:29 @dqn_agent.py:203][0m episode: 14222, total game step: 322000, epsilon: 0.73072099
[32m[0315 21:34:29 @network.py:203][0m step: 272000, current TD loss: 0.00073317240458
[32m[0315 21:34:30 @network.py:203][0m step: 272100, current TD loss: 0.000807649514172
[32m[0315 21:34:31 @network.py:203][0m step: 272200, current TD loss: 0.00127275567502
[32m[0315 21:34:32 @network.py:203][0m step: 272300, current TD loss: 0.0029760338366
[32m[0315 21:34:34 @network.py:203][0m step: 272400, current TD loss: 0.00208252645098
[32m[0315 21:34:35 @network.py:203][0m step: 272500, current TD loss: 0.0066314516589
[32m[0315 21:34:35 @dqn_agent.py:216][0m At time step 272500, the target_network is updated
[32m[0315 21:34:36 @network.py:203][0m step: 272600, current TD loss: 0.00583846587688
[32m[0315 21:34:38 @network.py:203][0m step: 272700, current TD loss: 0.00118675082922
[32m[0315 21:34:39 @network.py:203][0m step: 272800, current TD loss: 0.00238642236218
[32m[0315 21:34:40 @network.py:203][0m step: 272900, current TD loss: 0.0133026270196
[32m[0315 21:34:41 @dqn_agent.py:203][0m episode: 14267, total game step: 323000, epsilon: 0.72973099
[32m[0315 21:34:41 @network.py:203][0m step: 273000, current TD loss: 0.00164698413573
[32m[0315 21:34:43 @network.py:203][0m step: 273100, current TD loss: 0.00441874889657
[32m[0315 21:34:44 @network.py:203][0m step: 273200, current TD loss: 0.0011718980968
[32m[0315 21:34:45 @network.py:203][0m step: 273300, current TD loss: 0.00387710239738
[32m[0315 21:34:46 @network.py:203][0m step: 273400, current TD loss: 0.0166316963732
[32m[0315 21:34:47 @network.py:203][0m step: 273500, current TD loss: 0.00158106093295
[32m[0315 21:34:49 @network.py:203][0m step: 273600, current TD loss: 0.00112496502697
[32m[0315 21:34:50 @network.py:203][0m step: 273700, current TD loss: 0.00132543675136
[32m[0315 21:34:50 @summary_handler.py:101][0m At episode: 323704, Reward: 0.12 (over 100 episodes)
[32m[0315 21:34:50 @summary_handler.py:102][0m Length: 21.93
[32m[0315 21:34:51 @network.py:203][0m step: 273800, current TD loss: 0.000984740327112
[32m[0315 21:34:52 @network.py:203][0m step: 273900, current TD loss: 0.00160376960412
[32m[0315 21:34:53 @dqn_agent.py:203][0m episode: 14311, total game step: 324000, epsilon: 0.72874099
[32m[0315 21:34:54 @network.py:203][0m step: 274000, current TD loss: 0.00337298074737
[32m[0315 21:34:55 @network.py:203][0m step: 274100, current TD loss: 0.00134550617076
[32m[0315 21:34:56 @network.py:203][0m step: 274200, current TD loss: 0.001071300474
[32m[0315 21:34:57 @network.py:203][0m step: 274300, current TD loss: 0.00149057107046
[32m[0315 21:34:58 @network.py:203][0m step: 274400, current TD loss: 0.000537626212463
[32m[0315 21:35:00 @network.py:203][0m step: 274500, current TD loss: 0.00149493990466
[32m[0315 21:35:01 @network.py:203][0m step: 274600, current TD loss: 0.00286440690979
[32m[0315 21:35:02 @network.py:203][0m step: 274700, current TD loss: 0.0156568922102
[32m[0315 21:35:03 @network.py:203][0m step: 274800, current TD loss: 0.00147058907896
[32m[0315 21:35:04 @network.py:203][0m step: 274900, current TD loss: 0.0013003074564
[32m[0315 21:35:06 @dqn_agent.py:203][0m episode: 14353, total game step: 325000, epsilon: 0.72775099
[32m[0315 21:35:06 @network.py:203][0m step: 275000, current TD loss: 0.00151604646817
[32m[0315 21:35:06 @dqn_agent.py:216][0m At time step 275000, the target_network is updated
[32m[0315 21:35:07 @network.py:203][0m step: 275100, current TD loss: 0.00288382451981
[32m[0315 21:35:08 @network.py:203][0m step: 275200, current TD loss: 0.00152103463188
[32m[0315 21:35:09 @network.py:203][0m step: 275300, current TD loss: 0.00372914131731
[32m[0315 21:35:11 @network.py:203][0m step: 275400, current TD loss: 0.0146862734109
[32m[0315 21:35:12 @network.py:203][0m step: 275500, current TD loss: 0.00328097306192
[32m[0315 21:35:13 @network.py:203][0m step: 275600, current TD loss: 0.0030331662856
[32m[0315 21:35:14 @network.py:203][0m step: 275700, current TD loss: 0.00181911350228
[32m[0315 21:35:15 @network.py:203][0m step: 275800, current TD loss: 0.00216702441685
[32m[0315 21:35:17 @network.py:203][0m step: 275900, current TD loss: 0.00101309432648
[32m[0315 21:35:18 @summary_handler.py:101][0m At episode: 325989, Reward: 0.18 (over 100 episodes)
[32m[0315 21:35:18 @summary_handler.py:102][0m Length: 22.85
[32m[0315 21:35:18 @dqn_agent.py:203][0m episode: 14400, total game step: 326000, epsilon: 0.72676099
[32m[0315 21:35:18 @network.py:203][0m step: 276000, current TD loss: 0.000852690311149
[32m[0315 21:35:20 @network.py:203][0m step: 276100, current TD loss: 0.00539023429155
[32m[0315 21:35:21 @network.py:203][0m step: 276200, current TD loss: 0.00222063437104
[32m[0315 21:35:22 @network.py:203][0m step: 276300, current TD loss: 0.00140848208684
[32m[0315 21:35:24 @network.py:203][0m step: 276400, current TD loss: 0.00106572650839
[32m[0315 21:35:25 @network.py:203][0m step: 276500, current TD loss: 0.00931877829134
[32m[0315 21:35:26 @network.py:203][0m step: 276600, current TD loss: 0.00212786463089
[32m[0315 21:35:28 @network.py:203][0m step: 276700, current TD loss: 0.00178858230356
[32m[0315 21:35:29 @network.py:203][0m step: 276800, current TD loss: 0.00126142601948
[32m[0315 21:35:30 @network.py:203][0m step: 276900, current TD loss: 0.00145732413512
[32m[0315 21:35:32 @dqn_agent.py:203][0m episode: 14443, total game step: 327000, epsilon: 0.72577099
[32m[0315 21:35:32 @network.py:203][0m step: 277000, current TD loss: 0.000804031209555
[32m[0315 21:35:33 @network.py:203][0m step: 277100, current TD loss: 0.00127749494277
[32m[0315 21:35:34 @network.py:203][0m step: 277200, current TD loss: 0.00140159018338
[32m[0315 21:35:36 @network.py:203][0m step: 277300, current TD loss: 0.00148372817785
[32m[0315 21:35:37 @network.py:203][0m step: 277400, current TD loss: 0.00221839360893
[32m[0315 21:35:38 @network.py:203][0m step: 277500, current TD loss: 0.00692222453654
[32m[0315 21:35:38 @dqn_agent.py:216][0m At time step 277500, the target_network is updated
[32m[0315 21:35:40 @network.py:203][0m step: 277600, current TD loss: 0.0130542144179
[32m[0315 21:35:41 @network.py:203][0m step: 277700, current TD loss: 0.00310766277835
[32m[0315 21:35:42 @network.py:203][0m step: 277800, current TD loss: 0.00704648019746
[32m[0315 21:35:44 @network.py:203][0m step: 277900, current TD loss: 0.00101777142845
[32m[0315 21:35:45 @dqn_agent.py:203][0m episode: 14486, total game step: 328000, epsilon: 0.72478099
[32m[0315 21:35:45 @network.py:203][0m step: 278000, current TD loss: 0.00515676243231
[32m[0315 21:35:47 @network.py:203][0m step: 278100, current TD loss: 0.00294719915837
[32m[0315 21:35:48 @network.py:203][0m step: 278200, current TD loss: 0.000615614466369
[32m[0315 21:35:49 @summary_handler.py:101][0m At episode: 328270, Reward: 0.17 (over 100 episodes)
[32m[0315 21:35:49 @summary_handler.py:102][0m Length: 22.81
[32m[0315 21:35:49 @network.py:203][0m step: 278300, current TD loss: 0.00165687431581
[32m[0315 21:35:51 @network.py:203][0m step: 278400, current TD loss: 0.00151537987404
[32m[0315 21:35:52 @network.py:203][0m step: 278500, current TD loss: 0.00117733574007
[32m[0315 21:35:53 @network.py:203][0m step: 278600, current TD loss: 0.00450148526579
[32m[0315 21:35:55 @network.py:203][0m step: 278700, current TD loss: 0.000890920462552
[32m[0315 21:35:56 @network.py:203][0m step: 278800, current TD loss: 0.00209169182926
[32m[0315 21:35:57 @network.py:203][0m step: 278900, current TD loss: 0.00282041775063
[32m[0315 21:35:59 @dqn_agent.py:203][0m episode: 14532, total game step: 329000, epsilon: 0.72379099
[32m[0315 21:35:59 @network.py:203][0m step: 279000, current TD loss: 0.00209503760561
[32m[0315 21:36:00 @network.py:203][0m step: 279100, current TD loss: 0.0122305136174
[32m[0315 21:36:01 @network.py:203][0m step: 279200, current TD loss: 0.00195175525732
[32m[0315 21:36:03 @network.py:203][0m step: 279300, current TD loss: 0.00164961826522
[32m[0315 21:36:04 @network.py:203][0m step: 279400, current TD loss: 0.00233845645562
[32m[0315 21:36:06 @network.py:203][0m step: 279500, current TD loss: 0.00252762925811
[32m[0315 21:36:07 @network.py:203][0m step: 279600, current TD loss: 0.00806237012148
[32m[0315 21:36:08 @network.py:203][0m step: 279700, current TD loss: 0.00816899165511
[32m[0315 21:36:10 @network.py:203][0m step: 279800, current TD loss: 0.00173381972127
[32m[0315 21:36:11 @network.py:203][0m step: 279900, current TD loss: 0.013335281983
[32m[0315 21:36:12 @dqn_agent.py:203][0m episode: 14582, total game step: 330000, epsilon: 0.72280099
[32m[0315 21:36:12 @network.py:203][0m step: 280000, current TD loss: 0.00072813074803
[32m[0315 21:36:12 @dqn_agent.py:216][0m At time step 280000, the target_network is updated
[32m[0315 21:36:14 @network.py:203][0m step: 280100, current TD loss: 0.00102243665606
[32m[0315 21:36:15 @network.py:203][0m step: 280200, current TD loss: 0.00299694295973
[32m[0315 21:36:16 @network.py:203][0m step: 280300, current TD loss: 0.00178536679596
[32m[0315 21:36:18 @network.py:203][0m step: 280400, current TD loss: 0.0032529393211
[32m[0315 21:36:18 @summary_handler.py:101][0m At episode: 330420, Reward: 0.13 (over 100 episodes)
[32m[0315 21:36:18 @summary_handler.py:102][0m Length: 21.5
[32m[0315 21:36:19 @network.py:203][0m step: 280500, current TD loss: 0.00585151743144
[32m[0315 21:36:20 @network.py:203][0m step: 280600, current TD loss: 0.000629379588645
[32m[0315 21:36:22 @network.py:203][0m step: 280700, current TD loss: 0.00420500058681
[32m[0315 21:36:23 @network.py:203][0m step: 280800, current TD loss: 0.0015732164029
[32m[0315 21:36:25 @network.py:203][0m step: 280900, current TD loss: 0.000209475067095
[32m[0315 21:36:26 @dqn_agent.py:203][0m episode: 14629, total game step: 331000, epsilon: 0.72181099
[32m[0315 21:36:26 @network.py:203][0m step: 281000, current TD loss: 0.00192362046801
[32m[0315 21:36:27 @network.py:203][0m step: 281100, current TD loss: 0.00187808880582
[32m[0315 21:36:29 @network.py:203][0m step: 281200, current TD loss: 0.0122251594439
[32m[0315 21:36:30 @network.py:203][0m step: 281300, current TD loss: 0.00173078279477
[32m[0315 21:36:31 @network.py:203][0m step: 281400, current TD loss: 0.000175833818503
[32m[0315 21:36:33 @network.py:203][0m step: 281500, current TD loss: 0.000883852364495
[32m[0315 21:36:34 @network.py:203][0m step: 281600, current TD loss: 0.00197244202718
[32m[0315 21:36:35 @network.py:203][0m step: 281700, current TD loss: 0.00279819173738
[32m[0315 21:36:37 @network.py:203][0m step: 281800, current TD loss: 0.00100296211895
[32m[0315 21:36:38 @network.py:203][0m step: 281900, current TD loss: 0.00129336351529
[32m[0315 21:36:39 @dqn_agent.py:203][0m episode: 14678, total game step: 332000, epsilon: 0.72082099
[32m[0315 21:36:39 @network.py:203][0m step: 282000, current TD loss: 0.00381602253765
[32m[0315 21:36:41 @network.py:203][0m step: 282100, current TD loss: 0.00350135192275
[32m[0315 21:36:42 @network.py:203][0m step: 282200, current TD loss: 0.00193277793005
[32m[0315 21:36:43 @network.py:203][0m step: 282300, current TD loss: 0.000905528431758
[32m[0315 21:36:45 @network.py:203][0m step: 282400, current TD loss: 0.000878456165083
[32m[0315 21:36:45 @summary_handler.py:101][0m At episode: 332470, Reward: 0.11 (over 100 episodes)
[32m[0315 21:36:46 @summary_handler.py:102][0m Length: 20.5
[32m[0315 21:36:46 @network.py:203][0m step: 282500, current TD loss: 0.00307609583251
[32m[0315 21:36:46 @dqn_agent.py:216][0m At time step 282500, the target_network is updated
[32m[0315 21:36:47 @network.py:203][0m step: 282600, current TD loss: 0.00451664160937
[32m[0315 21:36:49 @network.py:203][0m step: 282700, current TD loss: 0.00522835971788
[32m[0315 21:36:50 @network.py:203][0m step: 282800, current TD loss: 0.0022609946318
[32m[0315 21:36:51 @network.py:203][0m step: 282900, current TD loss: 0.0158705040812
[32m[0315 21:36:53 @dqn_agent.py:203][0m episode: 14725, total game step: 333000, epsilon: 0.71983099
[32m[0315 21:36:53 @network.py:203][0m step: 283000, current TD loss: 0.00233056815341
[32m[0315 21:36:54 @network.py:203][0m step: 283100, current TD loss: 0.025197647512
[32m[0315 21:36:55 @network.py:203][0m step: 283200, current TD loss: 0.00349479983561
[32m[0315 21:36:57 @network.py:203][0m step: 283300, current TD loss: 0.0129071781412
[32m[0315 21:36:58 @network.py:203][0m step: 283400, current TD loss: 0.00112348888069
[32m[0315 21:36:59 @network.py:203][0m step: 283500, current TD loss: 0.0012856607791
[32m[0315 21:37:01 @network.py:203][0m step: 283600, current TD loss: 0.00194444973022
[32m[0315 21:37:02 @network.py:203][0m step: 283700, current TD loss: 0.0011513705831
[32m[0315 21:37:03 @network.py:203][0m step: 283800, current TD loss: 0.000693397130817
[32m[0315 21:37:05 @network.py:203][0m step: 283900, current TD loss: 0.00108721922152
[32m[0315 21:37:06 @dqn_agent.py:203][0m episode: 14775, total game step: 334000, epsilon: 0.71884099
[32m[0315 21:37:06 @network.py:203][0m step: 284000, current TD loss: 0.015538437292
[32m[0315 21:37:07 @network.py:203][0m step: 284100, current TD loss: 0.0132370125502
[32m[0315 21:37:09 @network.py:203][0m step: 284200, current TD loss: 0.00201644585468
[32m[0315 21:37:10 @network.py:203][0m step: 284300, current TD loss: 0.00164391018916
[32m[0315 21:37:11 @network.py:203][0m step: 284400, current TD loss: 0.000733379391022
[32m[0315 21:37:13 @network.py:203][0m step: 284500, current TD loss: 0.000934690644499
[32m[0315 21:37:14 @summary_handler.py:101][0m At episode: 334571, Reward: 0.1 (over 100 episodes)
[32m[0315 21:37:14 @summary_handler.py:102][0m Length: 21.01
[32m[0315 21:37:14 @network.py:203][0m step: 284600, current TD loss: 0.00732315704226
[32m[0315 21:37:16 @network.py:203][0m step: 284700, current TD loss: 0.00910376291722
[32m[0315 21:37:17 @network.py:203][0m step: 284800, current TD loss: 0.00241373246536
[32m[0315 21:37:18 @network.py:203][0m step: 284900, current TD loss: 0.00122887408361
[32m[0315 21:37:20 @dqn_agent.py:203][0m episode: 14820, total game step: 335000, epsilon: 0.71785099
[32m[0315 21:37:20 @network.py:203][0m step: 285000, current TD loss: 0.00241951784119
[32m[0315 21:37:20 @dqn_agent.py:216][0m At time step 285000, the target_network is updated
[32m[0315 21:37:21 @network.py:203][0m step: 285100, current TD loss: 0.00247421930544
[32m[0315 21:37:22 @network.py:203][0m step: 285200, current TD loss: 0.00129563640803
[32m[0315 21:37:24 @network.py:203][0m step: 285300, current TD loss: 0.00272085494362
[32m[0315 21:37:25 @network.py:203][0m step: 285400, current TD loss: 0.00274833128788
[32m[0315 21:37:26 @network.py:203][0m step: 285500, current TD loss: 0.00108157133218
[32m[0315 21:37:28 @network.py:203][0m step: 285600, current TD loss: 0.00473939580843
[32m[0315 21:37:29 @network.py:203][0m step: 285700, current TD loss: 0.00581053225324
[32m[0315 21:37:30 @network.py:203][0m step: 285800, current TD loss: 0.00241881632246
[32m[0315 21:37:32 @network.py:203][0m step: 285900, current TD loss: 0.00099339755252
[32m[0315 21:37:33 @dqn_agent.py:203][0m episode: 14860, total game step: 336000, epsilon: 0.71686099
[32m[0315 21:37:33 @network.py:203][0m step: 286000, current TD loss: 0.00229907757603
[32m[0315 21:37:34 @network.py:203][0m step: 286100, current TD loss: 0.00164037279319
[32m[0315 21:37:36 @network.py:203][0m step: 286200, current TD loss: 0.000233895581914
[32m[0315 21:37:37 @network.py:203][0m step: 286300, current TD loss: 0.0089434562251
[32m[0315 21:37:38 @network.py:203][0m step: 286400, current TD loss: 0.00937016494572
[32m[0315 21:37:40 @network.py:203][0m step: 286500, current TD loss: 0.00223137345165
[32m[0315 21:37:41 @network.py:203][0m step: 286600, current TD loss: 0.00774622429162
[32m[0315 21:37:43 @network.py:203][0m step: 286700, current TD loss: 0.00408739037812
[32m[0315 21:37:43 @summary_handler.py:101][0m At episode: 336749, Reward: 0.1 (over 100 episodes)
[32m[0315 21:37:43 @summary_handler.py:102][0m Length: 21.78
[32m[0315 21:37:44 @network.py:203][0m step: 286800, current TD loss: 0.00484535144642
[32m[0315 21:37:45 @network.py:203][0m step: 286900, current TD loss: 0.00126029772218
[32m[0315 21:37:47 @dqn_agent.py:203][0m episode: 14913, total game step: 337000, epsilon: 0.71587099
[32m[0315 21:37:47 @network.py:203][0m step: 287000, current TD loss: 0.00194221269339
[32m[0315 21:37:48 @network.py:203][0m step: 287100, current TD loss: 0.000948986096773
[32m[0315 21:37:49 @network.py:203][0m step: 287200, current TD loss: 0.000780313042924
[32m[0315 21:37:51 @network.py:203][0m step: 287300, current TD loss: 0.0109025472775
[32m[0315 21:37:52 @network.py:203][0m step: 287400, current TD loss: 0.00292507838458
[32m[0315 21:37:53 @network.py:203][0m step: 287500, current TD loss: 0.00257582310587
[32m[0315 21:37:53 @dqn_agent.py:216][0m At time step 287500, the target_network is updated
[32m[0315 21:37:55 @network.py:203][0m step: 287600, current TD loss: 0.00124004692771
[32m[0315 21:37:56 @network.py:203][0m step: 287700, current TD loss: 0.00332918181084
[32m[0315 21:37:57 @network.py:203][0m step: 287800, current TD loss: 0.0157968625426
[32m[0315 21:37:59 @network.py:203][0m step: 287900, current TD loss: 0.00736491475254
[32m[0315 21:38:00 @dqn_agent.py:203][0m episode: 14950, total game step: 338000, epsilon: 0.71488099
[32m[0315 21:38:00 @network.py:203][0m step: 288000, current TD loss: 0.00175329891499
[32m[0315 21:38:01 @network.py:203][0m step: 288100, current TD loss: 0.00114038493484
[32m[0315 21:38:03 @network.py:203][0m step: 288200, current TD loss: 0.00391799677163
[32m[0315 21:38:04 @network.py:203][0m step: 288300, current TD loss: 0.00212207529694
[32m[0315 21:38:06 @network.py:203][0m step: 288400, current TD loss: 0.00118330400437
[32m[0315 21:38:07 @network.py:203][0m step: 288500, current TD loss: 0.0110529931262
[32m[0315 21:38:08 @network.py:203][0m step: 288600, current TD loss: 0.00243960530497
[32m[0315 21:38:10 @network.py:203][0m step: 288700, current TD loss: 0.00088796147611
[32m[0315 21:38:11 @network.py:203][0m step: 288800, current TD loss: 0.00133948214352
[32m[0315 21:38:12 @network.py:203][0m step: 288900, current TD loss: 0.00286083342507
[32m[0315 21:38:14 @dqn_agent.py:203][0m episode: 14994, total game step: 339000, epsilon: 0.71389099
[32m[0315 21:38:14 @network.py:203][0m step: 289000, current TD loss: 0.00132921407931
[32m[0315 21:38:15 @network.py:203][0m step: 289100, current TD loss: 0.00195392314345
[32m[0315 21:38:16 @summary_handler.py:101][0m At episode: 339151, Reward: 0.14 (over 100 episodes)
[32m[0315 21:38:16 @summary_handler.py:102][0m Length: 24.02
[32m[0315 21:38:16 @network.py:203][0m step: 289200, current TD loss: 0.00114385585766
[32m[0315 21:38:18 @network.py:203][0m step: 289300, current TD loss: 0.00961416494101
[32m[0315 21:38:19 @network.py:203][0m step: 289400, current TD loss: 0.00973786972463
[32m[0315 21:38:20 @network.py:203][0m step: 289500, current TD loss: 0.00179034494795
[32m[0315 21:38:22 @network.py:203][0m step: 289600, current TD loss: 0.0018300851807
[32m[0315 21:38:23 @network.py:203][0m step: 289700, current TD loss: 0.00157052988652
[32m[0315 21:38:25 @network.py:203][0m step: 289800, current TD loss: 0.00577093567699
[32m[0315 21:38:26 @network.py:203][0m step: 289900, current TD loss: 0.00261481595226
[32m[0315 21:38:27 @dqn_agent.py:203][0m episode: 15031, total game step: 340000, epsilon: 0.71290099
[32m[0315 21:38:27 @network.py:203][0m step: 290000, current TD loss: 0.00205791881308
[32m[0315 21:38:27 @dqn_agent.py:216][0m At time step 290000, the target_network is updated
[32m[0315 21:38:29 @network.py:203][0m step: 290100, current TD loss: 0.00250269961543
[32m[0315 21:38:30 @network.py:203][0m step: 290200, current TD loss: 0.00170280924067
[32m[0315 21:38:32 @network.py:203][0m step: 290300, current TD loss: 0.00204738322645
[32m[0315 21:38:33 @network.py:203][0m step: 290400, current TD loss: 0.00381572940387
[32m[0315 21:38:35 @network.py:203][0m step: 290500, current TD loss: 0.0130436839536
[32m[0315 21:38:36 @network.py:203][0m step: 290600, current TD loss: 0.00212753168307
[32m[0315 21:38:38 @network.py:203][0m step: 290700, current TD loss: 0.00120533758309
[32m[0315 21:38:39 @network.py:203][0m step: 290800, current TD loss: 0.00380553514697
[32m[0315 21:38:41 @network.py:203][0m step: 290900, current TD loss: 0.00758216064423
[32m[0315 21:38:42 @dqn_agent.py:203][0m episode: 15083, total game step: 341000, epsilon: 0.71191099
[32m[0315 21:38:42 @network.py:203][0m step: 291000, current TD loss: 0.0032164810691
[32m[0315 21:38:43 @network.py:203][0m step: 291100, current TD loss: 0.00117623806
[32m[0315 21:38:45 @network.py:203][0m step: 291200, current TD loss: 0.036679700017
[32m[0315 21:38:46 @network.py:203][0m step: 291300, current TD loss: 0.00199464918114
[32m[0315 21:38:48 @network.py:203][0m step: 291400, current TD loss: 0.0050817783922
[32m[0315 21:38:48 @summary_handler.py:101][0m At episode: 341422, Reward: 0.15 (over 100 episodes)
[32m[0315 21:38:48 @summary_handler.py:102][0m Length: 22.71
[32m[0315 21:38:49 @network.py:203][0m step: 291500, current TD loss: 0.0022999800276
[32m[0315 21:38:51 @network.py:203][0m step: 291600, current TD loss: 0.00208560936153
[32m[0315 21:38:52 @network.py:203][0m step: 291700, current TD loss: 0.0109868273139
[32m[0315 21:38:54 @network.py:203][0m step: 291800, current TD loss: 0.00352952745743
[32m[0315 21:38:55 @network.py:203][0m step: 291900, current TD loss: 0.00137624365743
[32m[0315 21:38:57 @dqn_agent.py:203][0m episode: 15131, total game step: 342000, epsilon: 0.71092099
[32m[0315 21:38:57 @network.py:203][0m step: 292000, current TD loss: 0.00156213459559
[32m[0315 21:38:58 @network.py:203][0m step: 292100, current TD loss: 0.00121616735123
[32m[0315 21:39:00 @network.py:203][0m step: 292200, current TD loss: 0.0195849724114
[32m[0315 21:39:01 @network.py:203][0m step: 292300, current TD loss: 0.00272955861874
[32m[0315 21:39:03 @network.py:203][0m step: 292400, current TD loss: 0.00246310862713
[32m[0315 21:39:04 @network.py:203][0m step: 292500, current TD loss: 0.00132626702543
[32m[0315 21:39:04 @dqn_agent.py:216][0m At time step 292500, the target_network is updated
[32m[0315 21:39:06 @network.py:203][0m step: 292600, current TD loss: 0.00302319647744
[32m[0315 21:39:07 @network.py:203][0m step: 292700, current TD loss: 0.0119378054515
[32m[0315 21:39:08 @network.py:203][0m step: 292800, current TD loss: 0.00174637499731
[32m[0315 21:39:10 @network.py:203][0m step: 292900, current TD loss: 0.00120887567755
[32m[0315 21:39:11 @dqn_agent.py:203][0m episode: 15166, total game step: 343000, epsilon: 0.70993099
[32m[0315 21:39:11 @network.py:203][0m step: 293000, current TD loss: 0.00224953843281
[32m[0315 21:39:13 @network.py:203][0m step: 293100, current TD loss: 0.00092123565264
[32m[0315 21:39:14 @network.py:203][0m step: 293200, current TD loss: 0.000841617817059
[32m[0315 21:39:16 @network.py:203][0m step: 293300, current TD loss: 0.00311372661963
[32m[0315 21:39:17 @network.py:203][0m step: 293400, current TD loss: 0.00244099413976
[32m[0315 21:39:19 @network.py:203][0m step: 293500, current TD loss: 0.0106989620253
[32m[0315 21:39:20 @network.py:203][0m step: 293600, current TD loss: 0.00202552624978
[32m[0315 21:39:22 @network.py:203][0m step: 293700, current TD loss: 0.00117022939958
[32m[0315 21:39:23 @summary_handler.py:101][0m At episode: 343767, Reward: 0.15 (over 100 episodes)
[32m[0315 21:39:23 @summary_handler.py:102][0m Length: 23.45
[32m[0315 21:39:23 @network.py:203][0m step: 293800, current TD loss: 0.00170328444801
[32m[0315 21:39:25 @network.py:203][0m step: 293900, current TD loss: 0.00377032044344
[32m[0315 21:39:26 @dqn_agent.py:203][0m episode: 15206, total game step: 344000, epsilon: 0.70894099
[32m[0315 21:39:26 @network.py:203][0m step: 294000, current TD loss: 0.00137605634518
[32m[0315 21:39:27 @network.py:203][0m step: 294100, current TD loss: 0.00152788660489
[32m[0315 21:39:29 @network.py:203][0m step: 294200, current TD loss: 0.0025072125718
[32m[0315 21:39:30 @network.py:203][0m step: 294300, current TD loss: 0.00878379214555
[32m[0315 21:39:32 @network.py:203][0m step: 294400, current TD loss: 0.00157263467554
[32m[0315 21:39:33 @network.py:203][0m step: 294500, current TD loss: 0.0027271094732
[32m[0315 21:39:35 @network.py:203][0m step: 294600, current TD loss: 0.00191580574028
[32m[0315 21:39:36 @network.py:203][0m step: 294700, current TD loss: 0.00609308760613
[32m[0315 21:39:38 @network.py:203][0m step: 294800, current TD loss: 0.00169031368569
[32m[0315 21:39:39 @network.py:203][0m step: 294900, current TD loss: 0.0011361381039
[32m[0315 21:39:41 @dqn_agent.py:203][0m episode: 15247, total game step: 345000, epsilon: 0.70795099
[32m[0315 21:39:41 @network.py:203][0m step: 295000, current TD loss: 0.00393720716238
[32m[0315 21:39:41 @dqn_agent.py:216][0m At time step 295000, the target_network is updated
[32m[0315 21:39:42 @network.py:203][0m step: 295100, current TD loss: 0.00171033851802
[32m[0315 21:39:44 @network.py:203][0m step: 295200, current TD loss: 0.00317291356623
[32m[0315 21:39:45 @network.py:203][0m step: 295300, current TD loss: 0.00359816616401
[32m[0315 21:39:47 @network.py:203][0m step: 295400, current TD loss: 0.00335319247097
[32m[0315 21:39:48 @network.py:203][0m step: 295500, current TD loss: 0.0175075531006
[32m[0315 21:39:49 @network.py:203][0m step: 295600, current TD loss: 0.00733459694311
[32m[0315 21:39:51 @network.py:203][0m step: 295700, current TD loss: 0.0027881283313
[32m[0315 21:39:53 @network.py:203][0m step: 295800, current TD loss: 0.00345504865982
[32m[0315 21:39:54 @network.py:203][0m step: 295900, current TD loss: 0.00111608649604
[32m[0315 21:39:55 @dqn_agent.py:203][0m episode: 15287, total game step: 346000, epsilon: 0.70696099
[32m[0315 21:39:55 @network.py:203][0m step: 296000, current TD loss: 0.00347770052031
[32m[0315 21:39:57 @network.py:203][0m step: 296100, current TD loss: 0.00135413452517
[32m[0315 21:39:59 @network.py:203][0m step: 296200, current TD loss: 0.00168992532417
[32m[0315 21:40:00 @summary_handler.py:101][0m At episode: 346275, Reward: 0.18 (over 100 episodes)
[32m[0315 21:40:00 @summary_handler.py:102][0m Length: 25.08
[32m[0315 21:40:00 @network.py:203][0m step: 296300, current TD loss: 0.000994646688923
[32m[0315 21:40:02 @network.py:203][0m step: 296400, current TD loss: 0.00165553682018
[32m[0315 21:40:03 @network.py:203][0m step: 296500, current TD loss: 0.00208391435444
[32m[0315 21:40:05 @network.py:203][0m step: 296600, current TD loss: 0.00859916489571
[32m[0315 21:40:06 @network.py:203][0m step: 296700, current TD loss: 0.0013504428789
[32m[0315 21:40:08 @network.py:203][0m step: 296800, current TD loss: 0.00187533348799
[32m[0315 21:40:09 @network.py:203][0m step: 296900, current TD loss: 0.0047285030596
[32m[0315 21:40:11 @dqn_agent.py:203][0m episode: 15332, total game step: 347000, epsilon: 0.70597099
[32m[0315 21:40:11 @network.py:203][0m step: 297000, current TD loss: 0.00245303288102
[32m[0315 21:40:12 @network.py:203][0m step: 297100, current TD loss: 0.00561600271612
[32m[0315 21:40:14 @network.py:203][0m step: 297200, current TD loss: 0.00306892301887
[32m[0315 21:40:15 @network.py:203][0m step: 297300, current TD loss: 0.000848368683364
[32m[0315 21:40:17 @network.py:203][0m step: 297400, current TD loss: 0.00211232085712
[32m[0315 21:40:18 @network.py:203][0m step: 297500, current TD loss: 0.00582373980433
[32m[0315 21:40:18 @dqn_agent.py:216][0m At time step 297500, the target_network is updated
[32m[0315 21:40:20 @network.py:203][0m step: 297600, current TD loss: 0.00142720690928
[32m[0315 21:40:21 @network.py:203][0m step: 297700, current TD loss: 0.00144860474393
[32m[0315 21:40:23 @network.py:203][0m step: 297800, current TD loss: 0.00239270064048
[32m[0315 21:40:24 @network.py:203][0m step: 297900, current TD loss: 0.00581131409854
[32m[0315 21:40:26 @dqn_agent.py:203][0m episode: 15375, total game step: 348000, epsilon: 0.70498099
[32m[0315 21:40:26 @network.py:203][0m step: 298000, current TD loss: 0.00182628375478
[32m[0315 21:40:27 @network.py:203][0m step: 298100, current TD loss: 0.00437002582476
[32m[0315 21:40:29 @network.py:203][0m step: 298200, current TD loss: 0.00249680527486
[32m[0315 21:40:30 @network.py:203][0m step: 298300, current TD loss: 0.00171733251773
[32m[0315 21:40:32 @network.py:203][0m step: 298400, current TD loss: 0.00131993880495
[32m[0315 21:40:33 @network.py:203][0m step: 298500, current TD loss: 0.00325147435069
[32m[0315 21:40:33 @summary_handler.py:101][0m At episode: 348500, Reward: 0.15 (over 100 episodes)
[32m[0315 21:40:33 @summary_handler.py:102][0m Length: 22.25
[32m[0315 21:40:35 @network.py:203][0m step: 298600, current TD loss: 0.00391345005482
[32m[0315 21:40:37 @network.py:203][0m step: 298700, current TD loss: 0.00204796064645
[32m[0315 21:40:38 @network.py:203][0m step: 298800, current TD loss: 0.00749279279262
[32m[0315 21:40:39 @network.py:203][0m step: 298900, current TD loss: 0.00192968070041
[32m[0315 21:40:41 @dqn_agent.py:203][0m episode: 15423, total game step: 349000, epsilon: 0.70399099
[32m[0315 21:40:41 @network.py:203][0m step: 299000, current TD loss: 0.018383782357
[32m[0315 21:40:43 @network.py:203][0m step: 299100, current TD loss: 0.00265960791148
[32m[0315 21:40:44 @network.py:203][0m step: 299200, current TD loss: 0.00261767441407
[32m[0315 21:40:46 @network.py:203][0m step: 299300, current TD loss: 0.00368622038513
[32m[0315 21:40:47 @network.py:203][0m step: 299400, current TD loss: 0.00118027254939
[32m[0315 21:40:49 @network.py:203][0m step: 299500, current TD loss: 0.00150260957889
[32m[0315 21:40:50 @network.py:203][0m step: 299600, current TD loss: 0.0024048006162
[32m[0315 21:40:52 @network.py:203][0m step: 299700, current TD loss: 0.00564815895632
[32m[0315 21:40:53 @network.py:203][0m step: 299800, current TD loss: 0.0162798501551
[32m[0315 21:40:55 @network.py:203][0m step: 299900, current TD loss: 0.00157336937264
[32m[0315 21:40:56 @dqn_agent.py:203][0m episode: 15472, total game step: 350000, epsilon: 0.70300099
[32m[0315 21:40:56 @network.py:203][0m step: 300000, current TD loss: 0.00167041923851
[32m[0315 21:40:56 @dqn_agent.py:216][0m At time step 300000, the target_network is updated
[32m[0315 21:40:58 @network.py:203][0m step: 300100, current TD loss: 0.014283509925
[32m[0315 21:40:59 @network.py:203][0m step: 300200, current TD loss: 0.00275263213553
[32m[0315 21:41:01 @network.py:203][0m step: 300300, current TD loss: 0.00212191510946
[32m[0315 21:41:02 @network.py:203][0m step: 300400, current TD loss: 0.0105520412326
[32m[0315 21:41:04 @network.py:203][0m step: 300500, current TD loss: 0.00631505530328
[32m[0315 21:41:05 @network.py:203][0m step: 300600, current TD loss: 0.00279755238444
[32m[0315 21:41:06 @summary_handler.py:101][0m At episode: 350629, Reward: 0.1 (over 100 episodes)
[32m[0315 21:41:06 @summary_handler.py:102][0m Length: 21.29
[32m[0315 21:41:07 @network.py:203][0m step: 300700, current TD loss: 0.00748838903382
[32m[0315 21:41:08 @network.py:203][0m step: 300800, current TD loss: 0.00757569726557
[32m[0315 21:41:10 @network.py:203][0m step: 300900, current TD loss: 0.00560317095369
[32m[0315 21:41:11 @dqn_agent.py:203][0m episode: 15521, total game step: 351000, epsilon: 0.70201099
[32m[0315 21:41:11 @network.py:203][0m step: 301000, current TD loss: 0.0062079206109
[32m[0315 21:41:12 @network.py:203][0m step: 301100, current TD loss: 0.0020168395713
[32m[0315 21:41:14 @network.py:203][0m step: 301200, current TD loss: 0.00267387577333
[32m[0315 21:41:15 @network.py:203][0m step: 301300, current TD loss: 0.00760275963694
[32m[0315 21:41:16 @network.py:203][0m step: 301400, current TD loss: 0.00280137127265
[32m[0315 21:41:18 @network.py:203][0m step: 301500, current TD loss: 0.0119764460251
[32m[0315 21:41:19 @network.py:203][0m step: 301600, current TD loss: 0.000882496184204
[32m[0315 21:41:20 @network.py:203][0m step: 301700, current TD loss: 0.000548993120901
[32m[0315 21:41:22 @network.py:203][0m step: 301800, current TD loss: 0.00242574280128
[32m[0315 21:41:23 @network.py:203][0m step: 301900, current TD loss: 0.00168626941741
[32m[0315 21:41:24 @dqn_agent.py:203][0m episode: 15565, total game step: 352000, epsilon: 0.70102099
[32m[0315 21:41:24 @network.py:203][0m step: 302000, current TD loss: 0.00588728860021
[32m[0315 21:41:26 @network.py:203][0m step: 302100, current TD loss: 0.00441443873569
[32m[0315 21:41:27 @network.py:203][0m step: 302200, current TD loss: 0.00187118945178
[32m[0315 21:41:28 @network.py:203][0m step: 302300, current TD loss: 0.00367171084508
[32m[0315 21:41:30 @network.py:203][0m step: 302400, current TD loss: 0.0103222727776
[32m[0315 21:41:31 @network.py:203][0m step: 302500, current TD loss: 0.000885523681063
[32m[0315 21:41:31 @dqn_agent.py:216][0m At time step 302500, the target_network is updated
[32m[0315 21:41:32 @network.py:203][0m step: 302600, current TD loss: 0.00526071386412
[32m[0315 21:41:34 @network.py:203][0m step: 302700, current TD loss: 0.00201506447047
[32m[0315 21:41:35 @network.py:203][0m step: 302800, current TD loss: 0.00392763316631
[32m[0315 21:41:36 @summary_handler.py:101][0m At episode: 352880, Reward: 0.15 (over 100 episodes)
[32m[0315 21:41:36 @summary_handler.py:102][0m Length: 22.51
[32m[0315 21:41:36 @network.py:203][0m step: 302900, current TD loss: 0.00223555741832
[32m[0315 21:41:38 @dqn_agent.py:203][0m episode: 15605, total game step: 353000, epsilon: 0.70003099
[32m[0315 21:41:38 @network.py:203][0m step: 303000, current TD loss: 0.00310123781674
[32m[0315 21:41:39 @network.py:203][0m step: 303100, current TD loss: 0.00274777295999
[32m[0315 21:41:40 @network.py:203][0m step: 303200, current TD loss: 0.00091343652457
[32m[0315 21:41:42 @network.py:203][0m step: 303300, current TD loss: 0.00154281454161
[32m[0315 21:41:43 @network.py:203][0m step: 303400, current TD loss: 0.00129345362075
[32m[0315 21:41:44 @network.py:203][0m step: 303500, current TD loss: 0.00431164074689
[32m[0315 21:41:46 @network.py:203][0m step: 303600, current TD loss: 0.00153123750351
[32m[0315 21:41:47 @network.py:203][0m step: 303700, current TD loss: 0.000984246144071
[32m[0315 21:41:48 @network.py:203][0m step: 303800, current TD loss: 0.00214981148019
[32m[0315 21:41:50 @network.py:203][0m step: 303900, current TD loss: 0.00115041574463
[32m[0315 21:41:51 @dqn_agent.py:203][0m episode: 15643, total game step: 354000, epsilon: 0.69904099
[32m[0315 21:41:51 @network.py:203][0m step: 304000, current TD loss: 0.00215049041435
[32m[0315 21:41:52 @network.py:203][0m step: 304100, current TD loss: 0.00300654047169
[32m[0315 21:41:54 @network.py:203][0m step: 304200, current TD loss: 0.00111596030183
[32m[0315 21:41:55 @network.py:203][0m step: 304300, current TD loss: 0.000771517632529
[32m[0315 21:41:56 @network.py:203][0m step: 304400, current TD loss: 0.00259306561202
[32m[0315 21:41:58 @network.py:203][0m step: 304500, current TD loss: 0.00619533890858
[32m[0315 21:41:59 @network.py:203][0m step: 304600, current TD loss: 0.00738596729934
[32m[0315 21:42:01 @network.py:203][0m step: 304700, current TD loss: 0.00513250287622
[32m[0315 21:42:02 @network.py:203][0m step: 304800, current TD loss: 0.00267559848726
[32m[0315 21:42:03 @network.py:203][0m step: 304900, current TD loss: 0.00340236490592
[32m[0315 21:42:05 @dqn_agent.py:203][0m episode: 15692, total game step: 355000, epsilon: 0.69805099
[32m[0315 21:42:05 @network.py:203][0m step: 305000, current TD loss: 0.00293736089952
[32m[0315 21:42:05 @dqn_agent.py:216][0m At time step 305000, the target_network is updated
[32m[0315 21:42:06 @network.py:203][0m step: 305100, current TD loss: 0.00181119667832
[32m[0315 21:42:07 @summary_handler.py:101][0m At episode: 355150, Reward: 0.17 (over 100 episodes)
[32m[0315 21:42:07 @summary_handler.py:102][0m Length: 22.7
[32m[0315 21:42:07 @network.py:203][0m step: 305200, current TD loss: 0.00126612535678
[32m[0315 21:42:09 @network.py:203][0m step: 305300, current TD loss: 0.00808516982943
[32m[0315 21:42:10 @network.py:203][0m step: 305400, current TD loss: 0.0083547020331
[32m[0315 21:42:11 @network.py:203][0m step: 305500, current TD loss: 0.00171926384792
[32m[0315 21:42:13 @network.py:203][0m step: 305600, current TD loss: 0.00361296790652
[32m[0315 21:42:14 @network.py:203][0m step: 305700, current TD loss: 0.00210769311525
[32m[0315 21:42:16 @network.py:203][0m step: 305800, current TD loss: 0.00353929004632
[32m[0315 21:42:17 @network.py:203][0m step: 305900, current TD loss: 0.00157057936303
[32m[0315 21:42:18 @dqn_agent.py:203][0m episode: 15744, total game step: 356000, epsilon: 0.69706099
[32m[0315 21:42:18 @network.py:203][0m step: 306000, current TD loss: 0.00208189967088
[32m[0315 21:42:20 @network.py:203][0m step: 306100, current TD loss: 0.00191669585183
[32m[0315 21:42:21 @network.py:203][0m step: 306200, current TD loss: 0.00179167883471
[32m[0315 21:42:23 @network.py:203][0m step: 306300, current TD loss: 0.0174366291612
[32m[0315 21:42:24 @network.py:203][0m step: 306400, current TD loss: 0.0158289093524
[32m[0315 21:42:25 @network.py:203][0m step: 306500, current TD loss: 0.00181300193071
[32m[0315 21:42:27 @network.py:203][0m step: 306600, current TD loss: 0.00139727082569
[32m[0315 21:42:28 @network.py:203][0m step: 306700, current TD loss: 0.00137402873952
[32m[0315 21:42:29 @network.py:203][0m step: 306800, current TD loss: 0.00304177775979
[32m[0315 21:42:31 @network.py:203][0m step: 306900, current TD loss: 0.0066561116837
[32m[0315 21:42:32 @dqn_agent.py:203][0m episode: 15799, total game step: 357000, epsilon: 0.69607099
[32m[0315 21:42:32 @network.py:203][0m step: 307000, current TD loss: 0.00248899497092
[32m[0315 21:42:33 @summary_handler.py:101][0m At episode: 357038, Reward: 0.07 (over 100 episodes)
[32m[0315 21:42:33 @summary_handler.py:102][0m Length: 18.88
[32m[0315 21:42:34 @network.py:203][0m step: 307100, current TD loss: 0.00501990551129
[32m[0315 21:42:35 @network.py:203][0m step: 307200, current TD loss: 0.0019490099512
[32m[0315 21:42:36 @network.py:203][0m step: 307300, current TD loss: 0.000845538976137
[32m[0315 21:42:38 @network.py:203][0m step: 307400, current TD loss: 0.0212819986045
[32m[0315 21:42:39 @network.py:203][0m step: 307500, current TD loss: 0.00468860007823
[32m[0315 21:42:39 @dqn_agent.py:216][0m At time step 307500, the target_network is updated
[32m[0315 21:42:41 @network.py:203][0m step: 307600, current TD loss: 0.0141481794417
[32m[0315 21:42:42 @network.py:203][0m step: 307700, current TD loss: 0.00218287995085
[32m[0315 21:42:43 @network.py:203][0m step: 307800, current TD loss: 0.0032480659429
[32m[0315 21:42:45 @network.py:203][0m step: 307900, current TD loss: 0.00166723527946
[32m[0315 21:42:46 @dqn_agent.py:203][0m episode: 15839, total game step: 358000, epsilon: 0.69508099
[32m[0315 21:42:46 @network.py:203][0m step: 308000, current TD loss: 0.0163873340935
[32m[0315 21:42:48 @network.py:203][0m step: 308100, current TD loss: 0.00102234492078
[32m[0315 21:42:49 @network.py:203][0m step: 308200, current TD loss: 0.00251430575736
[32m[0315 21:42:51 @network.py:203][0m step: 308300, current TD loss: 0.00681683095172
[32m[0315 21:42:52 @network.py:203][0m step: 308400, current TD loss: 0.00190162891522
[32m[0315 21:42:53 @network.py:203][0m step: 308500, current TD loss: 0.00219528004527
[32m[0315 21:42:55 @network.py:203][0m step: 308600, current TD loss: 0.00625960715115
[32m[0315 21:42:56 @network.py:203][0m step: 308700, current TD loss: 0.0164611320943
[32m[0315 21:42:58 @network.py:203][0m step: 308800, current TD loss: 0.00331657752395
[32m[0315 21:42:59 @network.py:203][0m step: 308900, current TD loss: 0.00160743657034
[32m[0315 21:43:00 @dqn_agent.py:203][0m episode: 15883, total game step: 359000, epsilon: 0.69409099
[32m[0315 21:43:00 @network.py:203][0m step: 309000, current TD loss: 0.00495996791869
[32m[0315 21:43:02 @network.py:203][0m step: 309100, current TD loss: 0.00688591599464
[32m[0315 21:43:03 @network.py:203][0m step: 309200, current TD loss: 0.00127466674894
[32m[0315 21:43:04 @network.py:203][0m step: 309300, current TD loss: 0.0028337771073
[32m[0315 21:43:06 @network.py:203][0m step: 309400, current TD loss: 0.0012419517152
[32m[0315 21:43:07 @network.py:203][0m step: 309500, current TD loss: 0.00120753736701
[32m[0315 21:43:07 @summary_handler.py:101][0m At episode: 359501, Reward: 0.13 (over 100 episodes)
[32m[0315 21:43:07 @summary_handler.py:102][0m Length: 24.63
[32m[0315 21:43:08 @network.py:203][0m step: 309600, current TD loss: 0.00135844945908
[32m[0315 21:43:10 @network.py:203][0m step: 309700, current TD loss: 0.00311872642487
[32m[0315 21:43:11 @network.py:203][0m step: 309800, current TD loss: 0.00134487543255
[32m[0315 21:43:13 @network.py:203][0m step: 309900, current TD loss: 0.00249900878407
[32m[0315 21:43:14 @dqn_agent.py:203][0m episode: 15923, total game step: 360000, epsilon: 0.69310099
[32m[0315 21:43:14 @network.py:203][0m step: 310000, current TD loss: 0.00288278982043
[32m[0315 21:43:14 @dqn_agent.py:216][0m At time step 310000, the target_network is updated
[32m[0315 21:43:15 @network.py:203][0m step: 310100, current TD loss: 0.00360277155414
[32m[0315 21:43:17 @network.py:203][0m step: 310200, current TD loss: 0.0076400032267
[32m[0315 21:43:18 @network.py:203][0m step: 310300, current TD loss: 0.00194964127149
[32m[0315 21:43:20 @network.py:203][0m step: 310400, current TD loss: 0.00362973986194
[32m[0315 21:43:21 @network.py:203][0m step: 310500, current TD loss: 0.00356896664016
[32m[0315 21:43:22 @network.py:203][0m step: 310600, current TD loss: 0.00344234472141
[32m[0315 21:43:24 @network.py:203][0m step: 310700, current TD loss: 0.0183198731393
[32m[0315 21:43:25 @network.py:203][0m step: 310800, current TD loss: 0.00228708516806
[32m[0315 21:43:27 @network.py:203][0m step: 310900, current TD loss: 0.00132441846654
[32m[0315 21:43:28 @dqn_agent.py:203][0m episode: 15962, total game step: 361000, epsilon: 0.69211099
[32m[0315 21:43:28 @network.py:203][0m step: 311000, current TD loss: 0.00544582447037
[32m[0315 21:43:30 @network.py:203][0m step: 311100, current TD loss: 0.00224964972585
[32m[0315 21:43:31 @network.py:203][0m step: 311200, current TD loss: 0.0144096454605
[32m[0315 21:43:32 @network.py:203][0m step: 311300, current TD loss: 0.00423369277269
[32m[0315 21:43:34 @network.py:203][0m step: 311400, current TD loss: 0.00286433938891
[32m[0315 21:43:35 @network.py:203][0m step: 311500, current TD loss: 0.00452574621886
[32m[0315 21:43:36 @network.py:203][0m step: 311600, current TD loss: 0.00253986939788
[32m[0315 21:43:38 @network.py:203][0m step: 311700, current TD loss: 0.00287777814083
[32m[0315 21:43:39 @network.py:203][0m step: 311800, current TD loss: 0.00283799460158
[32m[0315 21:43:40 @network.py:203][0m step: 311900, current TD loss: 0.0145607851446
[32m[0315 21:43:41 @summary_handler.py:101][0m At episode: 361974, Reward: 0.15 (over 100 episodes)
[32m[0315 21:43:41 @summary_handler.py:102][0m Length: 24.73
[32m[0315 21:43:42 @dqn_agent.py:203][0m episode: 16001, total game step: 362000, epsilon: 0.69112099
[32m[0315 21:43:42 @network.py:203][0m step: 312000, current TD loss: 0.0120231220499
[32m[0315 21:43:43 @network.py:203][0m step: 312100, current TD loss: 0.00716127548367
[32m[0315 21:43:44 @network.py:203][0m step: 312200, current TD loss: 0.00232915813103
[32m[0315 21:43:46 @network.py:203][0m step: 312300, current TD loss: 0.00366982771084
[32m[0315 21:43:47 @network.py:203][0m step: 312400, current TD loss: 0.00283416127786
[32m[0315 21:43:49 @network.py:203][0m step: 312500, current TD loss: 0.00523791275918
[32m[0315 21:43:49 @dqn_agent.py:216][0m At time step 312500, the target_network is updated
[32m[0315 21:43:50 @network.py:203][0m step: 312600, current TD loss: 0.00291458563879
[32m[0315 21:43:51 @network.py:203][0m step: 312700, current TD loss: 0.00167956307996
[32m[0315 21:43:53 @network.py:203][0m step: 312800, current TD loss: 0.00377513561398
[32m[0315 21:43:54 @network.py:203][0m step: 312900, current TD loss: 0.0020167962648
[32m[0315 21:43:56 @dqn_agent.py:203][0m episode: 16048, total game step: 363000, epsilon: 0.69013099
[32m[0315 21:43:56 @network.py:203][0m step: 313000, current TD loss: 0.00323945702985
[32m[0315 21:43:57 @network.py:203][0m step: 313100, current TD loss: 0.0141288358718
[32m[0315 21:43:58 @network.py:203][0m step: 313200, current TD loss: 0.0288767963648
[32m[0315 21:44:00 @network.py:203][0m step: 313300, current TD loss: 0.00313714472577
[32m[0315 21:44:01 @network.py:203][0m step: 313400, current TD loss: 0.00202947901562
[32m[0315 21:44:02 @network.py:203][0m step: 313500, current TD loss: 0.00426911469549
[32m[0315 21:44:04 @network.py:203][0m step: 313600, current TD loss: 0.00930845364928
[32m[0315 21:44:05 @network.py:203][0m step: 313700, current TD loss: 0.00144332111813
[32m[0315 21:44:07 @network.py:203][0m step: 313800, current TD loss: 0.00166950444691
[32m[0315 21:44:08 @network.py:203][0m step: 313900, current TD loss: 0.00174478953704
[32m[0315 21:44:09 @dqn_agent.py:203][0m episode: 16089, total game step: 364000, epsilon: 0.68914099
[32m[0315 21:44:09 @network.py:203][0m step: 314000, current TD loss: 0.00383847812191
[32m[0315 21:44:11 @network.py:203][0m step: 314100, current TD loss: 0.00370006985031
[32m[0315 21:44:12 @network.py:203][0m step: 314200, current TD loss: 0.00332088000141
[32m[0315 21:44:12 @summary_handler.py:101][0m At episode: 364230, Reward: 0.13 (over 100 episodes)
[32m[0315 21:44:12 @summary_handler.py:102][0m Length: 22.56
[32m[0315 21:44:13 @network.py:203][0m step: 314300, current TD loss: 0.00982655584812
[32m[0315 21:44:15 @network.py:203][0m step: 314400, current TD loss: 0.00444417400286
[32m[0315 21:44:16 @network.py:203][0m step: 314500, current TD loss: 0.00340765202418
[32m[0315 21:44:17 @network.py:203][0m step: 314600, current TD loss: 0.000973468064331
[32m[0315 21:44:19 @network.py:203][0m step: 314700, current TD loss: 0.00381122087128
[32m[0315 21:44:20 @network.py:203][0m step: 314800, current TD loss: 0.00237329630181
[32m[0315 21:44:21 @network.py:203][0m step: 314900, current TD loss: 0.00733951479197
[32m[0315 21:44:23 @dqn_agent.py:203][0m episode: 16131, total game step: 365000, epsilon: 0.68815099
[32m[0315 21:44:23 @network.py:203][0m step: 315000, current TD loss: 0.00448532309383
[32m[0315 21:44:23 @dqn_agent.py:216][0m At time step 315000, the target_network is updated
[32m[0315 21:44:24 @network.py:203][0m step: 315100, current TD loss: 0.00147195265163
[32m[0315 21:44:25 @network.py:203][0m step: 315200, current TD loss: 0.000871748896316
[32m[0315 21:44:27 @network.py:203][0m step: 315300, current TD loss: 0.00535573204979
[32m[0315 21:44:28 @network.py:203][0m step: 315400, current TD loss: 0.00415963260457
[32m[0315 21:44:29 @network.py:203][0m step: 315500, current TD loss: 0.00978504586965
[32m[0315 21:44:31 @network.py:203][0m step: 315600, current TD loss: 0.00175109447446
[32m[0315 21:44:32 @network.py:203][0m step: 315700, current TD loss: 0.00792614556849
[32m[0315 21:44:33 @network.py:203][0m step: 315800, current TD loss: 0.00149816670455
[32m[0315 21:44:34 @network.py:203][0m step: 315900, current TD loss: 0.00065099413041
[32m[0315 21:44:36 @dqn_agent.py:203][0m episode: 16163, total game step: 366000, epsilon: 0.68716099
[32m[0315 21:44:36 @network.py:203][0m step: 316000, current TD loss: 0.0040797307156
[32m[0315 21:44:37 @network.py:203][0m step: 316100, current TD loss: 0.00348540442064
[32m[0315 21:44:38 @network.py:203][0m step: 316200, current TD loss: 0.00481259683147
[32m[0315 21:44:40 @network.py:203][0m step: 316300, current TD loss: 0.0128790056333
[32m[0315 21:44:41 @network.py:203][0m step: 316400, current TD loss: 0.00321913603693
[32m[0315 21:44:42 @network.py:203][0m step: 316500, current TD loss: 0.00480200257152
[32m[0315 21:44:44 @network.py:203][0m step: 316600, current TD loss: 0.00235098460689
[32m[0315 21:44:45 @network.py:203][0m step: 316700, current TD loss: 0.00209254212677
[32m[0315 21:44:46 @summary_handler.py:101][0m At episode: 366755, Reward: 0.17 (over 100 episodes)
[32m[0315 21:44:46 @summary_handler.py:102][0m Length: 25.25
[32m[0315 21:44:46 @network.py:203][0m step: 316800, current TD loss: 0.0182537715882
[32m[0315 21:44:48 @network.py:203][0m step: 316900, current TD loss: 0.00129914376885
[32m[0315 21:44:49 @dqn_agent.py:203][0m episode: 16207, total game step: 367000, epsilon: 0.68617099
[32m[0315 21:44:49 @network.py:203][0m step: 317000, current TD loss: 0.0157133489847
[32m[0315 21:44:50 @network.py:203][0m step: 317100, current TD loss: 0.00375913921744
[32m[0315 21:44:52 @network.py:203][0m step: 317200, current TD loss: 0.00601819483563
[32m[0315 21:44:53 @network.py:203][0m step: 317300, current TD loss: 0.00139644416049
[32m[0315 21:44:54 @network.py:203][0m step: 317400, current TD loss: 0.00612940546125
[32m[0315 21:44:56 @network.py:203][0m step: 317500, current TD loss: 0.001812414499
[32m[0315 21:44:56 @dqn_agent.py:216][0m At time step 317500, the target_network is updated
[32m[0315 21:44:57 @network.py:203][0m step: 317600, current TD loss: 0.0127607891336
[32m[0315 21:44:58 @network.py:203][0m step: 317700, current TD loss: 0.0022229347378
[32m[0315 21:45:00 @network.py:203][0m step: 317800, current TD loss: 0.0152180213481
[32m[0315 21:45:01 @network.py:203][0m step: 317900, current TD loss: 0.00448106043041
[32m[0315 21:45:02 @dqn_agent.py:203][0m episode: 16251, total game step: 368000, epsilon: 0.68518099
[32m[0315 21:45:02 @network.py:203][0m step: 318000, current TD loss: 0.00313989678398
[32m[0315 21:45:04 @network.py:203][0m step: 318100, current TD loss: 0.00464296294376
[32m[0315 21:45:05 @network.py:203][0m step: 318200, current TD loss: 0.00164640927687
[32m[0315 21:45:06 @network.py:203][0m step: 318300, current TD loss: 0.00317501462996
[32m[0315 21:45:08 @network.py:203][0m step: 318400, current TD loss: 0.00274867052212
[32m[0315 21:45:09 @network.py:203][0m step: 318500, current TD loss: 0.00167902978137
[32m[0315 21:45:10 @network.py:203][0m step: 318600, current TD loss: 0.00220454856753
[32m[0315 21:45:12 @network.py:203][0m step: 318700, current TD loss: 0.00219924654812
[32m[0315 21:45:13 @network.py:203][0m step: 318800, current TD loss: 0.00239662453532
[32m[0315 21:45:14 @network.py:203][0m step: 318900, current TD loss: 0.00402688793838
[32m[0315 21:45:16 @dqn_agent.py:203][0m episode: 16286, total game step: 369000, epsilon: 0.68419099
[32m[0315 21:45:16 @network.py:203][0m step: 319000, current TD loss: 0.00264949491248
[32m[0315 21:45:17 @network.py:203][0m step: 319100, current TD loss: 0.00801803264767
[32m[0315 21:45:18 @network.py:203][0m step: 319200, current TD loss: 0.00209792889655
[32m[0315 21:45:19 @summary_handler.py:101][0m At episode: 369243, Reward: 0.19 (over 100 episodes)
[32m[0315 21:45:19 @summary_handler.py:102][0m Length: 24.88
[32m[0315 21:45:20 @network.py:203][0m step: 319300, current TD loss: 0.0030986466445
[32m[0315 21:45:21 @network.py:203][0m step: 319400, current TD loss: 0.00397673575208
[32m[0315 21:45:22 @network.py:203][0m step: 319500, current TD loss: 0.0023552828934
[32m[0315 21:45:24 @network.py:203][0m step: 319600, current TD loss: 0.0019366114866
[32m[0315 21:45:25 @network.py:203][0m step: 319700, current TD loss: 0.00516666192561
[32m[0315 21:45:26 @network.py:203][0m step: 319800, current TD loss: 0.00319817732088
[32m[0315 21:45:28 @network.py:203][0m step: 319900, current TD loss: 0.00172719382681
[32m[0315 21:45:29 @dqn_agent.py:203][0m episode: 16334, total game step: 370000, epsilon: 0.68320099
[32m[0315 21:45:29 @network.py:203][0m step: 320000, current TD loss: 0.00392388924956
[32m[0315 21:45:29 @dqn_agent.py:216][0m At time step 320000, the target_network is updated
[32m[0315 21:45:30 @network.py:203][0m step: 320100, current TD loss: 0.00522444210947
[32m[0315 21:45:32 @network.py:203][0m step: 320200, current TD loss: 0.00370931718498
[32m[0315 21:45:33 @network.py:203][0m step: 320300, current TD loss: 0.00384627562016
[32m[0315 21:45:35 @network.py:203][0m step: 320400, current TD loss: 0.0126087591052
[32m[0315 21:45:36 @network.py:203][0m step: 320500, current TD loss: 0.000571009120904
[32m[0315 21:45:37 @network.py:203][0m step: 320600, current TD loss: 0.00215944554657
[32m[0315 21:45:39 @network.py:203][0m step: 320700, current TD loss: 0.00286051584408
[32m[0315 21:45:40 @network.py:203][0m step: 320800, current TD loss: 0.00290696858428
[32m[0315 21:45:41 @network.py:203][0m step: 320900, current TD loss: 0.00451999902725
[32m[0315 21:45:43 @dqn_agent.py:203][0m episode: 16376, total game step: 371000, epsilon: 0.68221099
[32m[0315 21:45:43 @network.py:203][0m step: 321000, current TD loss: 0.00267154560424
[32m[0315 21:45:44 @network.py:203][0m step: 321100, current TD loss: 0.00152889965102
[32m[0315 21:45:45 @network.py:203][0m step: 321200, current TD loss: 0.00734539050609
[32m[0315 21:45:47 @network.py:203][0m step: 321300, current TD loss: 0.00246546417475
[32m[0315 21:45:48 @network.py:203][0m step: 321400, current TD loss: 0.0142686087638
[32m[0315 21:45:49 @network.py:203][0m step: 321500, current TD loss: 0.00527154561132
[32m[0315 21:45:49 @summary_handler.py:101][0m At episode: 371506, Reward: 0.12 (over 100 episodes)
[32m[0315 21:45:49 @summary_handler.py:102][0m Length: 22.63
[32m[0315 21:45:51 @network.py:203][0m step: 321600, current TD loss: 0.00222361204214
[32m[0315 21:45:52 @network.py:203][0m step: 321700, current TD loss: 0.00239176442847
[32m[0315 21:45:53 @network.py:203][0m step: 321800, current TD loss: 0.00384669937193
[32m[0315 21:45:55 @network.py:203][0m step: 321900, current TD loss: 0.00127593881916
[32m[0315 21:45:56 @dqn_agent.py:203][0m episode: 16421, total game step: 372000, epsilon: 0.68122099
[32m[0315 21:45:56 @network.py:203][0m step: 322000, current TD loss: 0.0209632627666
[32m[0315 21:45:57 @network.py:203][0m step: 322100, current TD loss: 0.00561000267044
[32m[0315 21:45:59 @network.py:203][0m step: 322200, current TD loss: 0.00865236949176
[32m[0315 21:46:00 @network.py:203][0m step: 322300, current TD loss: 0.00560310017318
[32m[0315 21:46:02 @network.py:203][0m step: 322400, current TD loss: 0.0036220671609
[32m[0315 21:46:03 @network.py:203][0m step: 322500, current TD loss: 0.00347724300809
[32m[0315 21:46:03 @dqn_agent.py:216][0m At time step 322500, the target_network is updated
[32m[0315 21:46:04 @network.py:203][0m step: 322600, current TD loss: 0.00710912840441
[32m[0315 21:46:06 @network.py:203][0m step: 322700, current TD loss: 0.00134569511283
[32m[0315 21:46:07 @network.py:203][0m step: 322800, current TD loss: 0.00179440097418
[32m[0315 21:46:09 @network.py:203][0m step: 322900, current TD loss: 0.0112946657464
[32m[0315 21:46:10 @dqn_agent.py:203][0m episode: 16454, total game step: 373000, epsilon: 0.68023099
[32m[0315 21:46:10 @network.py:203][0m step: 323000, current TD loss: 0.00486369151622
[32m[0315 21:46:11 @network.py:203][0m step: 323100, current TD loss: 0.00277985399589
[32m[0315 21:46:13 @network.py:203][0m step: 323200, current TD loss: 0.00167350762058
[32m[0315 21:46:14 @network.py:203][0m step: 323300, current TD loss: 0.00275402283296
[32m[0315 21:46:15 @network.py:203][0m step: 323400, current TD loss: 0.0049682664685
[32m[0315 21:46:17 @network.py:203][0m step: 323500, current TD loss: 0.00228814524598
[32m[0315 21:46:18 @network.py:203][0m step: 323600, current TD loss: 0.00693259947002
[32m[0315 21:46:19 @network.py:203][0m step: 323700, current TD loss: 0.0137068396434
[32m[0315 21:46:21 @network.py:203][0m step: 323800, current TD loss: 0.00236251624301
[32m[0315 21:46:22 @network.py:203][0m step: 323900, current TD loss: 0.00615139678121
[32m[0315 21:46:23 @dqn_agent.py:203][0m episode: 16499, total game step: 374000, epsilon: 0.67924099
[32m[0315 21:46:23 @network.py:203][0m step: 324000, current TD loss: 0.00213943002746
[32m[0315 21:46:23 @summary_handler.py:101][0m At episode: 374014, Reward: 0.2 (over 100 episodes)
[32m[0315 21:46:23 @summary_handler.py:102][0m Length: 25.08
[32m[0315 21:46:25 @network.py:203][0m step: 324100, current TD loss: 0.00252408860251
[32m[0315 21:46:26 @network.py:203][0m step: 324200, current TD loss: 0.00578749552369
[32m[0315 21:46:27 @network.py:203][0m step: 324300, current TD loss: 0.00146275246516
[32m[0315 21:46:29 @network.py:203][0m step: 324400, current TD loss: 0.0223661363125
[32m[0315 21:46:30 @network.py:203][0m step: 324500, current TD loss: 0.00807893835008
[32m[0315 21:46:31 @network.py:203][0m step: 324600, current TD loss: 0.00361601426266
[32m[0315 21:46:32 @network.py:203][0m step: 324700, current TD loss: 0.00354220531881
[32m[0315 21:46:34 @network.py:203][0m step: 324800, current TD loss: 0.00108516169712
[32m[0315 21:46:35 @network.py:203][0m step: 324900, current TD loss: 0.00273313559592
[32m[0315 21:46:36 @dqn_agent.py:203][0m episode: 16530, total game step: 375000, epsilon: 0.67825099
[32m[0315 21:46:36 @network.py:203][0m step: 325000, current TD loss: 0.00553305540234
[32m[0315 21:46:36 @dqn_agent.py:216][0m At time step 325000, the target_network is updated
[32m[0315 21:46:38 @network.py:203][0m step: 325100, current TD loss: 0.00211955956183
[32m[0315 21:46:39 @network.py:203][0m step: 325200, current TD loss: 0.0137697299942
[32m[0315 21:46:40 @network.py:203][0m step: 325300, current TD loss: 0.00198781210929
[32m[0315 21:46:42 @network.py:203][0m step: 325400, current TD loss: 0.00110571878031
[32m[0315 21:46:43 @network.py:203][0m step: 325500, current TD loss: 0.00325518846512
[32m[0315 21:46:44 @network.py:203][0m step: 325600, current TD loss: 0.0224922150373
[32m[0315 21:46:46 @network.py:203][0m step: 325700, current TD loss: 0.0185024105012
[32m[0315 21:46:47 @network.py:203][0m step: 325800, current TD loss: 0.00671788305044
[32m[0315 21:46:48 @network.py:203][0m step: 325900, current TD loss: 0.00291483104229
[32m[0315 21:46:49 @dqn_agent.py:203][0m episode: 16568, total game step: 376000, epsilon: 0.67726099
[32m[0315 21:46:49 @network.py:203][0m step: 326000, current TD loss: 0.000766306475271
[32m[0315 21:46:50 @network.py:203][0m step: 326100, current TD loss: 0.00113965326454
[32m[0315 21:46:51 @network.py:203][0m step: 326200, current TD loss: 0.00085095630493
[32m[0315 21:46:52 @network.py:203][0m step: 326300, current TD loss: 0.0199556071311
[32m[0315 21:46:54 @network.py:203][0m step: 326400, current TD loss: 0.00267021567561
[32m[0315 21:46:55 @network.py:203][0m step: 326500, current TD loss: 0.00161275872961
[32m[0315 21:46:56 @network.py:203][0m step: 326600, current TD loss: 0.00567300105467
[32m[0315 21:46:57 @network.py:203][0m step: 326700, current TD loss: 0.00551378726959
[32m[0315 21:46:58 @summary_handler.py:101][0m At episode: 376794, Reward: 0.2 (over 100 episodes)
[32m[0315 21:46:58 @summary_handler.py:102][0m Length: 27.8
[32m[0315 21:46:58 @network.py:203][0m step: 326800, current TD loss: 0.000883379601873
[32m[0315 21:46:59 @network.py:203][0m step: 326900, current TD loss: 0.00533044151962
[32m[0315 21:47:00 @dqn_agent.py:203][0m episode: 16611, total game step: 377000, epsilon: 0.67627099
[32m[0315 21:47:00 @network.py:203][0m step: 327000, current TD loss: 0.00388921960257
[32m[0315 21:47:02 @network.py:203][0m step: 327100, current TD loss: 0.00172213301994
[32m[0315 21:47:03 @network.py:203][0m step: 327200, current TD loss: 0.00246609887108
[32m[0315 21:47:04 @network.py:203][0m step: 327300, current TD loss: 0.00722289551049
[32m[0315 21:47:05 @network.py:203][0m step: 327400, current TD loss: 0.0149484351277
[32m[0315 21:47:06 @network.py:203][0m step: 327500, current TD loss: 0.00068098452175
[32m[0315 21:47:06 @dqn_agent.py:216][0m At time step 327500, the target_network is updated
[32m[0315 21:47:07 @network.py:203][0m step: 327600, current TD loss: 0.00366034870967
[32m[0315 21:47:08 @network.py:203][0m step: 327700, current TD loss: 0.00223624706268
[32m[0315 21:47:10 @network.py:203][0m step: 327800, current TD loss: 0.00295214122161
[32m[0315 21:47:11 @network.py:203][0m step: 327900, current TD loss: 0.0150819066912
[32m[0315 21:47:12 @dqn_agent.py:203][0m episode: 16646, total game step: 378000, epsilon: 0.67528099
[32m[0315 21:47:12 @network.py:203][0m step: 328000, current TD loss: 0.00583788193762
[32m[0315 21:47:13 @network.py:203][0m step: 328100, current TD loss: 0.002404659288
[32m[0315 21:47:14 @network.py:203][0m step: 328200, current TD loss: 0.00686849933118
[32m[0315 21:47:15 @network.py:203][0m step: 328300, current TD loss: 0.00274673709646
[32m[0315 21:47:16 @network.py:203][0m step: 328400, current TD loss: 0.0118922991678
[32m[0315 21:47:17 @network.py:203][0m step: 328500, current TD loss: 0.0122938901186
[32m[0315 21:47:19 @network.py:203][0m step: 328600, current TD loss: 0.0127404360101
[32m[0315 21:47:20 @network.py:203][0m step: 328700, current TD loss: 0.00937163736671
