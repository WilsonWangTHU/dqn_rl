[32m[0313 21:59:52 @logger.py:67][0m Log file set to /mnt/rl_playground/tool/train_gym.py/../../log/gym_0313-215952.log
[32m[0313 21:59:52 @train_gym.py:36][0m Session starts, using gpu: 0
[32m[0313 21:59:52 @dqn_agent.py:46][0m Constructing a q-learning agent to play Breakout-v0
[32m[0313 21:59:52 @environments.py:45][0m Init game environments Breakout-v0
[32m[0313 21:59:52 @environments.py:87][0m Game set image size: 80, random walk step: 30
[32m[0313 21:59:52 @network.py:123][0m building the target network, name: target_network
[32m[0313 21:59:52 @network.py:51][0m Building network of type: dqn, using basebone: nips
[32m[0313 21:59:52 @cnn.py:21][0m building the basebone network, using nips format
[32m[0313 21:59:52 @network.py:125][0m building the pred network, name: predict_network
[32m[0313 21:59:52 @network.py:51][0m Building network of type: dqn, using basebone: nips
[32m[0313 21:59:52 @cnn.py:21][0m building the basebone network, using nips format
[32m[0313 21:59:52 @experience.py:23][0m building the experience shop
[32m[0313 21:59:52 @summary_handler.py:30][0m summary write initialized, writing to /mnt/rl_playground/tool/../agent/../checkpoint
[32m[0313 21:59:57 @summary_handler.py:92][0m At episode: 1099, Reward: 0.267326732673 (over 100 episodes)
[32m[0313 21:59:57 @summary_handler.py:93][0m Length: 10.8811881188
[32m[0313 22:00:02 @summary_handler.py:92][0m At episode: 2281, Reward: 0.29702970297 (over 100 episodes)
[32m[0313 22:00:02 @summary_handler.py:93][0m Length: 11.702970297
[32m[0313 22:00:19 @summary_handler.py:92][0m At episode: 3283, Reward: 0.19801980198 (over 100 episodes)
[32m[0313 22:00:19 @summary_handler.py:93][0m Length: 9.92079207921
[32m[0313 22:00:24 @summary_handler.py:92][0m At episode: 4383, Reward: 0.29702970297 (over 100 episodes)
[32m[0313 22:00:24 @summary_handler.py:93][0m Length: 10.8910891089
[32m[0313 22:00:28 @summary_handler.py:92][0m At episode: 5504, Reward: 0.267326732673 (over 100 episodes)
[32m[0313 22:00:28 @summary_handler.py:93][0m Length: 11.099009901
[32m[0313 22:00:33 @summary_handler.py:92][0m At episode: 6595, Reward: 0.247524752475 (over 100 episodes)
[32m[0313 22:00:33 @summary_handler.py:93][0m Length: 10.801980198
[32m[0313 22:00:41 @summary_handler.py:92][0m At episode: 7552, Reward: 0.178217821782 (over 100 episodes)
[32m[0313 22:00:41 @summary_handler.py:93][0m Length: 9.47524752475
[32m[0313 22:00:45 @summary_handler.py:92][0m At episode: 8566, Reward: 0.178217821782 (over 100 episodes)
[32m[0313 22:00:45 @summary_handler.py:93][0m Length: 10.0396039604
[32m[0313 22:01:54 @summary_handler.py:92][0m At episode: 9721, Reward: 0.267326732673 (over 100 episodes)
[32m[0313 22:01:54 @summary_handler.py:93][0m Length: 11.4356435644
