[32m[0315 11:27:33 @logger.py:67][0m Log file set to /mnt/rl_playground/tool/train_gym.py/../../log/gym_0315-112733.log
[32m[0315 11:27:33 @train_gym.py:36][0m Session starts, using gpu: 0
[32m[0315 11:27:33 @dqn_agent.py:46][0m Constructing a q-learning agent to play Breakout-v0
[32m[0315 11:27:33 @environments.py:45][0m Init game environments Breakout-v0
[32m[0315 11:27:33 @environments.py:87][0m Game set image size: 80, random walk step: 30
[32m[0315 11:27:33 @network.py:124][0m building the target network, name: target_network
[32m[0315 11:27:33 @network.py:52][0m Building network of type: dqn, using basebone: nips
[32m[0315 11:27:33 @cnn.py:21][0m building the basebone network, using nips format
[32m[0315 11:27:33 @network.py:126][0m building the pred network, name: predict_network
[32m[0315 11:27:33 @network.py:52][0m Building network of type: dqn, using basebone: nips
[32m[0315 11:27:33 @cnn.py:21][0m building the basebone network, using nips format
[32m[0315 11:27:34 @experience.py:23][0m building the experience shop
[32m[0315 11:27:34 @summary_handler.py:30][0m summary write initialized, writing to /mnt/rl_playground/tool/../agent/../checkpoint
[32m[0315 11:27:38 @summary_handler.py:92][0m At episode: 1007, Reward: 0.148514851485 (over 100 episodes)
[32m[0315 11:27:38 @summary_handler.py:93][0m Length: 9.9702970297
[32m[0315 11:27:42 @summary_handler.py:92][0m At episode: 2025, Reward: 0.237623762376 (over 100 episodes)
[32m[0315 11:27:42 @summary_handler.py:93][0m Length: 10.0792079208
[32m[0315 11:27:47 @summary_handler.py:92][0m At episode: 3256, Reward: 0.366336633663 (over 100 episodes)
[32m[0315 11:27:47 @summary_handler.py:93][0m Length: 12.1881188119
[32m[0315 11:27:51 @summary_handler.py:92][0m At episode: 4291, Reward: 0.247524752475 (over 100 episodes)
[32m[0315 11:27:51 @summary_handler.py:93][0m Length: 10.2475247525
[32m[0315 11:27:54 @dqn_agent.py:208][0m episode: 5000, epsilon: 1.0
[32m[0315 11:27:56 @summary_handler.py:92][0m At episode: 5507, Reward: 0.29702970297 (over 100 episodes)
[32m[0315 11:27:56 @summary_handler.py:93][0m Length: 12.0396039604
[32m[0315 11:28:00 @summary_handler.py:92][0m At episode: 6593, Reward: 0.267326732673 (over 100 episodes)
[32m[0315 11:28:00 @summary_handler.py:93][0m Length: 10.7524752475
