[32m[0312 23:20:28 @logger.py:67][0m Log file set to /mnt/rl_playground/tool/train_gym.py/../../log/gym_0312-232028.log
[32m[0312 23:20:28 @train_gym.py:35][0m Session starts, using gpu: 0
[32m[0312 23:20:28 @dqn_agent.py:46][0m Constructing a q-learning agent to play Breakout-v0
[32m[0312 23:20:28 @environments.py:43][0m Init game environments Breakout-v0
[32m[0312 23:20:28 @environments.py:74][0m Game set image size: 80, random walk step: 30
[32m[0312 23:20:28 @network.py:122][0m building the target network, name: target_network
[32m[0312 23:20:28 @network.py:51][0m Building network of type: dqn, using basebone: nips
[32m[0312 23:20:28 @cnn.py:21][0m building the basebone network, using nips format
[32m[0312 23:20:28 @network.py:124][0m building the pred network, name: predict_network
[32m[0312 23:20:28 @network.py:51][0m Building network of type: dqn, using basebone: nips
[32m[0312 23:20:28 @cnn.py:21][0m building the basebone network, using nips format
[32m[0312 23:20:28 @experience.py:23][0m building the experience shop
[32m[0312 23:20:28 @summary_handler.py:30][0m summary write initialized, writing to /mnt/rl_playground/tool/../agent/../checkpoint
[32m[0312 23:20:30 @dqn_agent.py:183][0m Playing at episode: 7, this time we got reward 0.0
[32m[0312 23:20:30 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:30 @dqn_agent.py:183][0m Playing at episode: 14, this time we got reward 0.0
[32m[0312 23:20:30 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:30 @dqn_agent.py:183][0m Playing at episode: 21, this time we got reward 0.0
[32m[0312 23:20:30 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:30 @dqn_agent.py:183][0m Playing at episode: 29, this time we got reward 0.0
[32m[0312 23:20:30 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:31 @dqn_agent.py:183][0m Playing at episode: 36, this time we got reward 0.0
[32m[0312 23:20:31 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:31 @dqn_agent.py:183][0m Playing at episode: 52, this time we got reward 1.0
[32m[0312 23:20:31 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:32 @dqn_agent.py:183][0m Playing at episode: 62, this time we got reward 0.0
[32m[0312 23:20:32 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:32 @dqn_agent.py:183][0m Playing at episode: 84, this time we got reward 1.0
[32m[0312 23:20:32 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:33 @dqn_agent.py:183][0m Playing at episode: 92, this time we got reward 0.0
[32m[0312 23:20:33 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:33 @dqn_agent.py:183][0m Playing at episode: 99, this time we got reward 0.0
[32m[0312 23:20:33 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:34 @dqn_agent.py:183][0m Playing at episode: 134, this time we got reward 2.0
[32m[0312 23:20:34 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:34 @dqn_agent.py:183][0m Playing at episode: 135, this time we got reward 0.0
[32m[0312 23:20:34 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:35 @dqn_agent.py:183][0m Playing at episode: 143, this time we got reward 0.0
[32m[0312 23:20:35 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:35 @dqn_agent.py:183][0m Playing at episode: 150, this time we got reward 0.0
[32m[0312 23:20:35 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:35 @dqn_agent.py:183][0m Playing at episode: 156, this time we got reward 0.0
[32m[0312 23:20:35 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:35 @dqn_agent.py:183][0m Playing at episode: 165, this time we got reward 0.0
[32m[0312 23:20:35 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:36 @dqn_agent.py:183][0m Playing at episode: 172, this time we got reward 0.0
[32m[0312 23:20:36 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:36 @dqn_agent.py:183][0m Playing at episode: 180, this time we got reward 0.0
[32m[0312 23:20:36 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:37 @dqn_agent.py:183][0m Playing at episode: 200, this time we got reward 1.0
[32m[0312 23:20:37 @dqn_agent.py:184][0m    Epsilon: 1.0
[32m[0312 23:20:37 @dqn_agent.py:183][0m Playing at episode: 207, this time we got reward 0.0
[32m[0312 23:20:37 @dqn_agent.py:184][0m    Epsilon: 0.9997624
[32m[0312 23:20:37 @dqn_agent.py:201][0m At time step 0, the target_network is updated
